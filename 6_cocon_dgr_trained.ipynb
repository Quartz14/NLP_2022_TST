{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T02:58:00.983332Z",
     "iopub.status.busy": "2022-04-17T02:58:00.98303Z",
     "iopub.status.idle": "2022-04-17T02:58:08.09453Z",
     "shell.execute_reply": "2022-04-17T02:58:08.093737Z",
     "shell.execute_reply.started": "2022-04-17T02:58:00.9833Z"
    },
    "id": "ZcfYGRvnRUvW",
    "outputId": "31de46a3-5623-4ca4-e572-3f63f9a0200b"
   },
   "outputs": [],
   "source": [
    "from transformers_cocon import (AdamW,GPT2Config,GPT2LMHeadModel,GPT2Tokenizer,\n",
    "                                         PreTrainedModel,PreTrainedTokenizer,get_linear_schedule_with_warmup,\n",
    "                                         CoconBlock,HDiscriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T02:57:56.293109Z",
     "iopub.status.busy": "2022-04-17T02:57:56.292466Z",
     "iopub.status.idle": "2022-04-17T02:57:56.297199Z",
     "shell.execute_reply": "2022-04-17T02:57:56.296326Z",
     "shell.execute_reply.started": "2022-04-17T02:57:56.293069Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../input/yelp-dgr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T02:58:19.70593Z",
     "iopub.status.busy": "2022-04-17T02:58:19.705592Z",
     "iopub.status.idle": "2022-04-17T02:58:19.782586Z",
     "shell.execute_reply": "2022-04-17T02:58:19.781838Z",
     "shell.execute_reply.started": "2022-04-17T02:58:19.705892Z"
    },
    "id": "8cSRDouXJl1X",
    "outputId": "8597666b-ab75-4f89-e2df-e7183722f2f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T02:58:22.178501Z",
     "iopub.status.busy": "2022-04-17T02:58:22.178225Z",
     "iopub.status.idle": "2022-04-17T02:58:22.184646Z",
     "shell.execute_reply": "2022-04-17T02:58:22.18355Z",
     "shell.execute_reply.started": "2022-04-17T02:58:22.178453Z"
    },
    "id": "gvieVnQBJzEO",
    "outputId": "53048095-6d84-4f96-8603-1dadf8ab1e17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T02:58:24.399626Z",
     "iopub.status.busy": "2022-04-17T02:58:24.39884Z",
     "iopub.status.idle": "2022-04-17T02:58:24.408222Z",
     "shell.execute_reply": "2022-04-17T02:58:24.407315Z",
     "shell.execute_reply.started": "2022-04-17T02:58:24.399581Z"
    },
    "id": "XYw8QPQvXiEd"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "from typing import Dict, List, Tuple\n",
    "import json\n",
    "#import wget\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.distributed import get_rank, get_world_size\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.modules.normalization import LayerNorm\n",
    "from torch.nn.modules import ModuleList\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T02:58:26.257612Z",
     "iopub.status.busy": "2022-04-17T02:58:26.257314Z",
     "iopub.status.idle": "2022-04-17T02:58:54.862188Z",
     "shell.execute_reply": "2022-04-17T02:58:54.86142Z",
     "shell.execute_reply.started": "2022-04-17T02:58:26.25758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.config.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T02:58:54.864227Z",
     "iopub.status.busy": "2022-04-17T02:58:54.863963Z",
     "iopub.status.idle": "2022-04-17T02:58:55.607252Z",
     "shell.execute_reply": "2022-04-17T02:58:55.606515Z",
     "shell.execute_reply.started": "2022-04-17T02:58:54.864191Z"
    },
    "id": "tXTPbbZjXiEx",
    "outputId": "7546f4f6-19a1-4219-ad6a-dfd755c19d5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50263"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens = ['<POS>', '<NEG>','<CON_START>','<START>','<END>','<PAD>']\n",
    "special_tokens_dict = {'additional_special_tokens': special_tokens}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "start_token_id = tokenizer.convert_tokens_to_ids(['<START>'])[0]\n",
    "pad_token_id = tokenizer.convert_tokens_to_ids(['<PAD>'])[0]\n",
    "model.config.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T02:58:55.609131Z",
     "iopub.status.busy": "2022-04-17T02:58:55.608656Z",
     "iopub.status.idle": "2022-04-17T02:58:56.763367Z",
     "shell.execute_reply": "2022-04-17T02:58:56.762405Z",
     "shell.execute_reply.started": "2022-04-17T02:58:55.609087Z"
    },
    "id": "CXbf-366XiE0"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    #print(param)\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64HOE1TwXuGs",
    "outputId": "c6cdfc81-e15a-41b2-f217-b20947bc3598"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "mount='/content/gdrive'\n",
    "print(\"Colab: mounting Google drive on \", mount)\n",
    "\n",
    "drive.mount(mount)\n",
    "# Switch to the directory on the Google Drive that you want to use\n",
    "import os\n",
    "drive_root = mount + \"/My Drive/NLP-project-2022/\"\n",
    "%cd $drive_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T12:04:59.110372Z",
     "iopub.status.busy": "2022-04-01T12:04:59.110041Z",
     "iopub.status.idle": "2022-04-01T12:04:59.896504Z",
     "shell.execute_reply": "2022-04-01T12:04:59.895499Z",
     "shell.execute_reply.started": "2022-04-01T12:04:59.110319Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls '/kaggle/input/sentiment-lexicon/gpt2-pytorch_model.bin'\n",
    "/kaggle/input/sentiment-lexicon/negative-words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T12:02:59.067388Z",
     "iopub.status.busy": "2022-04-01T12:02:59.067093Z",
     "iopub.status.idle": "2022-04-01T12:02:59.074067Z",
     "shell.execute_reply": "2022-04-01T12:02:59.072962Z",
     "shell.execute_reply.started": "2022-04-01T12:02:59.067356Z"
    },
    "id": "pl04Nbb-JxYl",
    "outputId": "997fa75d-4548-4d9e-d08b-e932dfb91319"
   },
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T02:58:56.767237Z",
     "iopub.status.busy": "2022-04-17T02:58:56.767006Z",
     "iopub.status.idle": "2022-04-17T02:59:01.059714Z",
     "shell.execute_reply": "2022-04-17T02:59:01.058945Z",
     "shell.execute_reply.started": "2022-04-17T02:58:56.767203Z"
    },
    "id": "UBlAnAI2KXdt"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GPT2LMHeadModel:\n\tUnexpected key(s) in state_dict: \"transformer.h.0.attn.masked_bias\", \"transformer.h.1.attn.masked_bias\", \"transformer.h.2.attn.masked_bias\", \"transformer.h.3.attn.masked_bias\", \"transformer.h.4.attn.masked_bias\", \"transformer.h.5.attn.masked_bias\", \"transformer.h.6.attn.masked_bias\", \"transformer.h.7.attn.masked_bias\", \"transformer.h.8.attn.masked_bias\", \"transformer.h.9.attn.masked_bias\", \"transformer.h.10.attn.masked_bias\", \"transformer.h.11.attn.masked_bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ee86a2df76a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel_state_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'yelp_models/pytorch_model_zero_grad_1.bin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_state_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aishu\\miniconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m-> 1498\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m   1499\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GPT2LMHeadModel:\n\tUnexpected key(s) in state_dict: \"transformer.h.0.attn.masked_bias\", \"transformer.h.1.attn.masked_bias\", \"transformer.h.2.attn.masked_bias\", \"transformer.h.3.attn.masked_bias\", \"transformer.h.4.attn.masked_bias\", \"transformer.h.5.attn.masked_bias\", \"transformer.h.6.attn.masked_bias\", \"transformer.h.7.attn.masked_bias\", \"transformer.h.8.attn.masked_bias\", \"transformer.h.9.attn.masked_bias\", \"transformer.h.10.attn.masked_bias\", \"transformer.h.11.attn.masked_bias\". "
     ]
    }
   ],
   "source": [
    "model_state_dict = torch.load('yelp_models/pytorch_model_zero_grad_1.bin', map_location='cpu')\n",
    "model.load_state_dict(model_state_dict)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.config.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50263"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "special_tokens = ['<POS>', '<NEG>','<CON_START>','<START>','<END>','<PAD>']\n",
    "special_tokens_dict = {'additional_special_tokens': special_tokens}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "start_token_id = tokenizer.convert_tokens_to_ids(['<START>'])[0]\n",
    "model.config.vocab_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50263, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50263, bias=False)\n",
       ")>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['transformer.wte.weight', 'transformer.wpe.weight', 'transformer.h.0.ln_1.weight', 'transformer.h.0.ln_1.bias', 'transformer.h.0.attn.bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.0.attn.c_attn.weight', 'transformer.h.0.attn.c_attn.bias', 'transformer.h.0.attn.c_proj.weight', 'transformer.h.0.attn.c_proj.bias', 'transformer.h.0.ln_2.weight', 'transformer.h.0.ln_2.bias', 'transformer.h.0.mlp.c_fc.weight', 'transformer.h.0.mlp.c_fc.bias', 'transformer.h.0.mlp.c_proj.weight', 'transformer.h.0.mlp.c_proj.bias', 'transformer.h.1.ln_1.weight', 'transformer.h.1.ln_1.bias', 'transformer.h.1.attn.bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.1.attn.c_attn.weight', 'transformer.h.1.attn.c_attn.bias', 'transformer.h.1.attn.c_proj.weight', 'transformer.h.1.attn.c_proj.bias', 'transformer.h.1.ln_2.weight', 'transformer.h.1.ln_2.bias', 'transformer.h.1.mlp.c_fc.weight', 'transformer.h.1.mlp.c_fc.bias', 'transformer.h.1.mlp.c_proj.weight', 'transformer.h.1.mlp.c_proj.bias', 'transformer.h.2.ln_1.weight', 'transformer.h.2.ln_1.bias', 'transformer.h.2.attn.bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.2.attn.c_attn.weight', 'transformer.h.2.attn.c_attn.bias', 'transformer.h.2.attn.c_proj.weight', 'transformer.h.2.attn.c_proj.bias', 'transformer.h.2.ln_2.weight', 'transformer.h.2.ln_2.bias', 'transformer.h.2.mlp.c_fc.weight', 'transformer.h.2.mlp.c_fc.bias', 'transformer.h.2.mlp.c_proj.weight', 'transformer.h.2.mlp.c_proj.bias', 'transformer.h.3.ln_1.weight', 'transformer.h.3.ln_1.bias', 'transformer.h.3.attn.bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.3.attn.c_attn.weight', 'transformer.h.3.attn.c_attn.bias', 'transformer.h.3.attn.c_proj.weight', 'transformer.h.3.attn.c_proj.bias', 'transformer.h.3.ln_2.weight', 'transformer.h.3.ln_2.bias', 'transformer.h.3.mlp.c_fc.weight', 'transformer.h.3.mlp.c_fc.bias', 'transformer.h.3.mlp.c_proj.weight', 'transformer.h.3.mlp.c_proj.bias', 'transformer.h.4.ln_1.weight', 'transformer.h.4.ln_1.bias', 'transformer.h.4.attn.bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.4.attn.c_attn.weight', 'transformer.h.4.attn.c_attn.bias', 'transformer.h.4.attn.c_proj.weight', 'transformer.h.4.attn.c_proj.bias', 'transformer.h.4.ln_2.weight', 'transformer.h.4.ln_2.bias', 'transformer.h.4.mlp.c_fc.weight', 'transformer.h.4.mlp.c_fc.bias', 'transformer.h.4.mlp.c_proj.weight', 'transformer.h.4.mlp.c_proj.bias', 'transformer.h.5.ln_1.weight', 'transformer.h.5.ln_1.bias', 'transformer.h.5.attn.bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.5.attn.c_attn.weight', 'transformer.h.5.attn.c_attn.bias', 'transformer.h.5.attn.c_proj.weight', 'transformer.h.5.attn.c_proj.bias', 'transformer.h.5.ln_2.weight', 'transformer.h.5.ln_2.bias', 'transformer.h.5.mlp.c_fc.weight', 'transformer.h.5.mlp.c_fc.bias', 'transformer.h.5.mlp.c_proj.weight', 'transformer.h.5.mlp.c_proj.bias', 'transformer.h.6.ln_1.weight', 'transformer.h.6.ln_1.bias', 'transformer.h.6.attn.bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.6.attn.c_attn.weight', 'transformer.h.6.attn.c_attn.bias', 'transformer.h.6.attn.c_proj.weight', 'transformer.h.6.attn.c_proj.bias', 'transformer.h.6.ln_2.weight', 'transformer.h.6.ln_2.bias', 'transformer.h.6.mlp.c_fc.weight', 'transformer.h.6.mlp.c_fc.bias', 'transformer.h.6.mlp.c_proj.weight', 'transformer.h.6.mlp.c_proj.bias', 'transformer.h.7.ln_1.weight', 'transformer.h.7.ln_1.bias', 'transformer.h.7.attn.bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.7.attn.c_attn.weight', 'transformer.h.7.attn.c_attn.bias', 'transformer.h.7.attn.c_proj.weight', 'transformer.h.7.attn.c_proj.bias', 'transformer.h.7.ln_2.weight', 'transformer.h.7.ln_2.bias', 'transformer.h.7.mlp.c_fc.weight', 'transformer.h.7.mlp.c_fc.bias', 'transformer.h.7.mlp.c_proj.weight', 'transformer.h.7.mlp.c_proj.bias', 'transformer.h.8.ln_1.weight', 'transformer.h.8.ln_1.bias', 'transformer.h.8.attn.bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.8.attn.c_attn.weight', 'transformer.h.8.attn.c_attn.bias', 'transformer.h.8.attn.c_proj.weight', 'transformer.h.8.attn.c_proj.bias', 'transformer.h.8.ln_2.weight', 'transformer.h.8.ln_2.bias', 'transformer.h.8.mlp.c_fc.weight', 'transformer.h.8.mlp.c_fc.bias', 'transformer.h.8.mlp.c_proj.weight', 'transformer.h.8.mlp.c_proj.bias', 'transformer.h.9.ln_1.weight', 'transformer.h.9.ln_1.bias', 'transformer.h.9.attn.bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.9.attn.c_attn.weight', 'transformer.h.9.attn.c_attn.bias', 'transformer.h.9.attn.c_proj.weight', 'transformer.h.9.attn.c_proj.bias', 'transformer.h.9.ln_2.weight', 'transformer.h.9.ln_2.bias', 'transformer.h.9.mlp.c_fc.weight', 'transformer.h.9.mlp.c_fc.bias', 'transformer.h.9.mlp.c_proj.weight', 'transformer.h.9.mlp.c_proj.bias', 'transformer.h.10.ln_1.weight', 'transformer.h.10.ln_1.bias', 'transformer.h.10.attn.bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.10.attn.c_attn.weight', 'transformer.h.10.attn.c_attn.bias', 'transformer.h.10.attn.c_proj.weight', 'transformer.h.10.attn.c_proj.bias', 'transformer.h.10.ln_2.weight', 'transformer.h.10.ln_2.bias', 'transformer.h.10.mlp.c_fc.weight', 'transformer.h.10.mlp.c_fc.bias', 'transformer.h.10.mlp.c_proj.weight', 'transformer.h.10.mlp.c_proj.bias', 'transformer.h.11.ln_1.weight', 'transformer.h.11.ln_1.bias', 'transformer.h.11.attn.bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.11.attn.c_attn.weight', 'transformer.h.11.attn.c_attn.bias', 'transformer.h.11.attn.c_proj.weight', 'transformer.h.11.attn.c_proj.bias', 'transformer.h.11.ln_2.weight', 'transformer.h.11.ln_2.bias', 'transformer.h.11.mlp.c_fc.weight', 'transformer.h.11.mlp.c_fc.bias', 'transformer.h.11.mlp.c_proj.weight', 'transformer.h.11.mlp.c_proj.bias', 'transformer.ln_f.weight', 'transformer.ln_f.bias', 'lm_head.weight'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50263, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50263, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load('yelp_models/pytorch_model_zero_grad_1.bin', map_location='cpu')\n",
    "model.load_state_dict(model_state_dict,strict=False) #transformer.h.'0'.attn.masked_bias not loaded as abset in older version of transformers library which is used here\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T02:59:01.062271Z",
     "iopub.status.busy": "2022-04-17T02:59:01.061775Z",
     "iopub.status.idle": "2022-04-17T02:59:01.068494Z",
     "shell.execute_reply": "2022-04-17T02:59:01.067673Z",
     "shell.execute_reply.started": "2022-04-17T02:59:01.062233Z"
    },
    "id": "3atiPh6OXiE6"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T02:59:01.070108Z",
     "iopub.status.busy": "2022-04-17T02:59:01.069749Z",
     "iopub.status.idle": "2022-04-17T02:59:01.07914Z",
     "shell.execute_reply": "2022-04-17T02:59:01.078301Z",
     "shell.execute_reply.started": "2022-04-17T02:59:01.070068Z"
    },
    "id": "FVd6baWDXiE8"
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T02:59:01.082135Z",
     "iopub.status.busy": "2022-04-17T02:59:01.081932Z",
     "iopub.status.idle": "2022-04-17T02:59:02.090011Z",
     "shell.execute_reply": "2022-04-17T02:59:02.089249Z",
     "shell.execute_reply.started": "2022-04-17T02:59:01.082112Z"
    },
    "id": "qIOMTs7_XiFF"
   },
   "outputs": [],
   "source": [
    "config = GPT2Config.from_pretrained(\"gpt2\", cache_dir='saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T02:59:02.92799Z",
     "iopub.status.busy": "2022-04-17T02:59:02.927431Z",
     "iopub.status.idle": "2022-04-17T02:59:03.076084Z",
     "shell.execute_reply": "2022-04-17T02:59:03.075337Z",
     "shell.execute_reply.started": "2022-04-17T02:59:02.927952Z"
    },
    "id": "P0b3pCtCXiFF"
   },
   "outputs": [],
   "source": [
    "cocon_block = CoconBlock(config.n_ctx, config, scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T02:59:03.440177Z",
     "iopub.status.busy": "2022-04-17T02:59:03.439924Z",
     "iopub.status.idle": "2022-04-17T02:59:03.457471Z",
     "shell.execute_reply": "2022-04-17T02:59:03.456793Z",
     "shell.execute_reply.started": "2022-04-17T02:59:03.440148Z"
    },
    "id": "9Gd8JKFzKlxW"
   },
   "outputs": [],
   "source": [
    "cocon_block = cocon_block.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ofvV--YlBt0X"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cocon_block.load_state_dict(torch.load('yelp_models/cocon_dgr_5.pt', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T02:59:06.413211Z",
     "iopub.status.busy": "2022-04-17T02:59:06.412709Z",
     "iopub.status.idle": "2022-04-17T02:59:06.421548Z",
     "shell.execute_reply": "2022-04-17T02:59:06.420357Z",
     "shell.execute_reply.started": "2022-04-17T02:59:06.413168Z"
    },
    "id": "lB4dKFFiXiFG",
    "outputId": "835dd28e-2542-48cb-d639-2120cb3b2c41"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.zero_grad()\n",
    "\n",
    "cocon_block.eval()\n",
    "cocon_block.zero_grad()\n",
    "#cocon_block.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_UolW1HXiFH"
   },
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T02:59:29.830213Z",
     "iopub.status.busy": "2022-04-17T02:59:29.829948Z",
     "iopub.status.idle": "2022-04-17T02:59:32.826065Z",
     "shell.execute_reply": "2022-04-17T02:59:32.825352Z",
     "shell.execute_reply.started": "2022-04-17T02:59:29.830183Z"
    },
    "id": "iETWemBVXiFK",
    "outputId": "5b819de6-7ce9-4692-8812-58675df2ea88"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>c1</th>\n",
       "      <th>a1</th>\n",
       "      <th>r1</th>\n",
       "      <th>del_sent</th>\n",
       "      <th>defr_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>excellent food .</td>\n",
       "      <td>POS</td>\n",
       "      <td>food .</td>\n",
       "      <td>excellent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;POS&gt;&lt;CON_START&gt;food .&lt;START&gt;excellent food .&lt;...</td>\n",
       "      <td>&lt;ATTR_WORDS&gt;excellent&lt;CON_START&gt;food .&lt;START&gt;e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>superb customer service .</td>\n",
       "      <td>POS</td>\n",
       "      <td>customer service .</td>\n",
       "      <td>superb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;POS&gt;&lt;CON_START&gt;customer service .&lt;START&gt;super...</td>\n",
       "      <td>&lt;ATTR_WORDS&gt;superb&lt;CON_START&gt;customer service ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they also have daily specials and ice cream wh...</td>\n",
       "      <td>POS</td>\n",
       "      <td>they also have daily specials and ice cream wh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;POS&gt;&lt;CON_START&gt;they also have daily specials ...</td>\n",
       "      <td>&lt;ATTR_WORDS&gt;nan&lt;CON_START&gt;they also have daily...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it 's a good toasted hoagie .</td>\n",
       "      <td>POS</td>\n",
       "      <td>it 's a good toasted hoagie .</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;POS&gt;&lt;CON_START&gt;it 's a good toasted hoagie .&lt;...</td>\n",
       "      <td>&lt;ATTR_WORDS&gt;nan&lt;CON_START&gt;it 's a good toasted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the staff is friendly .</td>\n",
       "      <td>POS</td>\n",
       "      <td>the staff is .</td>\n",
       "      <td>friendly</td>\n",
       "      <td>hostile</td>\n",
       "      <td>&lt;POS&gt;&lt;CON_START&gt;the staff is .&lt;START&gt;the staff...</td>\n",
       "      <td>&lt;ATTR_WORDS&gt;friendly&lt;CON_START&gt;the staff is .&lt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence sentiment  \\\n",
       "0                                   excellent food .       POS   \n",
       "1                          superb customer service .       POS   \n",
       "2  they also have daily specials and ice cream wh...       POS   \n",
       "3                      it 's a good toasted hoagie .       POS   \n",
       "4                            the staff is friendly .       POS   \n",
       "\n",
       "                                                  c1         a1       r1  \\\n",
       "0                                             food .  excellent      NaN   \n",
       "1                                 customer service .     superb      NaN   \n",
       "2  they also have daily specials and ice cream wh...        NaN      NaN   \n",
       "3                      it 's a good toasted hoagie .        NaN      NaN   \n",
       "4                                     the staff is .   friendly  hostile   \n",
       "\n",
       "                                            del_sent  \\\n",
       "0  <POS><CON_START>food .<START>excellent food .<...   \n",
       "1  <POS><CON_START>customer service .<START>super...   \n",
       "2  <POS><CON_START>they also have daily specials ...   \n",
       "3  <POS><CON_START>it 's a good toasted hoagie .<...   \n",
       "4  <POS><CON_START>the staff is .<START>the staff...   \n",
       "\n",
       "                                           defr_sent  \n",
       "0  <ATTR_WORDS>excellent<CON_START>food .<START>e...  \n",
       "1  <ATTR_WORDS>superb<CON_START>customer service ...  \n",
       "2  <ATTR_WORDS>nan<CON_START>they also have daily...  \n",
       "3  <ATTR_WORDS>nan<CON_START>it 's a good toasted...  \n",
       "4  <ATTR_WORDS>friendly<CON_START>the staff is .<...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#df = pd.read_csv('../input/yelp-dgr/clean_text_unigrams_r.csv')\n",
    "df = pd.read_csv('clean_text_unigrams_r.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T02:59:37.645479Z",
     "iopub.status.busy": "2022-04-17T02:59:37.64521Z",
     "iopub.status.idle": "2022-04-17T02:59:37.735785Z",
     "shell.execute_reply": "2022-04-17T02:59:37.734913Z",
     "shell.execute_reply.started": "2022-04-17T02:59:37.645449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254591"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)#443261\n",
    "df_ = df.dropna(subset=['a1'])\n",
    "len(df_)#254591"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "POS          266042\n",
       "NEG          177219\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts(subset=['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "POS          175768\n",
       "NEG           78823\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.value_counts(subset=['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(train_ds[0]), tokenizer.decode(eval_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T02:59:46.116137Z",
     "iopub.status.busy": "2022-04-17T02:59:46.115556Z",
     "iopub.status.idle": "2022-04-17T02:59:46.259007Z",
     "shell.execute_reply": "2022-04-17T02:59:46.258233Z",
     "shell.execute_reply.started": "2022-04-17T02:59:46.116098Z"
    },
    "id": "sCCFYM7yTbIU"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "inputs = df_['del_sent'].to_list()\n",
    "y = df_['a1'].to_list()\n",
    "train_ds, eval_ds, train_attr, eval_attr = train_test_split(inputs, y, test_size=0.33, random_state=42)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T02:59:50.183188Z",
     "iopub.status.busy": "2022-04-17T02:59:50.182476Z",
     "iopub.status.idle": "2022-04-17T02:59:50.191085Z",
     "shell.execute_reply": "2022-04-17T02:59:50.190132Z",
     "shell.execute_reply.started": "2022-04-17T02:59:50.183152Z"
    }
   },
   "outputs": [],
   "source": [
    "len(train_ds)+len(eval_ds), len(df_),len(train_attr), len(eval_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T02:59:53.046243Z",
     "iopub.status.busy": "2022-04-17T02:59:53.045778Z",
     "iopub.status.idle": "2022-04-17T02:59:53.051408Z",
     "shell.execute_reply": "2022-04-17T02:59:53.050545Z",
     "shell.execute_reply.started": "2022-04-17T02:59:53.046206Z"
    },
    "id": "Aig4BbPGt-xM",
    "outputId": "4934309b-16ac-45c5-e1df-d746aab94e75"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_encode(lines):\n",
    "        '''\n",
    "        This method tokenizes the input data and encodes it using the OpenAIGPTTokenizer\n",
    "        :param file_path: Path of the input file, dtype: str\n",
    "        :return: encoded dataset  dtype: list\n",
    "        '''\n",
    "        tokenized_dataset = lines\n",
    "        for i, line in enumerate(tqdm(lines)):\n",
    "            token = tokenizer.tokenize(line)[:512]\n",
    "            tokenized_dataset[i] = tokenizer.convert_tokens_to_ids(token)\n",
    "        return tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones((2,3))\n",
    "a[1,:len([4,5])] = [4,5]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T02:59:57.875971Z",
     "iopub.status.busy": "2022-04-17T02:59:57.874952Z",
     "iopub.status.idle": "2022-04-17T03:00:44.468881Z",
     "shell.execute_reply": "2022-04-17T03:00:44.467962Z",
     "shell.execute_reply.started": "2022-04-17T02:59:57.875933Z"
    },
    "id": "ZnoMKbrxXiFL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 170575/170575 [00:27<00:00, 6274.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 84016/84016 [00:13<00:00, 6455.03it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 170575/170575 [00:07<00:00, 24148.32it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 84016/84016 [00:03<00:00, 22196.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input length  51\n",
      "input length  51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tokenize_and_encode(train_ds)\n",
    "eval_dataset = tokenize_and_encode(eval_ds)\n",
    "train_attr = tokenize_and_encode(train_attr)\n",
    "eval_attr = tokenize_and_encode(eval_attr)\n",
    "input_length = max(max(len(t) for t in train_dataset), max(len(q) for q in eval_dataset))\n",
    "print('input length ', input_length)\n",
    "input_length = min(input_length, 85)\n",
    "print('input length ', input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T03:00:44.471028Z",
     "iopub.status.busy": "2022-04-17T03:00:44.470683Z",
     "iopub.status.idle": "2022-04-17T03:00:44.482109Z",
     "shell.execute_reply": "2022-04-17T03:00:44.481162Z",
     "shell.execute_reply.started": "2022-04-17T03:00:44.470987Z"
    },
    "id": "A_qOqBVYIYaO"
   },
   "outputs": [],
   "source": [
    "def pre_process_dataset(encoded_dataset, encoded_attr, input_length, start_token_id,pad_token_id=pad_token_id):\n",
    "        \"\"\"\n",
    "        This method is to create torch tensor of input ids and lm labels\n",
    "        :param encoded_dataset: Input dataset, dtype: list\n",
    "        :param input_length: Maximum length of sentence from training and eval dataset, dtype: int\n",
    "        :param start_token_id: id of the '<START>' token, dtype: int\n",
    "        :return: torch.tensor of size [len(encoded_dataset), 2]\n",
    "        \"\"\"\n",
    "\n",
    "        n_batch = len(encoded_dataset)\n",
    "        attr_len = max([len(i) for i in encoded_attr])\n",
    "        attr = np.full(shape=(n_batch, attr_len), fill_value=pad_token_id,  dtype=np.int64)\n",
    "        input_ids = np.full(shape=(n_batch, input_length), fill_value=pad_token_id,  dtype=np.int64)\n",
    "        lm_labels = np.full(shape=(n_batch, input_length), fill_value=-100, dtype=np.int64)\n",
    "\n",
    "        for i, tokens in enumerate(encoded_dataset):\n",
    "            try:\n",
    "                #tokens = tokens[:input_length]\n",
    "                start_id_index = tokens.index(start_token_id)\n",
    "                input_ids[i, :len(tokens)] = tokens\n",
    "                start_id_index = tokens.index(start_token_id)\n",
    "                lm_labels[i, start_id_index : len(tokens)-1] = tokens[start_id_index + 1: len(tokens)]\n",
    "                attr[i, :len(encoded_attr[i])] = encoded_attr[i]\n",
    "                # LM loss calculate only for tokens after <START> token in the sentence\n",
    "                #lm_labels[i, :len(tokens)-1] = tokens[1:]\n",
    "            except ValueError:\n",
    "                print(\"Index {} doesn't have start token\".format(i))\n",
    "\n",
    "        input_ids = torch.tensor(input_ids)\n",
    "        lm_labels = torch.tensor(lm_labels)\n",
    "        attr = torch.tensor(attr)\n",
    "        tensor_dataset = (input_ids, attr, lm_labels)\n",
    "        #tensor_dataset.append(torch.tensor(d) for d in all_inputs)\n",
    "\n",
    "        return tensor_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T03:00:44.484011Z",
     "iopub.status.busy": "2022-04-17T03:00:44.483748Z",
     "iopub.status.idle": "2022-04-17T03:00:44.495595Z",
     "shell.execute_reply": "2022-04-17T03:00:44.494824Z",
     "shell.execute_reply.started": "2022-04-17T03:00:44.483974Z"
    },
    "id": "hQKOBjyWYoog"
   },
   "outputs": [],
   "source": [
    "train_batch_size = 32\n",
    "num_train_epochs = 2\n",
    "learning_rate = 6.25e-5\n",
    "warmup_proportion = 0.002\n",
    "max_grad_norm = 1\n",
    "weight_decay = 0.01\n",
    "n_gpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T03:00:44.497974Z",
     "iopub.status.busy": "2022-04-17T03:00:44.497709Z",
     "iopub.status.idle": "2022-04-17T03:00:44.504337Z",
     "shell.execute_reply": "2022-04-17T03:00:44.50353Z",
     "shell.execute_reply.started": "2022-04-17T03:00:44.49794Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T03:00:44.506228Z",
     "iopub.status.busy": "2022-04-17T03:00:44.506031Z",
     "iopub.status.idle": "2022-04-17T03:00:46.88793Z",
     "shell.execute_reply": "2022-04-17T03:00:46.887179Z",
     "shell.execute_reply.started": "2022-04-17T03:00:44.506205Z"
    },
    "id": "aIjus08-XiFT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Example Input ids= tensor([50258, 50259,    72,   326,  1312,   373, 24053,   764, 50260,    72,\n",
      "         5100,   326,  1312,   373, 24053,   764, 50261, 50262, 50262, 50262,\n",
      "        50262, 50262, 50262, 50262, 50262, 50262, 50262, 50262, 50262, 50262,\n",
      "        50262, 50262, 50262, 50262, 50262, 50262, 50262, 50262, 50262, 50262,\n",
      "        50262, 50262, 50262, 50262, 50262, 50262, 50262, 50262, 50262, 50262,\n",
      "        50262])\n",
      "Training Example attribute ids = tensor([45956,   515, 50262, 50262, 50262, 50262, 50262, 50262, 50262, 50262])\n",
      "Training Example Language Modeling ids = tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,    72,  5100,\n",
      "          326,  1312,   373, 24053,   764, 50261,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100])\n"
     ]
    }
   ],
   "source": [
    "train_tensor_dataset = pre_process_dataset(train_dataset,train_attr, input_length, start_token_id=start_token_id)\n",
    "eval_tensor_dataset = pre_process_dataset(eval_dataset, eval_attr, input_length, start_token_id=start_token_id)\n",
    "\n",
    "print(\"Training Example Input ids= {}\".format(train_tensor_dataset[0][0]))\n",
    "print(\"Training Example attribute ids = {}\".format(train_tensor_dataset[1][0]))\n",
    "print(\"Training Example Language Modeling ids = {}\".format(train_tensor_dataset[2][0]))\n",
    "\n",
    "\n",
    "train_data = TensorDataset(*train_tensor_dataset)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)\n",
    "\n",
    "eval_data = TensorDataset(*eval_tensor_dataset)\n",
    "eval_sampler = RandomSampler(eval_data)\n",
    "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=train_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3,4,5]\n",
    "h = l[:0]\n",
    "d = l[0:3]\n",
    "c = l[3:]\n",
    "print(h,d,c)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T03:00:46.889587Z",
     "iopub.status.busy": "2022-04-17T03:00:46.88937Z",
     "iopub.status.idle": "2022-04-17T03:00:46.921351Z",
     "shell.execute_reply": "2022-04-17T03:00:46.920653Z",
     "shell.execute_reply.started": "2022-04-17T03:00:46.889557Z"
    },
    "id": "If5zlgqxXiFX"
   },
   "outputs": [],
   "source": [
    "def train_cocon(train_dataset=train_dataloader, model=model, tokenizer=tokenizer, cocon_block=cocon_block):\n",
    "    t_total = len(train_dataloader) * num_train_epochs\n",
    "    \n",
    "    learning_rate = 5e-5\n",
    "    adam_epsilon = 1e-8\n",
    "    #t_total = len(train_dataloader) #// args.gradient_accumulation_steps * args.num_train_epochs\n",
    "\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    cocon_block_optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in cocon_block.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "        {\"params\": [p for n, p in cocon_block.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "        ]\n",
    "    cocon_block_optimizer = AdamW(cocon_block_optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)\n",
    "    cocon_block_scheduler = get_linear_schedule_with_warmup(\n",
    "        cocon_block_optimizer, num_warmup_steps=0, num_training_steps=t_total)\n",
    "    \n",
    "    #model, cocon_block, cocon_block_optimizer, train_dataloader = accelerator.prepare(model, cocon_block, cocon_block_optimizer, train_dataloader)\n",
    "    #cocon_block_optimizer.to(device)\n",
    "    #train_dataloader.to(device)\n",
    "    \n",
    "    \n",
    "    global_step = 0\n",
    "    epochs_trained = 0\n",
    "    steps_trained_in_current_epoch = 0\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    #total_loss = 0\n",
    "    lambda_self = 1\n",
    "    lambda_null = 1\n",
    "    lambda_cycle = 1\n",
    "    #epoch_max_steps = 10\n",
    "    #max_steps = 100\n",
    "    #hs_len = 0 \n",
    "    #cs_len = 20 \n",
    "    #tis_len = 20 \n",
    "    \n",
    "    #model.zero_grad()\n",
    "    train_iterator = trange(epochs_trained, num_train_epochs, desc=\"Epoch\")\n",
    "    for epoch_ind in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            \n",
    "            inputs, content, lm_labels = batch\n",
    "            #print(inputs.shape, content.shape, lm_labels.shape)\n",
    "            \n",
    "            #if(inputs.shape[1]<hs_len):\n",
    "            #    continue\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            lm_labels = lm_labels.to(device)\n",
    "            content = content.to(device)\n",
    "\n",
    "            #hs_tis_split_ind = random.randint(0,2)\n",
    "            #hs_len = 10 + hs_tis_split_ind\n",
    "            #cs_len = 20 - hs_tis_split_ind\n",
    "            #tis_len = 20 - hs_tis_split_ind\n",
    "            \n",
    "            #lm_labels = lm_labels[:, :hs_len+tis_len]\n",
    "            #original_context_seq = inputs[:, hs_len:hs_len+cs_len]\n",
    "            #original_history_seq = inputs[:, :hs_len]\n",
    "            #original_transform_input_seq = inputs[:, hs_len:hs_len+tis_len]\n",
    "            \n",
    "            #other_sample_inputs = torch.cat([inputs[-1:], inputs[:-1]], dim=0)\n",
    "            #other_sample_lm_labels = other_sample_inputs[:, :hs_len+tis_len]\n",
    "\n",
    "            #other_sample_context_seq = other_sample_inputs[:, hs_len:hs_len+cs_len]\n",
    "            #other_sample_history_seq = other_sample_inputs[:, :hs_len]\n",
    "            #other_sample_transform_input_seq = other_sample_inputs[:, hs_len:hs_len+tis_len]\n",
    "            \n",
    "            #model.eval()\n",
    "            #cocon_block.train()\n",
    "            model.zero_grad()\n",
    "            cocon_block.zero_grad()\n",
    "            \n",
    "            #SELF LOSS -> Modified to sentiment loss\n",
    "            #forward pass L_alpha(entire_input) #NO AR\n",
    "            #forward pass L_alpha(original_content)\n",
    "            with torch.no_grad():\n",
    "                hidden_states = model(inputs, output_after_block_ind=5)[0] \n",
    "                context_seq_hidden_states =  model(content, output_after_block_ind=5)[0] \n",
    "           \n",
    "            original_hidden_states = hidden_states.to(device)\n",
    "            #print(original_hidden_states.shape)\n",
    "            #original_history_seq_hidden_states = original_hidden_states[:, :hs_len].to(device)\n",
    "            #original_transform_input_seq_hidden_states = original_hidden_states[:, hs_len:hs_len+tis_len].to(device)\n",
    "            original_context_seq_hidden_states = context_seq_hidden_states.to(device)\n",
    "            #print(original_context_seq_hidden_states.shape)\n",
    "    \n",
    "            #other_sample_hidden_states = torch.cat([hidden_states[-1:], hidden_states[:-1]], dim=0).to(device)\n",
    "            #other_sample_history_seq_hidden_states = other_sample_hidden_states[:, :hs_len].to(device)\n",
    "            #other_sample_transform_input_seq_hidden_states = other_sample_hidden_states[:, hs_len:hs_len+tis_len].to(device)\n",
    "    \n",
    "            #other_sample_context_seq_hidden_states = torch.cat([context_seq_hidden_states[-1:], context_seq_hidden_states[:-1]], dim=0).to(device)\n",
    "            \n",
    "            #Cocon(input_hidden, content_hidden, history_hidden) #ROLE of history in cocon = concats to input\n",
    "            self_cocon_hidden_states = cocon_block(original_hidden_states, \n",
    "                                       context_seq=original_context_seq_hidden_states, \n",
    "                                       include_sos_output=True, cs_self_attn_mask_prob=1)\n",
    "            \n",
    "            #print('C: ',self_cocon_hidden_states.shape)\n",
    "            \n",
    "            #self_cocon_hidden_states = cocon_block(original_context_seq_hidden_states, \n",
    "                                       #include_sos_output=True, cs_self_attn_mask_prob=0)\n",
    "            \n",
    "            #print('C: ',self_cocon_hidden_states.shape)\n",
    "\n",
    "            \n",
    "            #self_cocon_lm_tail_input = torch.cat([original_hidden_states[:, :-1], self_cocon_hidden_states], dim=1).to(device)\n",
    "            #print('MUST MATCH LM LABELS: ',self_cocon_hidden_states.shape)\n",
    "            #print(lm_labels.shape)\n",
    "\n",
    "            # Ignore history when computing loss\n",
    "            #lm_logit_first_index = original_history_seq_hidden_states.shape[1] -1\n",
    "            #lm_labels_first_index = lm_logit_first_index + 1\n",
    "            \n",
    "            #L_beta([original_history_hidden + cocon_hidden])\n",
    "            self_cocon_lm_tail_outputs = model(input_hidden_state=self_cocon_hidden_states, \n",
    "                                               labels=lm_labels, lm_logit_first_index=0, \n",
    "                                               lm_labels_first_index=0, \n",
    "                                               input_before_block_ind=5+1)\n",
    "                        \n",
    "            #self_cocon_lm_tail_outputs[0][1] == self_cocon_lm_tail_outputs[1]\n",
    "            #next_token_logits = self_cocon_lm_tail_outputs[1]  # [N,L,C] where C is vocab_size\n",
    "            #if next_token_logits.shape[1] > 1:\n",
    "            #    next_token_logits = next_token_logits[:, -1:]\n",
    "            #next_cocon_output_prob = torch.nn.functional.softmax(next_token_logits, dim=-1)\n",
    "            \n",
    "            self_cocon_lm_loss = self_cocon_lm_tail_outputs[0] #SELF LOSS\n",
    "            total_loss = lambda_self * self_cocon_lm_loss\n",
    "            \n",
    "            #NULL LOSS ->modified to target sentiment\n",
    "            #L_alpha for input already done above\n",
    "            #L_alpha for content not req as null\n",
    "            #Cocon block [input_hidden, history]\n",
    "            #with torch.no_grad():\n",
    "            #    context_seq_hidden_states_null = model(target, path='half1')\n",
    "            #    context_seq_hidden_states_null = context_seq_hidden_states_null.to(device)\n",
    "\n",
    "            null_cocon_hidden_states = cocon_block(original_hidden_states, \n",
    "                                       context_seq=None,\n",
    "                                       include_sos_output=True)#, cs_self_attn_mask_prob=1- not req as noncontet to copy from\n",
    "            \n",
    "            #null_cocon_lm_tail_input = null_cocon_hidden_states\n",
    "\n",
    "            # Ignore history when computing loss - same as self\n",
    "            #lm_logit_first_index = original_history_seq_hidden_states.shape[1] -1\n",
    "            #lm_labels_first_index = lm_logit_first_index + 1\n",
    "            \n",
    "            #L_beta([original_history_hidden + cocon_hidden])\n",
    "            null_cocon_lm_tail_outputs = model(input_hidden_state=null_cocon_hidden_states, labels=lm_labels, \n",
    "                                               lm_logit_first_index=0, \n",
    "                                               lm_labels_first_index=0, \n",
    "                                               input_before_block_ind=5+1)\n",
    "            #self_cocon_lm_tail_outputs[0][1] == self_cocon_lm_tail_outputs[1]\n",
    "            #next_token_logits = self_cocon_lm_tail_outputs[1]  # [N,L,C] where C is vocab_size\n",
    "            #if next_token_logits.shape[1] > 1:\n",
    "            #    next_token_logits = next_token_logits[:, -1:]\n",
    "            #next_cocon_output_prob = torch.nn.functional.softmax(next_token_logits, dim=-1)\n",
    "            \n",
    "            null_cocon_lm_loss = null_cocon_lm_tail_outputs[0] #SELF LOSS\n",
    "            total_loss += lambda_null * null_cocon_lm_loss\n",
    "\n",
    "            cur_len = 0\n",
    "\n",
    "            \"\"\"\n",
    "            #CYCLE LOSS\n",
    "            #step1 : [other history, original content] -> compute mixed output\n",
    "            #Done AR so start with input=None\n",
    "             \n",
    "            cocon_block_output = None\n",
    "            cocon_th_gen_output = None \n",
    "            cocon_th_gen_input = None #[same as output but detatched]\n",
    "            cocon_output_embed = None #[used as content for step 2, instead of converting to token and back to hidden]\n",
    "\n",
    "            lm_tail_past = False #To indicate if consider entire embeding or only last one\n",
    "            lm_head_past = False #same as above\n",
    "            max_ar_len = original_transform_input_seq_hidden_states.shape[1]#20\n",
    "            \n",
    "            other_sample_history_seq_one_hot_prob = to_one_hot(other_sample_history_seq, n_dims=config.vocab_size).to(device)\n",
    "            other_sample_history_seq_embeds = torch.matmul(other_sample_history_seq_one_hot_prob, model.wte.weight).to(device)\n",
    "            \n",
    "            #Start auto regressive generation\n",
    "            while cur_len < max_ar_len:\n",
    "                #skipping L_alpha as we already have hidden states from previous computations\n",
    "                cocon_transformed_hidden_states = cocon_block(cocon_th_gen_input, context_seq=original_context_seq_hidden_states, history_seq=other_sample_history_seq_hidden_states, include_sos_output=True, cs_self_attn_mask_prob=1)\n",
    "                if cur_len == 0:\n",
    "                    cocon_block_output = cocon_transformed_hidden_states[:, -1:] #Consider last token as output\n",
    "                else:\n",
    "                    cocon_block_output = torch.cat([cocon_block_output, cocon_transformed_hidden_states[:,-1:]], dim=1)\n",
    "                \n",
    "                #\n",
    "                if cocon_th_gen_input is not None:\n",
    "                    hist_plus_cocon_hidden_states = torch.cat([other_sample_history_seq_hidden_states, cocon_th_gen_input[:, :-1], cocon_transformed_hidden_states[:, -1:]], dim=1)\n",
    "                else:\n",
    "                    hist_plus_cocon_hidden_states = torch.cat([other_sample_history_seq_hidden_states[:, :-1], cocon_transformed_hidden_states[:, -1:]], dim=1)\n",
    "                    \n",
    "                if(lm_tail_past):\n",
    "                    lm_tail_inputs = hist_plus_cocon_hidden_states[:, -1:, :].to(device)\n",
    "                else:\n",
    "                    lm_tail_inputs = hist_plus_cocon_hidden_states.to(device)\n",
    "                    \n",
    "                tail_outputs = model(lm_tail_inputs,path='half2')\n",
    "                next_token_logits = tail_outputs[1]  # [N,L,C] where C is vocab_size\n",
    "                if next_token_logits.shape[1] > 1:\n",
    "                    next_token_logits = next_token_logits[:, -1:]\n",
    "                lm_tail_past = True\n",
    "                next_cocon_output_prob = torch.nn.functional.softmax(next_token_logits, dim=-1)\n",
    "                next_cocon_output_embed = torch.matmul(next_cocon_output_prob, model.wte.weight).to(device)\n",
    "                if cur_len==0:\n",
    "                    cocon_output_embeds = next_cocon_output_embed.to(device)\n",
    "                    hist_plus_cocon_output_embeds = torch.cat([other_sample_history_seq_embeds, next_cocon_output_embed], dim=1).to(device)\n",
    "                else:\n",
    "                    cocon_output_embeds = torch.cat([cocon_output_embeds, next_cocon_output_embed], dim=1).to(device)\n",
    "                    hist_plus_cocon_output_embeds = torch.cat([hist_plus_cocon_output_embeds, next_cocon_output_embed], dim=1).to(device)\n",
    "                    \n",
    "                if(lm_head_past):\n",
    "                    lm_head_inputs = hist_plus_cocon_output_embeds[:, -1:, :].to(device)\n",
    "                else:\n",
    "                    lm_head_inputs = hist_plus_cocon_output_embeds.to(device)\n",
    "                    \n",
    "                head_outputs = model(lm_head_inputs, inputs_embeds=True)\n",
    "                cocon_gen_output_h = head_outputs[0][1] #tail_outputs[0][1].shape\n",
    "                if cocon_gen_output_h.shape[1] > 1:\n",
    "                    next_h = cocon_gen_output_h[:, -1:]\n",
    "                else:\n",
    "                    next_h = cocon_gen_output_h\n",
    "                lm_head_past = True\n",
    "                    \n",
    "                    \n",
    "                h_to_cat_input = next_h.detach()\n",
    "                if(cur_len ==0):\n",
    "                    cocon_th_gen_input = h_to_cat_input.to(device)\n",
    "                    cocon_th_gen_output = next_h.to(device)\n",
    "                else:\n",
    "                    cocon_th_gen_input = torch.cat([cocon_th_gen_input, h_to_cat_input], dim=1).to(device)\n",
    "                    cocon_th_gen_output = torch.cat([cocon_th_gen_output, next_h], dim=1).to(device)\n",
    "                \n",
    "                cur_len = cocon_th_gen_input.shape[1]\n",
    "            \n",
    "            #Completed AR generation \n",
    "            ar_cocon_final_output_embeds = cocon_output_embeds\n",
    "            \n",
    "            #STEP 1 - other history, original content = mixed\n",
    "            other_context_cocon_hidden_states = cocon_block(cocon_th_gen_output, context_seq=original_context_seq_hidden_states, history_seq=other_sample_history_seq_hidden_states, include_sos_output=True,cs_self_attn_mask_prob=1)\n",
    "            other_context_cocon_lm_tail_input = torch.cat([other_sample_history_seq_hidden_states[:, :-1], other_context_cocon_hidden_states], dim=1)\n",
    "            lm_logit_first_index = other_sample_history_seq_hidden_states.shape[1] -1\n",
    "            lm_labels_first_index = lm_logit_first_index + 1\n",
    "            \n",
    "            other_context_cocon_lm_tail_outputs = model(other_context_cocon_lm_tail_input, labels=other_sample_lm_labels, lm_logit_first_index=lm_logit_first_index, lm_labels_first_index=lm_labels_first_index, path='half2')\n",
    "            other_contex_cocon_lm_loss = other_context_cocon_lm_tail_outputs[0][0]\n",
    "            total_loss += other_contex_cocon_lm_loss * lambda_cycle\n",
    "            \n",
    "            \n",
    "            #STEP2 - original history, mixed content = original content\n",
    "            #to get mixed content we use the embedding directly to get hidden state instead of starting from tokens\n",
    "            ar_cocon_output_hidden_states = model(ar_cocon_final_output_embeds, inputs_embeds=True, path='half1')\n",
    "            #cocon - [original_transformed, mixed_content, original_history]\n",
    "            cycle_ar_cocon_recon_hidden_states = cocon_block(original_transform_input_seq_hidden_states, context_seq=ar_cocon_output_hidden_states, history_seq=original_history_seq_hidden_states, include_sos_output=True, cs_self_attn_mask_prob=1)\n",
    "            #update history to include cocon output\n",
    "            cycle_ar_cocon_recon_lm_tail_input = torch.cat([original_history_seq_hidden_states[:, :-1], cycle_ar_cocon_recon_hidden_states], dim=1)\n",
    "            #index after history\n",
    "            lm_logit_first_index = original_history_seq_hidden_states.shape[1] -1\n",
    "            #L_beta prediction\n",
    "            cycle_ar_cocon_recon_lm_tail_outputs = model(cycle_ar_cocon_recon_lm_tail_input, labels=lm_labels, lm_logit_first_index=lm_logit_first_index, lm_labels_first_index=lm_labels_first_index, path='half2')\n",
    "            \n",
    "            cycle_ar_cocon_recon_lm_loss = cycle_ar_cocon_recon_lm_tail_outputs[0][0]\n",
    "            total_loss += cycle_ar_cocon_recon_lm_loss * lambda_cycle\n",
    "            \"\"\"\n",
    "            \n",
    "            total_loss.backward()\n",
    "            #accelerator.backward(total_loss)\n",
    "        \n",
    "            tr_loss += total_loss.item()\n",
    "\n",
    "            #eval_loss, perplexity = evaluate()\n",
    "        \n",
    "            if (step + 1) % 100 == 0: \n",
    "                #ADD validation , bleue TODO\n",
    "                print(\"loss: \", tr_loss/(step+1))\n",
    "                torch.nn.utils.clip_grad_norm_(cocon_block.parameters(), 1)\n",
    "                cocon_block_optimizer.step() # opt.step() does not zero_grad, need to zero.grad() manually\n",
    "                cocon_block_scheduler.step() # Update learning rate schedule \n",
    "                torch.save({\n",
    "                          'epoch': epoch_ind,\n",
    "                          'model_state_dict': cocon_block.state_dict(),\n",
    "                          'optimizer_state_dict': cocon_block_optimizer.state_dict(),\n",
    "                          'loss': tr_loss,\n",
    "                          'step': step}, 'modified.tar')\n",
    "                \n",
    "                cocon_block.zero_grad()\n",
    "                model.zero_grad()\n",
    "            \n",
    "            global_step +=1\n",
    "            #if(step> epoch_max_steps or global_step>max_steps):\n",
    "             #   epoch_iterator.close()\n",
    "             #   break\n",
    "        #if(global_step>max_steps):\n",
    "        #    train_iterator.close()\n",
    "        #    break\n",
    "    return global_step, tr_loss/global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T06:39:35.034249Z",
     "iopub.status.busy": "2022-04-17T06:39:35.033999Z",
     "iopub.status.idle": "2022-04-17T07:29:23.937649Z",
     "shell.execute_reply": "2022-04-17T07:29:23.936818Z",
     "shell.execute_reply.started": "2022-04-17T06:39:35.034221Z"
    },
    "id": "me9haAjgXiFZ",
    "outputId": "e44a5262-aa2d-4a1f-8554-7cb6f1bc90b6"
   },
   "outputs": [],
   "source": [
    "global_step, tr_loss = train_cocon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "51*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T07:29:23.940618Z",
     "iopub.status.busy": "2022-04-17T07:29:23.939763Z",
     "iopub.status.idle": "2022-04-17T07:29:23.946710Z",
     "shell.execute_reply": "2022-04-17T07:29:23.946011Z",
     "shell.execute_reply.started": "2022-04-17T07:29:23.940580Z"
    },
    "id": "mdBh0Wn4XiFa",
    "outputId": "5973608f-caa2-46b9-80fb-43e8bb75ec2c"
   },
   "outputs": [],
   "source": [
    "global_step, tr_loss #2 epochs = (10662, 20.512922179115307)\n",
    "#4 epochs (10662, 10.538968369518473)\n",
    "# 6 epochs (10662, 9.399290811856767)\n",
    "#8 epochs (10662, 8.746620702734585)\n",
    "#10 epochs (10662, 8.746620702734585)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GoldjeHuUrdf"
   },
   "outputs": [],
   "source": [
    "#1 epoch =30min\n",
    "#model saved every 100 steps = 5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T07:29:23.948747Z",
     "iopub.status.busy": "2022-04-17T07:29:23.948053Z",
     "iopub.status.idle": "2022-04-17T07:29:24.021175Z",
     "shell.execute_reply": "2022-04-17T07:29:24.020427Z",
     "shell.execute_reply.started": "2022-04-17T07:29:23.948707Z"
    },
    "id": "MzZi3Dg09Ldl"
   },
   "outputs": [],
   "source": [
    "torch.save(cocon_block.state_dict(),'cocon_dgr_5.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OhmRATlNMWhK"
   },
   "outputs": [],
   "source": [
    "model = TheModelClass(*args, **kwargs)\n",
    "optimizer = TheOptimizerClass(*args, **kwargs)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_token_id = tokenizer.convert_tokens_to_ids(['<END>'])[0]\n",
    "pad_token_id = tokenizer.convert_tokens_to_ids(['<PAD>'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "uZVfyHS3XiFb"
   },
   "outputs": [],
   "source": [
    "def preditction_with_beam_search(ref_text, content=None,beam_width=3, max_len=30,vocab_length=40483, end_token_id=end_token_id ):\n",
    "    \"\"\"\n",
    "    This function decodes sentences using Beam Seach. \n",
    "    It will output #sentences = beam_width. This function works on a single example.\n",
    "    \n",
    "    ref_text : string : Input sentence\n",
    "    beam_width : int : Width of the output beam\n",
    "    vocab_length : int : Size of the Vocab after adding the special tokens\n",
    "    \"\"\"\n",
    "    \n",
    "    done = [False for i in range(beam_width)] # To track which beams are already decoded\n",
    "    stop_decode = False\n",
    "    decoded_sentences=[] # List of decoded sentences at any given time\n",
    "    \n",
    "    sm = torch.nn.Softmax(dim=-1) # To calculate Softmax over the final layer Logits\n",
    "    tokens = tokenizer.tokenize(ref_text) # Tokenize the input text\n",
    "    if(content is not None):\n",
    "        content_tokens =  tokenizer.tokenize(content)\n",
    "        content_indexed_tokens = tokenizer.convert_tokens_to_ids(content_tokens)\n",
    "        content_index_tokens = [content_indexed_tokens for i in range(beam_width)]\n",
    "        content_torch_tensor = torch.tensor(content_index_tokens).to(device)\n",
    "    \n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokens) # Convert tokens to ids\n",
    "    index_tokens = [indexed_tokens for i in range(beam_width)] # Replication of Input ids for all the beams\n",
    "\n",
    "    #index_tokens = [indexed_tokens for i in range(beam_width)]\n",
    "    torch_tensor = torch.tensor(index_tokens).to(device)\n",
    "    beam_indexes = [[] for i in range(beam_width)] # indexes of the current decoded beams\n",
    "    best_scoes = [0 for i in range(beam_width)] # A list of lists to store Probability values of each decoded token of best beams\n",
    "    count = 0\n",
    "    while count < max_len and not stop_decode:\n",
    "        if count == 0: # For the first step when only one sentence is availabe\n",
    "            with torch.no_grad():\n",
    "                # Calculate output probability distribution over the Vocab,\n",
    "                hidden_states = model(torch_tensor, output_after_block_ind=5)[0] \n",
    "                if(content is not None):\n",
    "                    context_seq_hidden_states =  model(content_torch_tensor, output_after_block_ind=5)[0] \n",
    "                else:\n",
    "                    context_seq_hidden_states = None\n",
    "           \n",
    "                original_hidden_states = hidden_states.to(device)\n",
    "                original_context_seq_hidden_states = context_seq_hidden_states.to(device)\n",
    "                \n",
    "                self_cocon_hidden_states = cocon_block(original_hidden_states, \n",
    "                                       context_seq=original_context_seq_hidden_states, \n",
    "                                       include_sos_output=True, cs_self_attn_mask_prob=0)\n",
    "        \n",
    "                self_cocon_lm_tail_outputs = model(input_hidden_state=self_cocon_hidden_states,lm_logit_first_index=0, \n",
    "                                               lm_labels_first_index=0, \n",
    "                                               input_before_block_ind=5+1)\n",
    "            \n",
    "            #print(self_cocon_lm_tail_outputs[0].shape,self_cocon_lm_tail_outputs[1].shape)\n",
    "                #output = model(torch_tensor)\n",
    "                preds = sm(self_cocon_lm_tail_outputs[0]) #  shape = [beam_bidth, len(input_sen)+1,Vocab_length]\n",
    "            top_v, top_i = preds[:,-1,:].topk(beam_width) # Fatch top indexes and it's values\n",
    "            [beam_indexes[i].append(top_i[0][i].tolist()) for i in range(beam_width)] # Update the Beam indexes\n",
    "            # Update the best_scores, for first time just add the topk values directly\n",
    "            for i in range(beam_width):\n",
    "                best_scoes[i] = top_v[0][i].item()\n",
    "            count += 1\n",
    "        else: # After first step\n",
    "            # Prepare the current_state by concating original input and decoded beam indexes\n",
    "            current_state = torch.cat((torch_tensor, torch.tensor(beam_indexes).to(device)), dim=1)\n",
    "            # Prediction on the current state\n",
    "            with torch.no_grad():\n",
    "                hidden_states = model(current_state, output_after_block_ind=5)[0] \n",
    "                #if(content is not None):\n",
    "                 #   context_seq_hidden_states =  model(content_torch_tensor, output_after_block_ind=5)[0] \n",
    "                #else:\n",
    "                #    context_seq_hidden_states = None\n",
    "           \n",
    "                original_hidden_states = hidden_states.to(device)\n",
    "                #original_context_seq_hidden_states = context_seq_hidden_states.to(device)\n",
    "                \n",
    "                self_cocon_hidden_states = cocon_block(original_hidden_states, \n",
    "                                       context_seq=original_context_seq_hidden_states, \n",
    "                                       include_sos_output=True, cs_self_attn_mask_prob=0)\n",
    "        \n",
    "                self_cocon_lm_tail_outputs = model(input_hidden_state=self_cocon_hidden_states,lm_logit_first_index=0, \n",
    "                                               lm_labels_first_index=0, \n",
    "                                               input_before_block_ind=5+1)\n",
    "                \n",
    "                \n",
    "                #outputs = model(current_state)\n",
    "                preds = sm(self_cocon_lm_tail_outputs[0])\n",
    "            # Multiply new probability predictions with corresponding best scores\n",
    "            # Total socres = beam_width * Vocab_Size\n",
    "            flatten_score = (preds[:,-1,:]*torch.tensor(best_scoes).to(device).unsqueeze(1)).view(-1)\n",
    "            # Fatch the top scores and indexes \n",
    "            vals, inx = flatten_score.topk(beam_width)\n",
    "            # best_score_inx saves the index of best beams after multiplying the probability of new prediction\n",
    "            best_scoes_inx = (inx / vocab_length).tolist()\n",
    "            best_scoes = vals.tolist()\n",
    "            # Unflatten the index \n",
    "            correct_inx = (inx % vocab_length).tolist()\n",
    "            \n",
    "            # Check if done for all the Beams\n",
    "            for i in range(beam_width):\n",
    "                if correct_inx[i] == end_token_id:\n",
    "                    done[i] = True\n",
    "            # Update the best score for each the current Beams\n",
    "            for i in range(beam_width):\n",
    "                if not done[i]:\n",
    "                    best_scoes[i] = vals.tolist()[i]\n",
    "            # Check is All the Beams are Done\n",
    "            if (sum(done) == beam_width):\n",
    "                stop_decode = True\n",
    "            # Prepapre the new beams\n",
    "            temp_lt=[0 for i in range(beam_width)]\n",
    "            for i,x in enumerate(best_scoes_inx):\n",
    "                temp_lt[i] = beam_indexes[i] + [correct_inx[i]]\n",
    "            # Update the Beam indexes\n",
    "            beam_indexes = temp_lt\n",
    "            del temp_lt\n",
    "            count += 1\n",
    "    # Decode All the beam indexes to till <END> token only and convert into sentence\n",
    "    for i in range(beam_width):\n",
    "        try:\n",
    "            end_index = beam_indexes[i].index(end_token_id )\n",
    "        except ValueError:\n",
    "            end_index = len(beam_indexes[i])\n",
    "            \n",
    "        decoded_sentences.append(tokenizer.decode(beam_indexes[i][:end_index]))\n",
    "        \n",
    "    return decoded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gpt(inp,cont,gen_len=30):\n",
    "    input_token = torch.tensor(tokenizer.encode(inp))\n",
    "    content_token = torch.tensor(tokenizer.encode(cont))\n",
    "    if(len(input_token.shape)<3):\n",
    "        input_token = input_token.unsqueeze(0) #batch dim\n",
    "        content_token = content_token.unsqueeze(0) #batch dim\n",
    "\n",
    "    #Repeat for history TO DO\n",
    "    #implement auto regression TODO\n",
    "    input_token = input_token.to(device)\n",
    "    content_token = content_token.to(device)\n",
    "    l = len(input_token[0])\n",
    "    for i in range(gen_len):\n",
    "        #L_alpha\n",
    "        with torch.no_grad():\n",
    "            hidden_inp = model(input_token, output_after_block_ind=5)[0] \n",
    "            hidden_content = model(content_token, output_after_block_ind=5)[0] \n",
    "            #Cocon             other_context_cocon_hidden_states = cocon_block(cocon_th_gen_output, context_seq=original_context_seq_hidden_states, history_seq=other_sample_history_seq_hidden_states, include_sos_output=True,cs_self_attn_mask_prob=1)\n",
    "            cout = cocon_block(hidden_inp, context_seq=hidden_content)\n",
    "            output = model(input_hidden_state=cout,lm_logit_first_index=0, \n",
    "                                               lm_labels_first_index=0, \n",
    "                                               input_before_block_ind=5+1)\n",
    "            pred_token_logits = output[0][:,-1:] \n",
    "        #softmax\n",
    "        pred_token_prob = torch.nn.functional.softmax(pred_token_logits, dim=-1)#[:,-1,:]\n",
    "        #sample\n",
    "        pred_token = torch.multinomial(pred_token_prob[0], num_samples=1) #repeat for every elem in batch\n",
    "        #append\n",
    "        input_token = torch.cat((input_token,pred_token),1)\n",
    "        #decode\n",
    "    #pred_text = tokenizer.decode(input_token)\n",
    "    return input_token, [tokenizer.decode(i) for i in input_token[:,l:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   0%|                                                                              | 0/2626 [01:20<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>gold</th>\n",
       "      <th>content</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred_mp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;POS&gt; &lt;CON_START&gt; i recommend checking this pl...</td>\n",
       "      <td>i highly recommend checking this place out.</td>\n",
       "      <td>highly</td>\n",
       "      <td>.always actors fog fog. fog. fog.</td>\n",
       "      <td>always proposal great actors. fogalways actor...</td>\n",
       "      <td>small definitely. fantastic.always.they recom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  <POS> <CON_START> i recommend checking this pl...   \n",
       "\n",
       "                                          gold content  \\\n",
       "0  i highly recommend checking this place out.  highly   \n",
       "\n",
       "                               pred1  \\\n",
       "0  .always actors fog fog. fog. fog.   \n",
       "\n",
       "                                               pred2  \\\n",
       "0   always proposal great actors. fogalways actor...   \n",
       "\n",
       "                                             pred_mp  \n",
       "0   small definitely. fantastic.always.they recom...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt2_cocon = pd.DataFrame()\n",
    "inpu = []\n",
    "outp = []\n",
    "conp = []\n",
    "outs1 = []\n",
    "outs2 = []\n",
    "outs_mp = []\n",
    "\n",
    "epoch_iterator = tqdm(eval_dataloader, desc=\"Iteration\")\n",
    "for step, batch in enumerate(epoch_iterator):\n",
    "    inputs, content, lm_labels = batch\n",
    "    input_ids = inputs.to(device)\n",
    "    lm_labels = lm_labels.to(device)\n",
    "    content = content.to(device)\n",
    "    for i in range(len(input_ids)):\n",
    "        #print(tokenizer.decode(input_ids[i]))\n",
    "        b = input_ids[i]==start_token_id\n",
    "        indices = b.nonzero()[0][0]\n",
    "        input_ = input_ids[i][:indices + 1]\n",
    "        \n",
    "        b = input_ids[i]==end_token_id\n",
    "        indices_end = b.nonzero()[0][0]\n",
    "        \n",
    "        target = tokenizer.decode(input_ids[i][indices + 1:indices_end])\n",
    "        #print(tokenizer.decode(input_))\n",
    "        input_ = tokenizer.decode(input_)\n",
    "        \n",
    "        b = content[i]==pad_token_id\n",
    "        indices = b.nonzero()[0][0]\n",
    "        content_ = content[i][:indices]\n",
    "        \n",
    "        content_ = tokenizer.decode(content_)\n",
    "        #inpu.append(input_)\n",
    "        #outp.append(target)\n",
    "        inpu.append(input_)\n",
    "        outp.append(target)\n",
    "        conp.append(content_)\n",
    "        op=preditction_with_beam_search(input_,content_,2, 10)\n",
    "        outs1.append(op[0])\n",
    "        outs2.append(op[1])\n",
    "        op = generate_gpt(input_,content_,gen_len=10)\n",
    "        outs_mp.append(op[1][0])\n",
    "    break\n",
    "    \n",
    "df_gpt2_cocon['input'] = inpu\n",
    "df_gpt2_cocon['gold'] = outp\n",
    "df_gpt2_cocon['content'] = conp\n",
    "df_gpt2_cocon['pred1'] = outs1\n",
    "df_gpt2_cocon['pred2'] = outs2\n",
    "df_gpt2_cocon['pred_mp'] = outs_mp\n",
    "    \n",
    "df_gpt2_cocon.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>gold</th>\n",
       "      <th>content</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred_mp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;POS&gt; &lt;CON_START&gt; i recommend checking this pl...</td>\n",
       "      <td>i highly recommend checking this place out.</td>\n",
       "      <td>highly</td>\n",
       "      <td>.always actors fog fog. fog. fog.</td>\n",
       "      <td>always proposal great actors. fogalways actor...</td>\n",
       "      <td>small definitely. fantastic.always.they recom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;NEG&gt; &lt;CON_START&gt; not only is there pizza, but...</td>\n",
       "      <td>not only is there pizza bad, but their custome...</td>\n",
       "      <td>bad horrible</td>\n",
       "      <td>.ues.always actors fog. actors. actors</td>\n",
       "      <td>alwaysalways actorsgreat. great actorsalways ...</td>\n",
       "      <td>.again.wrong always too rude always.att</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;POS&gt; &lt;CON_START&gt; cool tram that has views goi...</td>\n",
       "      <td>cool tram that has great views going up or dow...</td>\n",
       "      <td>great</td>\n",
       "      <td>always actors actors actors actors actors Kur...</td>\n",
       "      <td>love great always always fog always actors Ku...</td>\n",
       "      <td>owned awesome.keep no months.cious best love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;POS&gt; &lt;CON_START&gt; she was! &lt;START&gt;</td>\n",
       "      <td>she was fantastic!</td>\n",
       "      <td>fantastic</td>\n",
       "      <td>always!always! adulthood always actors adulth...</td>\n",
       "      <td>love. travel.always removing. travel..</td>\n",
       "      <td>spot! delicious always great &lt;END&gt;  excellent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;NEG&gt; &lt;CON_START&gt; however the food - oh the fo...</td>\n",
       "      <td>however the food - oh the food : ( - i was dis...</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>always. actors actors great. actors actors.al...</td>\n",
       "      <td>. Portlandalways.. Portlandalways.! always</td>\n",
       "      <td>unfortunately.best.worst.always. awful.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  <POS> <CON_START> i recommend checking this pl...   \n",
       "1  <NEG> <CON_START> not only is there pizza, but...   \n",
       "2  <POS> <CON_START> cool tram that has views goi...   \n",
       "3                 <POS> <CON_START> she was! <START>   \n",
       "4  <NEG> <CON_START> however the food - oh the fo...   \n",
       "\n",
       "                                                gold       content  \\\n",
       "0        i highly recommend checking this place out.        highly   \n",
       "1  not only is there pizza bad, but their custome...  bad horrible   \n",
       "2  cool tram that has great views going up or dow...         great   \n",
       "3                                 she was fantastic!     fantastic   \n",
       "4  however the food - oh the food : ( - i was dis...  disappointed   \n",
       "\n",
       "                                               pred1  \\\n",
       "0                  .always actors fog fog. fog. fog.   \n",
       "1             .ues.always actors fog. actors. actors   \n",
       "2   always actors actors actors actors actors Kur...   \n",
       "3   always!always! adulthood always actors adulth...   \n",
       "4   always. actors actors great. actors actors.al...   \n",
       "\n",
       "                                               pred2  \\\n",
       "0   always proposal great actors. fogalways actor...   \n",
       "1   alwaysalways actorsgreat. great actorsalways ...   \n",
       "2   love great always always fog always actors Ku...   \n",
       "3             love. travel.always removing. travel..   \n",
       "4         . Portlandalways.. Portlandalways.! always   \n",
       "\n",
       "                                             pred_mp  \n",
       "0   small definitely. fantastic.always.they recom...  \n",
       "1            .again.wrong always too rude always.att  \n",
       "2       owned awesome.keep no months.cious best love  \n",
       "3   spot! delicious always great <END>  excellent...  \n",
       "4            unfortunately.best.worst.always. awful.  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt2_cocon.to_csv('yelp_models/cocon_gpt_preds.csv', index=False)\n",
    "df_gpt2_cocon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#both loaded pretrained\n",
    "<POS> <CON_START> rolls are. <START>\n",
    "great\n",
    "rolls are great.\n",
    "[' love. actors always actors actors fog. fog fog', ' always removingalways great great fog great fog always.']\n",
    "---------------------------------------\n",
    "Iteration:   0%|                                                                              | 0/2626 [00:02<?, ?it/s]\n",
    "[' love and treats are.oved. knowledgeable always.']\n",
    "\n",
    "\n",
    "<POS> <CON_START> the place is clean and nice and the worker are very. <START>\n",
    "friendly\n",
    "the place is clean and nice and the worker are very friendly.\n",
    "[' always.always.always. always. actors actors', '. greatgreat functionalitygreat functionality recommended actorsalways always']\n",
    "---------------------------------------\n",
    "Iteration:   0%|                                                                              | 0/2626 [00:02<?, ?it/s]\n",
    "[' always.actually best.always. very.aza']\n",
    "\n",
    "#try cocon with trained gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 \n",
    "<POS> <CON_START> both went. <START>\n",
    "perfectly\n",
    "both went perfectly.\n",
    "Iteration:   0%|                                                                              | 0/2626 [00:01<?, ?it/s]\n",
    "['<CON_START> <CON_START> <CON_START> <END> <START> <START> <PAD> <START> <PAD> <CON_START>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "<POS> <CON_START> i this place! <START>\n",
    "love\n",
    "i love this place!\n",
    "Iteration:   0%|                                                                              | 0/2626 [00:01<?, ?it/s]\n",
    "[' was my <START>  I it to <START>  staff <CON_START>  five']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 12, 14, 64])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op[1][5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = torch.nn.Softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 14, 50263])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm(op[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_iterator = tqdm(eval_dataloader, desc=\"Iteration\")\n",
    "for step, batch in enumerate(epoch_iterator):\n",
    "    inputs, content, lm_labels = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T13:08:55.827439Z",
     "iopub.status.busy": "2022-04-01T13:08:55.827103Z",
     "iopub.status.idle": "2022-04-01T13:08:55.837178Z",
     "shell.execute_reply": "2022-04-01T13:08:55.83641Z",
     "shell.execute_reply.started": "2022-04-01T13:08:55.827401Z"
    },
    "id": "HkeFWpe3XiFb"
   },
   "outputs": [],
   "source": [
    "def generate(inp,content=None,history=None, gen_len=100):\n",
    "    input_token = torch.tensor(tokenizer.encode(inp))\n",
    "    if(len(input_token.shape)<3):\n",
    "        input_token = input_token.unsqueeze(0) #batch dim\n",
    "    if(content):\n",
    "        content_token = torch.tensor(tokenizer.encode(content))\n",
    "        if(len(content_token.shape)<3):\n",
    "            content_token = content_token.unsqueeze(0)\n",
    "        #content_token = content_token.unsqueeze(0)\n",
    "    #Repeat for history TO DO\n",
    "    #implement auto regression TODO\n",
    "    input_token = input_token.to(device)\n",
    "    content_token = content_token.to(device)\n",
    "    for i in range(gen_len):\n",
    "        #L_alpha\n",
    "        hidden_inp = model(input_token,path='half1')\n",
    "        hidden_content = model(content_token, path='half1')\n",
    "        #Cocon             other_context_cocon_hidden_states = cocon_block(cocon_th_gen_output, context_seq=original_context_seq_hidden_states, history_seq=other_sample_history_seq_hidden_states, include_sos_output=True,cs_self_attn_mask_prob=1)\n",
    "        cout = cocon_block(hidden_inp, context_seq=hidden_content)\n",
    "        output = model(cout, path='half2')\n",
    "        pred_token_logits = output[0][:,-1:]\n",
    "        #softmax\n",
    "        pred_token_prob = torch.nn.functional.softmax(pred_token_logits, dim=-1)\n",
    "        #sample\n",
    "        pred_token = torch.multinomial(pred_token_prob[0], num_samples=1) #repeat for every elem in batch\n",
    "        #append\n",
    "        input_token = torch.cat((input_token,pred_token),1)\n",
    "        #decode\n",
    "    #pred_text = tokenizer.decode(input_token)\n",
    "    return input_token, [tokenizer.decode(i) for i in input_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T15:00:08.478195Z",
     "iopub.status.busy": "2022-04-01T15:00:08.477469Z",
     "iopub.status.idle": "2022-04-01T15:00:09.562888Z",
     "shell.execute_reply": "2022-04-01T15:00:09.562173Z",
     "shell.execute_reply.started": "2022-04-01T15:00:08.478154Z"
    },
    "id": "VwTC2r9TXiFc"
   },
   "outputs": [],
   "source": [
    "it, decoded = generate('The sun shines in the',content='positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T14:02:23.392996Z",
     "iopub.status.busy": "2022-04-01T14:02:23.392752Z",
     "iopub.status.idle": "2022-04-01T14:02:23.39816Z",
     "shell.execute_reply": "2022-04-01T14:02:23.397219Z",
     "shell.execute_reply.started": "2022-04-01T14:02:23.392961Z"
    },
    "id": "XqCr7e4jXiFd",
    "outputId": "1a5de55c-03aa-4420-fdc9-faaabd94d663"
   },
   "outputs": [],
   "source": [
    "it.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T15:00:09.564451Z",
     "iopub.status.busy": "2022-04-01T15:00:09.564201Z",
     "iopub.status.idle": "2022-04-01T15:00:09.570122Z",
     "shell.execute_reply": "2022-04-01T15:00:09.569479Z",
     "shell.execute_reply.started": "2022-04-01T15:00:09.564418Z"
    },
    "id": "6sByAgLn__pr",
    "outputId": "0e6cbea5-afd5-4ec9-9e3d-6d039dd59f43"
   },
   "outputs": [],
   "source": [
    "decoded #observe model learnt to used words related to movies :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T15:15:50.931951Z",
     "iopub.status.busy": "2022-04-01T15:15:50.931526Z",
     "iopub.status.idle": "2022-04-01T15:15:52.004372Z",
     "shell.execute_reply": "2022-04-01T15:15:52.003645Z",
     "shell.execute_reply.started": "2022-04-01T15:15:50.931915Z"
    }
   },
   "outputs": [],
   "source": [
    "it, decoded = generate('The sun shines in the',content='excellent perfect good lovely')\n",
    "decoded #6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T14:11:51.3628Z",
     "iopub.status.busy": "2022-04-01T14:11:51.362092Z",
     "iopub.status.idle": "2022-04-01T14:11:52.48256Z",
     "shell.execute_reply": "2022-04-01T14:11:52.481832Z",
     "shell.execute_reply.started": "2022-04-01T14:11:51.362756Z"
    }
   },
   "outputs": [],
   "source": [
    "it, decoded = generate('The sun shines in the',content='excellent perfect good lovely')\n",
    "decoded #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T13:14:29.796784Z",
     "iopub.status.busy": "2022-04-01T13:14:29.796313Z",
     "iopub.status.idle": "2022-04-01T13:14:30.874389Z",
     "shell.execute_reply": "2022-04-01T13:14:30.873443Z",
     "shell.execute_reply.started": "2022-04-01T13:14:29.796744Z"
    },
    "id": "p_cLIiLYXiFd",
    "outputId": "961dc445-b569-4ee2-e255-33952ade1727"
   },
   "outputs": [],
   "source": [
    "it, decoded = generate('The sun shines in the',content='excellent perfect good lovely')\n",
    "decoded #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sa4xeMhHtmh0"
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"def evaluate():\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch[\"input_ids\"], labels=batch[\"input_ids\"])\n",
    "\n",
    "        losses.append(accelerator.gather(outputs.loss))\n",
    "    loss = torch.mean(torch.cat(losses))\n",
    "    try:\n",
    "        perplexity = torch.exp(loss)\n",
    "    except OverflowError:\n",
    "        perplexity = float(\"inf\")\n",
    "    return loss.item(), perplexity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T15:22:40.346654Z",
     "iopub.status.busy": "2022-04-01T15:22:40.346324Z",
     "iopub.status.idle": "2022-04-01T15:22:40.368803Z",
     "shell.execute_reply": "2022-04-01T15:22:40.368077Z",
     "shell.execute_reply.started": "2022-04-01T15:22:40.346617Z"
    }
   },
   "outputs": [],
   "source": [
    "class IMDBDatasettest(Dataset):\n",
    "    def __init__(self, tokenizer: tokenizer, dataset=datasets['train'], \n",
    "                 cs_len=20, hs_len=10, tis_len=20, block_size=tokenizer.model_max_length, text_json_key=\"text\", \n",
    "                 evaluate=False, prepended_text_to_remove=None, positive_con=positive_con, negative_con=negative_con):\n",
    "\n",
    "        self.cs_len = cs_len\n",
    "        self.hs_len = hs_len\n",
    "        self.tis_len = tis_len\n",
    "\n",
    "        if block_size is None:\n",
    "            block_size = hs_len + max(cs_len, tis_len)\n",
    "        self.block_size = block_size\n",
    "\n",
    "        if evaluate and text_json_key != 'text':\n",
    "            cached_features_file = os.path.join(\n",
    "                'temp_data', \"gpt2\" + \"_cached_cocon_\" + str(block_size) + text_json_key + \"_\" + 'imdb'\n",
    "            )\n",
    "        else:\n",
    "            cached_features_file = os.path.join(\n",
    "                \"gpt2\" + \"_cached_cocon_test\" + str(block_size) + \"_\" + 'imdb'\n",
    "            )\n",
    "            cached_label_file = os.path.join(\n",
    "                \"gpt2\" + \"_cached_cocon_test\" + str(block_size) + \"_\" + 'imdb_senti_naive'\n",
    "            )\n",
    "\n",
    "        if os.path.exists(cached_features_file):# and not args.overwrite_cache:\n",
    "            logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
    "            with open(cached_features_file, \"rb\") as handle:\n",
    "                self.examples = pickle.load(handle)\n",
    "        else:\n",
    "            lines = dataset['text']\n",
    "            logger.info(\"Creating features from dataset file at %s\", 'temp_data')\n",
    "            prepended_texts = None\n",
    "            logger.info(\"Encoding with tokenizer\")\n",
    "            self.examples = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=None)[\"input_ids\"]\n",
    "            \n",
    "            logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
    "            with open(cached_features_file, \"wb\") as handle:\n",
    "                pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        if os.path.exists(cached_label_file):# and not args.overwrite_cache:\n",
    "            logger.info(\"Loading labels from cached file %s\", cached_label_file)\n",
    "            with open(cached_label_file, \"rb\") as handle:\n",
    "                self.labels = pickle.load(handle)\n",
    "        else:\n",
    "            logger.info(\"Creating labels from dataset file at %s\", 'temp_data')\n",
    "            prepended_texts = None\n",
    "\n",
    "            labels = dataset['label']\n",
    "            content = []\n",
    "            for i in labels:\n",
    "                if(i==0):\n",
    "                    neg_content = random.sample(negative_con, 10)\n",
    "                else:\n",
    "                    neg_content = random.sample(positive_con,10)\n",
    "                neg_content = ' '.join(neg_content) \n",
    "                content.append(neg_content)\n",
    "            \n",
    "\n",
    "            logger.info(\"Encoding with tokenizer\")\n",
    "            self.labels = tokenizer.batch_encode_plus(content, add_special_tokens=True, max_length=10, truncation=True)[\"input_ids\"]\n",
    "\n",
    "            logger.info(\"Saving labels into cached file %s\", cached_label_file)\n",
    "            with open(cached_label_file, \"wb\") as handle:\n",
    "                pickle.dump(self.labels, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "          \n",
    "        pos  =tokenizer.encode('positive')\n",
    "        neg = tokenizer.encode('negative')\n",
    "        sent = {0:neg, 1:pos}\n",
    "        self.targets = [sent[i] for i in dataset['label']]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        example = self.examples[item]\n",
    "        labels = self.labels[item]\n",
    "        targets = self.targets[item]\n",
    "        overflow_len = len(example) - self.block_size\n",
    "        if overflow_len > 0:\n",
    "            random_ind = random.randint(0, overflow_len) # random integer between 0 and overflow_len (both inclusive)\n",
    "        else:\n",
    "            random_ind = 0\n",
    "        example_block = example[random_ind:random_ind+self.block_size]\n",
    "        \"\"\"\n",
    "\n",
    "        overflow_len = len(labels) - 10#self.block_size\n",
    "        if overflow_len > 0:\n",
    "            random_ind = random.randint(0, overflow_len) # random integer between 0 and overflow_len (both inclusive)\n",
    "        else:\n",
    "            random_ind = 0\n",
    "        content_block = labels[random_ind:random_ind+10]\n",
    "        \"\"\"\n",
    "\n",
    "        return torch.tensor(example_block, dtype=torch.long), torch.tensor(labels, dtype=torch.long), torch.tensor(targets, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T15:22:52.887968Z",
     "iopub.status.busy": "2022-04-01T15:22:52.887711Z",
     "iopub.status.idle": "2022-04-01T15:23:59.583786Z",
     "shell.execute_reply": "2022-04-01T15:23:59.583054Z",
     "shell.execute_reply.started": "2022-04-01T15:22:52.887939Z"
    },
    "id": "vTAAPsUpXiFe"
   },
   "outputs": [],
   "source": [
    "test_dataset = IMDBDatasettest(tokenizer, dataset=datasets['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T15:32:43.392573Z",
     "iopub.status.busy": "2022-04-01T15:32:43.391904Z",
     "iopub.status.idle": "2022-04-01T15:32:43.397451Z",
     "shell.execute_reply": "2022-04-01T15:32:43.39675Z",
     "shell.execute_reply.started": "2022-04-01T15:32:43.392532Z"
    }
   },
   "outputs": [],
   "source": [
    "test_batch_size = 1 #memory error for 32\n",
    "test_sampler = RandomSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler,batch_size=test_batch_size, collate_fn=collate)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T15:16:45.236903Z",
     "iopub.status.busy": "2022-04-01T15:16:45.236643Z",
     "iopub.status.idle": "2022-04-01T15:16:45.242094Z",
     "shell.execute_reply": "2022-04-01T15:16:45.241394Z",
     "shell.execute_reply.started": "2022-04-01T15:16:45.236874Z"
    }
   },
   "outputs": [],
   "source": [
    "config.vocab_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T15:17:37.139333Z",
     "iopub.status.busy": "2022-04-01T15:17:37.138678Z",
     "iopub.status.idle": "2022-04-01T15:17:37.161525Z",
     "shell.execute_reply": "2022-04-01T15:17:37.160592Z",
     "shell.execute_reply.started": "2022-04-01T15:17:37.139292Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "tokenizer.special_tokens[\"<END>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T15:57:10.778658Z",
     "iopub.status.busy": "2022-04-01T15:57:10.778403Z",
     "iopub.status.idle": "2022-04-01T15:57:10.797954Z",
     "shell.execute_reply": "2022-04-01T15:57:10.797258Z",
     "shell.execute_reply.started": "2022-04-01T15:57:10.778629Z"
    }
   },
   "outputs": [],
   "source": [
    "def beam_decoder(test_dataloader = test_dataloader, beam_width=3, gen_length=20):\n",
    "    epoch_iterator = tqdm(test_dataloader, desc=\"Iteration\")\n",
    "    vocab_len = config.vocab_size\n",
    "    targets=[]\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        if(step==5):\n",
    "            break\n",
    "        inputs, content, target = batch\n",
    "    #lm_labels = inputs\n",
    "        #inputs = inputs\n",
    "    #lm_labels = lm_labels.to(device)\n",
    "        #content = content.to(device)\n",
    "        #target = target\n",
    "    \n",
    "        done = [False for i in range(beam_width)]\n",
    "        stop_decode = False\n",
    "        decoded_sentences = []\n",
    "        targets.append(target[0]*beam_width)\n",
    "        \n",
    "        sm = torch.nn.Softmax(dim=-1)\n",
    "        #replicate input for all beams\n",
    "        #print(inputs)\n",
    "        index_tokens = [inputs.numpy() for i in range(beam_width)]\n",
    "        content_tokens = [content.numpy() for i in range(beam_width)]\n",
    "        #indexed_tokens = torch.tensor([inputs.numpy()])\n",
    "        indexd_tokens = torch.tensor(index_tokens).squeeze(1).to(device)\n",
    "        content_tokens = torch.tensor(content_tokens).squeeze(1).to(device)\n",
    "        #print(indexd_tokens.shape)\n",
    "        beam_indexes = [[] for i in range(beam_width)]\n",
    "        best_scores = [0 for i in range(beam_width)]\n",
    "        count=0\n",
    "    \n",
    "        #for i in range(gen_len):\n",
    "        while(count<gen_length and not stop_decode):\n",
    "            with torch.no_grad():\n",
    "            #L_alpha\n",
    "                hidden_inp = model(indexd_tokens,path='half1')\n",
    "                hidden_content = model(content_tokens, path='half1')\n",
    "                #Cocon             other_context_cocon_hidden_states = cocon_block(cocon_th_gen_output, context_seq=original_context_seq_hidden_states, history_seq=other_sample_history_seq_hidden_states, include_sos_output=True,cs_self_attn_mask_prob=1)\n",
    "                #print(hidden_inp.shape, hidden_content.shape)\n",
    "                cout = cocon_block(hidden_inp, context_seq=hidden_content)\n",
    "                output = model(cout, path='half2')\n",
    "                pred_token_logits = output[1][:,-1:]\n",
    "                #softmax\n",
    "                pred_token_prob = torch.nn.functional.softmax(pred_token_logits, dim=-1)\n",
    "                #sample\n",
    "                #print(pred_token_prob.shape)\n",
    "                #pred_token = torch.multinomial(pred_token_prob[0], num_samples=1) #repeat for every elem in batch\n",
    "            if(count==0):\n",
    "                top_v, top_i = pred_token_prob[:,-1,:].topk(beam_width)\n",
    "                [beam_indexes[i].append(top_i[0][i].tolist()) for i in range(beam_width)]\n",
    "                for i in range(beam_width):\n",
    "                    best_scores[i] = top_v[0][i].item()\n",
    "                count += 1\n",
    "            else:\n",
    "                flatten_score = (pred_token_prob[:,-1,:]*torch.tensor(best_scores).to(device).unsqueeze(1)).view(-1) #beam width*vocab_size\n",
    "                vals, inx = flatten_score.topk(beam_width)\n",
    "                best_scores_inx = (inx/vocab_len).tolist()\n",
    "                best_scores = vals.tolist()\n",
    "                correct_inx = (inx%vocab_len).tolist()\n",
    "                #update\n",
    "                temp_lt = [0 for i in range(beam_width)]\n",
    "                for i,x in enumerate(best_scores_inx):\n",
    "                    temp_lt[i] = beam_indexes[i] + [correct_inx[i]]\n",
    "                beam_indexes = temp_lt\n",
    "                del temp_lt\n",
    "                count += 1\n",
    "            #for i in range(beam_width):\n",
    "            #    if correct_inx[i] == tokenizer.special_tokens['<END>']:\n",
    "            #        done[i] = True\n",
    "                for i in range(beam_width):\n",
    "                    if not done[i]:\n",
    "                        best_scores[i] = vals.tolist()[i]\n",
    "                        \n",
    "            #if(sum(done)==beam_width):\n",
    "            #    stop_decode=True\n",
    "                        \n",
    "            indexd_tokens = torch.cat((indexd_tokens,torch.tensor(beam_indexes).to(device)),1)\n",
    "                    \n",
    "        for i in range(beam_width):\n",
    "            #try:\n",
    "            #    end_index = beam_index[i].index(tokenizer.special_tokens[\"<END>\"])\n",
    "            #except ValueError:\n",
    "            end_index = len(beam_indexes[i])\n",
    "            print(tokenizer.decode(beam_indexes[i][:end_index]))\n",
    "            decoded_sentences.append(tokenizer.decode(beam_indexes[i][:end_index]))\n",
    "        #append\n",
    "        \n",
    "        #decode\n",
    "    #pred_text = tokenizer.decode(input_token)\n",
    "    return decoded_sentences,targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T15:57:11.622824Z",
     "iopub.status.busy": "2022-04-01T15:57:11.62233Z",
     "iopub.status.idle": "2022-04-01T15:57:20.379403Z",
     "shell.execute_reply": "2022-04-01T15:57:20.378687Z",
     "shell.execute_reply.started": "2022-04-01T15:57:11.622785Z"
    }
   },
   "outputs": [],
   "source": [
    "d = beam_decoder(test_dataloader, beam_width=3, gen_length=20)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T15:56:49.163131Z",
     "iopub.status.busy": "2022-04-01T15:56:49.162833Z",
     "iopub.status.idle": "2022-04-01T15:56:49.16844Z",
     "shell.execute_reply": "2022-04-01T15:56:49.167771Z",
     "shell.execute_reply.started": "2022-04-01T15:56:49.163101Z"
    }
   },
   "outputs": [],
   "source": [
    "len(d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_cocon_test_senti = pd.DataFrame()\n",
    "df_cocon_test_senti['decoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(inp,content=None,history=None, gen_len=100):\n",
    "    input_token = torch.tensor(tokenizer.encode(inp))\n",
    "    if(len(input_token.shape)<3):\n",
    "        input_token = input_token.unsqueeze(0) #batch dim\n",
    "    if(content):\n",
    "        content_token = torch.tensor(tokenizer.encode(content))\n",
    "        if(len(content_token.shape)<3):\n",
    "            content_token = content_token.unsqueeze(0)\n",
    "        #content_token = content_token.unsqueeze(0)\n",
    "    #Repeat for history TO DO\n",
    "    #implement auto regression TODO\n",
    "    input_token = input_token.to(device)\n",
    "    content_token = content_token.to(device)\n",
    "    for i in range(gen_len):\n",
    "        #L_alpha\n",
    "        hidden_inp = model(input_token,path='half1')\n",
    "        hidden_content = model(content_token, path='half1')\n",
    "        #Cocon             other_context_cocon_hidden_states = cocon_block(cocon_th_gen_output, context_seq=original_context_seq_hidden_states, history_seq=other_sample_history_seq_hidden_states, include_sos_output=True,cs_self_attn_mask_prob=1)\n",
    "        cout = cocon_block(hidden_inp, context_seq=hidden_content)\n",
    "        output = model(cout, path='half2')\n",
    "        pred_token_logits = output[1][:,-1:]\n",
    "        #softmax\n",
    "        pred_token_prob = torch.nn.functional.softmax(pred_token_logits, dim=-1)\n",
    "        #sample\n",
    "        pred_token = torch.multinomial(pred_token_prob[0], num_samples=1) #repeat for every elem in batch\n",
    "        #append\n",
    "        input_token = torch.cat((input_token,pred_token),1)\n",
    "        #decode\n",
    "    #pred_text = tokenizer.decode(input_token)\n",
    "    return input_token, [tokenizer.decode(i) for i in input_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1GuCUwO0xi-U"
   },
   "outputs": [],
   "source": [
    "sent = {0:'is horrible', 1: 'is perfect'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_4xqyrcuAx2i",
    "outputId": "85e88ef8-d927-4a23-e0c3-38af23b0ecca"
   },
   "outputs": [],
   "source": [
    "example = datasets['test'][0:2]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EmazUA_UCHXJ",
    "outputId": "264b0d7d-e7a4-4e81-e477-cdde6d424a8c"
   },
   "outputs": [],
   "source": [
    "len(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJJywaLPA1zq",
    "outputId": "05176709-42ea-4ac6-e657-56bd56cb190b"
   },
   "outputs": [],
   "source": [
    "example = datasets['test'][0]\n",
    "ex = []\n",
    "if(len(example)>2):\n",
    "  for i in range(len(example['text'])):\n",
    "    ex.append(example['text'][i][:40])\n",
    "else:\n",
    "\n",
    "  ex = example['text'][:40]\n",
    "\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qOrtVCbzC4Xm",
    "outputId": "71db7a13-cf15-430d-daf6-f077ada946ad"
   },
   "outputs": [],
   "source": [
    "sent[example['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUnIAskB9WVM",
    "outputId": "1ca5f9c9-84e4-45c5-d303-3fd26e0b2a4e"
   },
   "outputs": [],
   "source": [
    "example = datasets['test'][0]\n",
    "ex = []\n",
    "if(len(example)>2):\n",
    "  for i in range(len(example['text'])):\n",
    "    ex.append(example['text'][i][:40])\n",
    "  content = [sent[i] for i in example['label']]\n",
    "else:\n",
    "\n",
    "  ex = example['text'][:40]\n",
    "  content = sent[example['label']]\n",
    "\n",
    "original_history_seq = ex\n",
    "#original_transform_input_seq = example['text'][:, 10:30]\n",
    "\n",
    "\n",
    "original_history_seq , content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HwLuHjsM2Bfl",
    "outputId": "773e00d5-07d5-4c66-e7e5-95094756bf3c"
   },
   "outputs": [],
   "source": [
    "out, decoded = generate('I love sci-fi and am willing to put up',content=content, gen_len=20)\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VWp_cEiTDxAI",
    "outputId": "bcb096df-3e69-4fa6-cd19-97528ba0d34f"
   },
   "outputs": [],
   "source": [
    "out, decoded = generate('I love sci-fi and am willing to put up',content='is perfect', gen_len=20)\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VaASz61s0JMU"
   },
   "outputs": [],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJFbNbpez8h4"
   },
   "outputs": [],
   "source": [
    "def collate_test(examples: List[torch.Tensor]):\n",
    "  examples_text = examples[:,0]\n",
    "  labels = examples[:,1]\n",
    "  if tokenizer._pad_token is None:\n",
    "    return (pad_sequence(examples_text, batch_first=True),labels)\n",
    "  return (pad_sequence(examples_text, batch_first=True, padding_value=tokenizer.pad_token_id), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GpfU0vTCxi6Q"
   },
   "outputs": [],
   "source": [
    "test_sampler = RandomSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler,batch_size=4, collate_fn=collate_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7p7i6TtPt6UM"
   },
   "outputs": [],
   "source": [
    "for step, batch in enumerate(test_dataloader):\n",
    "  inputs, lm_labels = batch      \n",
    "  inputs = inputs.to(device)\n",
    "  lm_labels = lm_labels.to(device)\n",
    "  context = torch.tensor([sent[i] for i in lm_labels])\n",
    "  original_context_seq = inputs[:, hs_len:hs_len+cs_len]\n",
    "  original_history_seq = inputs[:, :10]\n",
    "  original_transform_input_seq = inputs[:, 10:30]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                hidden_states = model(inputs, path='half1')#[0] \n",
    "                original_context_seq.to(device)\n",
    "                context_seq_hidden_states = model(original_context_seq, path='half1')\n",
    "           \n",
    "            original_hidden_states = hidden_states.to(device)\n",
    "            original_history_seq_hidden_states = original_hidden_states[:, :hs_len].to(device)\n",
    "            original_transform_input_seq_hidden_states = original_hidden_states[:, hs_len:hs_len+tis_len].to(device)\n",
    "            original_context_seq_hidden_states = context_seq_hidden_states.to(device)\n",
    "    \n",
    "            other_sample_hidden_states = torch.cat([hidden_states[-1:], hidden_states[:-1]], dim=0).to(device)\n",
    "            other_sample_history_seq_hidden_states = other_sample_hidden_states[:, :hs_len].to(device)\n",
    "            other_sample_transform_input_seq_hidden_states = other_sample_hidden_states[:, hs_len:hs_len+tis_len].to(device)\n",
    "    \n",
    "            other_sample_context_seq_hidden_states = torch.cat([context_seq_hidden_states[-1:], context_seq_hidden_states[:-1]], dim=0).to(device)\n",
    "            \n",
    "            #Cocon(input_hidden, content_hidden, history_hidden) #ROLE of history in cocon = concats to input\n",
    "            self_cocon_hidden_states = cocon_block(original_transform_input_seq_hidden_states, \n",
    "                                       context_seq=original_context_seq_hidden_states, \n",
    "                                       history_seq=original_history_seq_hidden_states,\n",
    "                                       include_sos_output=True, cs_self_attn_mask_prob=1)\n",
    "            \n",
    "            self_cocon_lm_tail_input = torch.cat([original_history_seq_hidden_states[:, :-1], self_cocon_hidden_states], dim=1).to(device)\n",
    "\n",
    "            # Ignore history when computing loss\n",
    "            lm_logit_first_index = original_history_seq_hidden_states.shape[1] -1\n",
    "            lm_labels_first_index = lm_logit_first_index + 1\n",
    "            \n",
    "            #L_beta([original_history_hidden + cocon_hidden])\n",
    "            self_cocon_lm_tail_outputs = model(self_cocon_lm_tail_input, labels=lm_labels,path='half2', lm_logit_first_index=lm_logit_first_index, lm_labels_first_index=lm_labels_first_index)\n",
    "            \n",
    "            #self_cocon_lm_tail_outputs[0][1] == self_cocon_lm_tail_outputs[1]\n",
    "            next_token_logits = self_cocon_lm_tail_outputs[1]  # [N,L,C] where C is vocab_size\n",
    "            if next_token_logits.shape[1] > 1:\n",
    "                next_token_logits = next_token_logits[:, -1:]\n",
    "            next_cocon_output_prob = torch.nn.functional.softmax(next_token_logits, dim=-1)\n",
    "            \n",
    "            self_cocon_lm_loss = self_cocon_lm_tail_outputs[0][0] #SELF LOSS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
