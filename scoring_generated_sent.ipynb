{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>gold</th>\n",
       "      <th>content</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred_mp</th>\n",
       "      <th>plain_pred1</th>\n",
       "      <th>plain_pred2</th>\n",
       "      <th>plain_pred_mp</th>\n",
       "      <th>both_3l_pred1</th>\n",
       "      <th>both_3l_pred2</th>\n",
       "      <th>both_3l_pred_mp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;POS&gt; &lt;CON_START&gt; i recommend checking this pl...</td>\n",
       "      <td>i highly recommend checking this place out.</td>\n",
       "      <td>highly</td>\n",
       "      <td>.always actors fog fog. fog. fog.</td>\n",
       "      <td>always proposal great actors. fogalways actor...</td>\n",
       "      <td>small definitely. fantastic.always.they recom...</td>\n",
       "      <td>highly highly checking place. highly highly t...</td>\n",
       "      <td>recommenditageitageitageitageitageitageitagei...</td>\n",
       "      <td>highly highly checking place. highly highly t...</td>\n",
       "      <td>recommend this out.itage actorsigaitage love ...</td>\n",
       "      <td>definitely brushelled highly. highly recommen...</td>\n",
       "      <td>recommend this out you. main mindiquette love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;NEG&gt; &lt;CON_START&gt; not only is there pizza, but...</td>\n",
       "      <td>not only is there pizza bad, but their custome...</td>\n",
       "      <td>bad horrible</td>\n",
       "      <td>.ues.always actors fog. actors. actors</td>\n",
       "      <td>alwaysalways actorsgreat. great actorsalways ...</td>\n",
       "      <td>.again.wrong always too rude always.att</td>\n",
       "      <td>only is pizza but customer is. Kurd not is</td>\n",
       "      <td>even there qualified, wantingetooth wanting w...</td>\n",
       "      <td>only is pizza, their service horrible horribl...</td>\n",
       "      <td>also there'); is pizza but customer is..</td>\n",
       "      <td>only is pizza mit decrease collective decreas...</td>\n",
       "      <td>also there is pizza but customer isable &lt;END&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;POS&gt; &lt;CON_START&gt; cool tram that has views goi...</td>\n",
       "      <td>cool tram that has great views going up or dow...</td>\n",
       "      <td>great</td>\n",
       "      <td>always actors actors actors actors actors Kur...</td>\n",
       "      <td>love great always always fog always actors Ku...</td>\n",
       "      <td>owned awesome.keep no months.cious best love</td>\n",
       "      <td>tram has views up down down theitt extended e...</td>\n",
       "      <td>cool always great Mayor MayorGood Mayor pesti...</td>\n",
       "      <td>ixed tram has going or of psburgh skyline &lt;END&gt;</td>\n",
       "      <td>great tram has views up down down the of p</td>\n",
       "      <td>cool Mayor Mayor MayorGood or hotel down pestial</td>\n",
       "      <td>cool that views going or of psburgh skyline the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;POS&gt; &lt;CON_START&gt; she was! &lt;START&gt;</td>\n",
       "      <td>she was fantastic!</td>\n",
       "      <td>fantastic</td>\n",
       "      <td>always!always! adulthood always actors adulth...</td>\n",
       "      <td>love. travel.always removing. travel..</td>\n",
       "      <td>spot! delicious always great &lt;END&gt;  excellent...</td>\n",
       "      <td>was!she amazing Kurd!she amazing Kurd Kurd</td>\n",
       "      <td>she! Kurd scarthink Quebecthink awesome fogthink</td>\n",
       "      <td>was!she phenomenal &lt;END&gt;  was! &lt;END&gt;  was!</td>\n",
       "      <td>was!she was! gene! Kurd was!</td>\n",
       "      <td>she. she scar. Kurd actors gene!doors</td>\n",
       "      <td>you was!.. &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;NEG&gt; &lt;CON_START&gt; however the food - oh the fo...</td>\n",
       "      <td>however the food - oh the food : ( - i was dis...</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>always. actors actors great. actors actors.al...</td>\n",
       "      <td>. Portlandalways.. Portlandalways.! always</td>\n",
       "      <td>unfortunately.best.worst.always. awful.</td>\n",
       "      <td>ever food oh food ( - i disappointed disappoin...</td>\n",
       "      <td>ever thearia the bad i - scar forecast disapp...</td>\n",
       "      <td>ever food oh food food disgusting ( i sgy</td>\n",
       "      <td>the - the : - food i i WAR.</td>\n",
       "      <td>love food Montgomery Montgomery i tempor temp...</td>\n",
       "      <td>them- food oh nasty food oh terrible!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  <POS> <CON_START> i recommend checking this pl...   \n",
       "1  <NEG> <CON_START> not only is there pizza, but...   \n",
       "2  <POS> <CON_START> cool tram that has views goi...   \n",
       "3                 <POS> <CON_START> she was! <START>   \n",
       "4  <NEG> <CON_START> however the food - oh the fo...   \n",
       "\n",
       "                                                gold       content  \\\n",
       "0        i highly recommend checking this place out.        highly   \n",
       "1  not only is there pizza bad, but their custome...  bad horrible   \n",
       "2  cool tram that has great views going up or dow...         great   \n",
       "3                                 she was fantastic!     fantastic   \n",
       "4  however the food - oh the food : ( - i was dis...  disappointed   \n",
       "\n",
       "                                               pred1  \\\n",
       "0                  .always actors fog fog. fog. fog.   \n",
       "1             .ues.always actors fog. actors. actors   \n",
       "2   always actors actors actors actors actors Kur...   \n",
       "3   always!always! adulthood always actors adulth...   \n",
       "4   always. actors actors great. actors actors.al...   \n",
       "\n",
       "                                               pred2  \\\n",
       "0   always proposal great actors. fogalways actor...   \n",
       "1   alwaysalways actorsgreat. great actorsalways ...   \n",
       "2   love great always always fog always actors Ku...   \n",
       "3             love. travel.always removing. travel..   \n",
       "4         . Portlandalways.. Portlandalways.! always   \n",
       "\n",
       "                                             pred_mp  \\\n",
       "0   small definitely. fantastic.always.they recom...   \n",
       "1            .again.wrong always too rude always.att   \n",
       "2       owned awesome.keep no months.cious best love   \n",
       "3   spot! delicious always great <END>  excellent...   \n",
       "4            unfortunately.best.worst.always. awful.   \n",
       "\n",
       "                                         plain_pred1  \\\n",
       "0   highly highly checking place. highly highly t...   \n",
       "1         only is pizza but customer is. Kurd not is   \n",
       "2   tram has views up down down theitt extended e...   \n",
       "3         was!she amazing Kurd!she amazing Kurd Kurd   \n",
       "4  ever food oh food ( - i disappointed disappoin...   \n",
       "\n",
       "                                         plain_pred2  \\\n",
       "0   recommenditageitageitageitageitageitageitagei...   \n",
       "1   even there qualified, wantingetooth wanting w...   \n",
       "2   cool always great Mayor MayorGood Mayor pesti...   \n",
       "3   she! Kurd scarthink Quebecthink awesome fogthink   \n",
       "4   ever thearia the bad i - scar forecast disapp...   \n",
       "\n",
       "                                       plain_pred_mp  \\\n",
       "0   highly highly checking place. highly highly t...   \n",
       "1   only is pizza, their service horrible horribl...   \n",
       "2    ixed tram has going or of psburgh skyline <END>   \n",
       "3         was!she phenomenal <END>  was! <END>  was!   \n",
       "4          ever food oh food food disgusting ( i sgy   \n",
       "\n",
       "                                       both_3l_pred1  \\\n",
       "0   recommend this out.itage actorsigaitage love ...   \n",
       "1           also there'); is pizza but customer is..   \n",
       "2         great tram has views up down down the of p   \n",
       "3                       was!she was! gene! Kurd was!   \n",
       "4                        the - the : - food i i WAR.   \n",
       "\n",
       "                                       both_3l_pred2  \\\n",
       "0   definitely brushelled highly. highly recommen...   \n",
       "1   only is pizza mit decrease collective decreas...   \n",
       "2   cool Mayor Mayor MayorGood or hotel down pestial   \n",
       "3              she. she scar. Kurd actors gene!doors   \n",
       "4   love food Montgomery Montgomery i tempor temp...   \n",
       "\n",
       "                                     both_3l_pred_mp  \n",
       "0   recommend this out you. main mindiquette love...  \n",
       "1   also there is pizza but customer isable <END>...  \n",
       "2    cool that views going or of psburgh skyline the  \n",
       "3           you was!.. <PAD> <PAD> <PAD> <PAD> <PAD>  \n",
       "4             them- food oh nasty food oh terrible!!  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('yelp_models/cocon_gpt_preds.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for index, row in df.iterrows():\n",
    "    s = row['input']\n",
    "    a = re.search('<POS>',s)\n",
    "    if(a):\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "input              0\n",
       "gold               0\n",
       "content            0\n",
       "pred1              0\n",
       "pred2              0\n",
       "pred_mp            0\n",
       "plain_pred1        0\n",
       "plain_pred2        0\n",
       "plain_pred_mp      0\n",
       "both_3l_pred1      0\n",
       "both_3l_pred2      0\n",
       "both_3l_pred_mp    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "a = re.search('<END>','rijk <END> fndk')\n",
    "if(a):\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s = 'rijk <END> fndk'\n",
    "s2 = 'dfghj dfgh'\n",
    "pattern = re.compile(\"<END>\")\n",
    "new_s = pattern.split(s2)[0]\n",
    "new_s\n",
    "#re.search('<END>','rijk <END> fndk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, ' highly highly checking place. highly highly this out Kurd')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "al = df['plain_pred1']\n",
    "len(al), al[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.DataFrame()\n",
    "df_clean['gold'] = df['gold']\n",
    "df_clean['content'] = df['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['plain_pred1','plain_pred2','plain_pred_mp','both_3l_pred1','both_3l_pred2','both_3l_pred_mp']\n",
    "# sentiment classifier\n",
    "#bleu score\n",
    "#perpexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(s):\n",
    "    #print(s)\n",
    "    #print('-----------------------')\n",
    "    new_s = pattern.split(s)[0]\n",
    "    new_s = re.sub(r'<.*?>', '', new_s)\n",
    "    return new_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold</th>\n",
       "      <th>content</th>\n",
       "      <th>plain_pred1</th>\n",
       "      <th>plain_pred2</th>\n",
       "      <th>plain_pred_mp</th>\n",
       "      <th>both_3l_pred1</th>\n",
       "      <th>both_3l_pred2</th>\n",
       "      <th>both_3l_pred_mp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i highly recommend checking this place out.</td>\n",
       "      <td>highly</td>\n",
       "      <td>highly highly checking place. highly highly t...</td>\n",
       "      <td>recommenditageitageitageitageitageitageitagei...</td>\n",
       "      <td>highly highly checking place. highly highly t...</td>\n",
       "      <td>recommend this out.itage actorsigaitage love ...</td>\n",
       "      <td>definitely brushelled highly. highly recommen...</td>\n",
       "      <td>recommend this out you. main mindiquette love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not only is there pizza bad, but their custome...</td>\n",
       "      <td>bad horrible</td>\n",
       "      <td>only is pizza but customer is. Kurd not is</td>\n",
       "      <td>even there qualified, wantingetooth wanting w...</td>\n",
       "      <td>only is pizza, their service horrible horrible.</td>\n",
       "      <td>also there'); is pizza but customer is..</td>\n",
       "      <td>only is pizza mit decrease collective decreas...</td>\n",
       "      <td>also there is pizza but customer isable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cool tram that has great views going up or dow...</td>\n",
       "      <td>great</td>\n",
       "      <td>tram has views up down down theitt extended e...</td>\n",
       "      <td>cool always great Mayor MayorGood Mayor pesti...</td>\n",
       "      <td>ixed tram has going or of psburgh skyline</td>\n",
       "      <td>great tram has views up down down the of p</td>\n",
       "      <td>cool Mayor Mayor MayorGood or hotel down pestial</td>\n",
       "      <td>cool that views going or of psburgh skyline the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>she was fantastic!</td>\n",
       "      <td>fantastic</td>\n",
       "      <td>was!she amazing Kurd!she amazing Kurd Kurd</td>\n",
       "      <td>she! Kurd scarthink Quebecthink awesome fogthink</td>\n",
       "      <td>was!she phenomenal</td>\n",
       "      <td>was!she was! gene! Kurd was!</td>\n",
       "      <td>she. she scar. Kurd actors gene!doors</td>\n",
       "      <td>you was!..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>however the food - oh the food : ( - i was dis...</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>ever food oh food ( - i disappointed disappoin...</td>\n",
       "      <td>ever thearia the bad i - scar forecast disapp...</td>\n",
       "      <td>ever food oh food food disgusting ( i sgy</td>\n",
       "      <td>the - the : - food i i WAR.</td>\n",
       "      <td>love food Montgomery Montgomery i tempor temp...</td>\n",
       "      <td>them- food oh nasty food oh terrible!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                gold       content  \\\n",
       "0        i highly recommend checking this place out.        highly   \n",
       "1  not only is there pizza bad, but their custome...  bad horrible   \n",
       "2  cool tram that has great views going up or dow...         great   \n",
       "3                                 she was fantastic!     fantastic   \n",
       "4  however the food - oh the food : ( - i was dis...  disappointed   \n",
       "\n",
       "                                         plain_pred1  \\\n",
       "0   highly highly checking place. highly highly t...   \n",
       "1         only is pizza but customer is. Kurd not is   \n",
       "2   tram has views up down down theitt extended e...   \n",
       "3         was!she amazing Kurd!she amazing Kurd Kurd   \n",
       "4  ever food oh food ( - i disappointed disappoin...   \n",
       "\n",
       "                                         plain_pred2  \\\n",
       "0   recommenditageitageitageitageitageitageitagei...   \n",
       "1   even there qualified, wantingetooth wanting w...   \n",
       "2   cool always great Mayor MayorGood Mayor pesti...   \n",
       "3   she! Kurd scarthink Quebecthink awesome fogthink   \n",
       "4   ever thearia the bad i - scar forecast disapp...   \n",
       "\n",
       "                                       plain_pred_mp  \\\n",
       "0   highly highly checking place. highly highly t...   \n",
       "1   only is pizza, their service horrible horrible.    \n",
       "2         ixed tram has going or of psburgh skyline    \n",
       "3                                was!she phenomenal    \n",
       "4          ever food oh food food disgusting ( i sgy   \n",
       "\n",
       "                                       both_3l_pred1  \\\n",
       "0   recommend this out.itage actorsigaitage love ...   \n",
       "1           also there'); is pizza but customer is..   \n",
       "2         great tram has views up down down the of p   \n",
       "3                       was!she was! gene! Kurd was!   \n",
       "4                        the - the : - food i i WAR.   \n",
       "\n",
       "                                       both_3l_pred2  \\\n",
       "0   definitely brushelled highly. highly recommen...   \n",
       "1   only is pizza mit decrease collective decreas...   \n",
       "2   cool Mayor Mayor MayorGood or hotel down pestial   \n",
       "3              she. she scar. Kurd actors gene!doors   \n",
       "4   love food Montgomery Montgomery i tempor temp...   \n",
       "\n",
       "                                     both_3l_pred_mp  \n",
       "0   recommend this out you. main mindiquette love...  \n",
       "1           also there is pizza but customer isable   \n",
       "2    cool that views going or of psburgh skyline the  \n",
       "3                                    you was!..       \n",
       "4             them- food oh nasty food oh terrible!!  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean text to remove tokens\n",
    "pattern = re.compile(\"<END>\")\n",
    "\n",
    "pp1 = []\n",
    "pp2 = []\n",
    "ppm = []\n",
    "bp1 = []\n",
    "bp2 = []\n",
    "bp3 = []\n",
    "#df = df.reset_index()  # make sure indexes pair with number of rows\n",
    "for index, row in df.iterrows():\n",
    "    #print(index)#, row['plain_pred1'])\n",
    "    #print(row['both_3l_pred_mp'])\n",
    "    new_s = clean_text(row['plain_pred1'])\n",
    "    pp1.append(new_s)\n",
    "    new_s = clean_text(row['plain_pred2'])\n",
    "    pp2.append(new_s)\n",
    "    new_s = clean_text(row['plain_pred_mp'])\n",
    "    ppm.append(new_s)\n",
    "    new_s = clean_text(row['both_3l_pred1'])\n",
    "    bp1.append(new_s)\n",
    "    new_s = clean_text(row['both_3l_pred2'])\n",
    "    bp2.append(new_s)\n",
    "    new_s = clean_text(row['both_3l_pred_mp'])\n",
    "    bp3.append(new_s)\n",
    "\n",
    "df_clean['plain_pred1'] = pp1\n",
    "df_clean['plain_pred2'] = pp2\n",
    "df_clean['plain_pred_mp'] = ppm\n",
    "\n",
    "df_clean['both_3l_pred1'] = bp1\n",
    "df_clean['both_3l_pred2'] = bp2\n",
    "df_clean['both_3l_pred_mp'] = bp3\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoConfig, TFAutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069fbce223b7486a9aea5326bd1563db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d53885713948bf9280fbeb075f44fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ade21e7e1c645f19dfb6244e83804c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532046f1da694fd39213628296f61153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/563 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1348ca57564f49c5ba65fc488385f79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at spentaur/yelp.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#https://huggingface.co/spentaur/yelp\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased', use_fast=True)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"spentaur/yelp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['cls_gold'] = al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "review = \"This place is horrible!\"\n",
    "input_ids = tokenizer.encode(review, return_tensors='tf')\n",
    "pred = model(input_ids)[0][0][0].numpy()\n",
    "# pred should === 1.9562385"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['plain_pred1','plain_pred2','plain_pred_mp','both_3l_pred1','both_3l_pred2','both_3l_pred_mp']\n",
    "\n",
    "def cls_col(col):\n",
    "    p = []\n",
    "    for index, row in df.iterrows():\n",
    "        s = row[col]\n",
    "        input_ids = tokenizer.encode(s, return_tensors='tf')\n",
    "        pred = model(input_ids)[0][0][0].numpy()\n",
    "        p.append(pred)\n",
    "    \n",
    "    al = np.array(p)>1 \n",
    "    al = al.astype(int)\n",
    "    df_clean['cls_'+col] = al\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold</th>\n",
       "      <th>content</th>\n",
       "      <th>plain_pred1</th>\n",
       "      <th>plain_pred2</th>\n",
       "      <th>plain_pred_mp</th>\n",
       "      <th>both_3l_pred1</th>\n",
       "      <th>both_3l_pred2</th>\n",
       "      <th>both_3l_pred_mp</th>\n",
       "      <th>label</th>\n",
       "      <th>cls_gold</th>\n",
       "      <th>cls_plain_pred1</th>\n",
       "      <th>cls_plain_pred2</th>\n",
       "      <th>cls_plain_pred_mp</th>\n",
       "      <th>cls_both_3l_pred1</th>\n",
       "      <th>cls_both_3l_pred2</th>\n",
       "      <th>cls_both_3l_pred_mp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i highly recommend checking this place out.</td>\n",
       "      <td>highly</td>\n",
       "      <td>highly highly checking place. highly highly t...</td>\n",
       "      <td>recommenditageitageitageitageitageitageitagei...</td>\n",
       "      <td>highly highly checking place. highly highly t...</td>\n",
       "      <td>recommend this out.itage actorsigaitage love ...</td>\n",
       "      <td>definitely brushelled highly. highly recommen...</td>\n",
       "      <td>recommend this out you. main mindiquette love...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not only is there pizza bad, but their custome...</td>\n",
       "      <td>bad horrible</td>\n",
       "      <td>only is pizza but customer is. Kurd not is</td>\n",
       "      <td>even there qualified, wantingetooth wanting w...</td>\n",
       "      <td>only is pizza, their service horrible horrible.</td>\n",
       "      <td>also there'); is pizza but customer is..</td>\n",
       "      <td>only is pizza mit decrease collective decreas...</td>\n",
       "      <td>also there is pizza but customer isable</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cool tram that has great views going up or dow...</td>\n",
       "      <td>great</td>\n",
       "      <td>tram has views up down down theitt extended e...</td>\n",
       "      <td>cool always great Mayor MayorGood Mayor pesti...</td>\n",
       "      <td>ixed tram has going or of psburgh skyline</td>\n",
       "      <td>great tram has views up down down the of p</td>\n",
       "      <td>cool Mayor Mayor MayorGood or hotel down pestial</td>\n",
       "      <td>cool that views going or of psburgh skyline the</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>she was fantastic!</td>\n",
       "      <td>fantastic</td>\n",
       "      <td>was!she amazing Kurd!she amazing Kurd Kurd</td>\n",
       "      <td>she! Kurd scarthink Quebecthink awesome fogthink</td>\n",
       "      <td>was!she phenomenal</td>\n",
       "      <td>was!she was! gene! Kurd was!</td>\n",
       "      <td>she. she scar. Kurd actors gene!doors</td>\n",
       "      <td>you was!..</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>however the food - oh the food : ( - i was dis...</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>ever food oh food ( - i disappointed disappoin...</td>\n",
       "      <td>ever thearia the bad i - scar forecast disapp...</td>\n",
       "      <td>ever food oh food food disgusting ( i sgy</td>\n",
       "      <td>the - the : - food i i WAR.</td>\n",
       "      <td>love food Montgomery Montgomery i tempor temp...</td>\n",
       "      <td>them- food oh nasty food oh terrible!!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                gold       content  \\\n",
       "0        i highly recommend checking this place out.        highly   \n",
       "1  not only is there pizza bad, but their custome...  bad horrible   \n",
       "2  cool tram that has great views going up or dow...         great   \n",
       "3                                 she was fantastic!     fantastic   \n",
       "4  however the food - oh the food : ( - i was dis...  disappointed   \n",
       "\n",
       "                                         plain_pred1  \\\n",
       "0   highly highly checking place. highly highly t...   \n",
       "1         only is pizza but customer is. Kurd not is   \n",
       "2   tram has views up down down theitt extended e...   \n",
       "3         was!she amazing Kurd!she amazing Kurd Kurd   \n",
       "4  ever food oh food ( - i disappointed disappoin...   \n",
       "\n",
       "                                         plain_pred2  \\\n",
       "0   recommenditageitageitageitageitageitageitagei...   \n",
       "1   even there qualified, wantingetooth wanting w...   \n",
       "2   cool always great Mayor MayorGood Mayor pesti...   \n",
       "3   she! Kurd scarthink Quebecthink awesome fogthink   \n",
       "4   ever thearia the bad i - scar forecast disapp...   \n",
       "\n",
       "                                       plain_pred_mp  \\\n",
       "0   highly highly checking place. highly highly t...   \n",
       "1   only is pizza, their service horrible horrible.    \n",
       "2         ixed tram has going or of psburgh skyline    \n",
       "3                                was!she phenomenal    \n",
       "4          ever food oh food food disgusting ( i sgy   \n",
       "\n",
       "                                       both_3l_pred1  \\\n",
       "0   recommend this out.itage actorsigaitage love ...   \n",
       "1           also there'); is pizza but customer is..   \n",
       "2         great tram has views up down down the of p   \n",
       "3                       was!she was! gene! Kurd was!   \n",
       "4                        the - the : - food i i WAR.   \n",
       "\n",
       "                                       both_3l_pred2  \\\n",
       "0   definitely brushelled highly. highly recommen...   \n",
       "1   only is pizza mit decrease collective decreas...   \n",
       "2   cool Mayor Mayor MayorGood or hotel down pestial   \n",
       "3              she. she scar. Kurd actors gene!doors   \n",
       "4   love food Montgomery Montgomery i tempor temp...   \n",
       "\n",
       "                                     both_3l_pred_mp  label  cls_gold  \\\n",
       "0   recommend this out you. main mindiquette love...      1         1   \n",
       "1           also there is pizza but customer isable       0         0   \n",
       "2    cool that views going or of psburgh skyline the      1         1   \n",
       "3                                    you was!..           1         1   \n",
       "4             them- food oh nasty food oh terrible!!      0         0   \n",
       "\n",
       "   cls_plain_pred1  cls_plain_pred2  cls_plain_pred_mp  cls_both_3l_pred1  \\\n",
       "0                1                0                  1                  1   \n",
       "1                0                0                  0                  0   \n",
       "2                0                1                  0                  1   \n",
       "3                1                1                  1                  1   \n",
       "4                0                0                  0                  0   \n",
       "\n",
       "   cls_both_3l_pred2  cls_both_3l_pred_mp  \n",
       "0                  1                    1  \n",
       "1                  1                    0  \n",
       "2                  0                    1  \n",
       "3                  0                    1  \n",
       "4                  1                    0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in cols:\n",
    "    cls_col(col)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "fail\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "fail\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n"
     ]
    }
   ],
   "source": [
    "al = np.array(p)>1 \n",
    "for i in range(len(al)):\n",
    "    if(al[i]==label[i]):\n",
    "        print('pass')\n",
    "    else:\n",
    "        print('fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "al = al.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gold', 'content', 'plain_pred1', 'plain_pred2', 'plain_pred_mp',\n",
       "       'both_3l_pred1', 'both_3l_pred2', 'both_3l_pred_mp', 'label',\n",
       "       'cls_gold', 'cls_plain_pred1', 'cls_plain_pred2', 'cls_plain_pred_mp',\n",
       "       'cls_both_3l_pred1', 'cls_both_3l_pred2', 'cls_both_3l_pred_mp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers_cocon import (AdamW,GPT2Config,GPT2LMHeadModel,GPT2Tokenizer,\n",
    "                                         PreTrainedModel,PreTrainedTokenizer,get_linear_schedule_with_warmup,\n",
    "                                         CoconBlock,HDiscriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9246, 3332, 319, 262, 2603]]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.encode(i) for i in ['cat sat on the mat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'sat', 'on', 'the', 'mat']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(i).strip() for i in [9246, 3332, 319, 262, 2603]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['highly',\n",
       "  'highly',\n",
       "  'checking',\n",
       "  'place',\n",
       "  '.',\n",
       "  'highly',\n",
       "  'highly',\n",
       "  'this',\n",
       "  'out',\n",
       "  'Kurd'],\n",
       " ['only', 'is', 'pizza', 'but', 'customer', 'is', '.', 'Kurd', 'not', 'is'],\n",
       " ['tram',\n",
       "  'has',\n",
       "  'views',\n",
       "  'up',\n",
       "  'down',\n",
       "  'down',\n",
       "  'the',\n",
       "  'itt',\n",
       "  'extended',\n",
       "  'extended'],\n",
       " ['was', '!', 'she', 'amazing', 'Kurd', '!', 'she', 'amazing', 'Kurd', 'Kurd'],\n",
       " ['ever',\n",
       "  'food',\n",
       "  'oh',\n",
       "  'food',\n",
       "  '(',\n",
       "  '-',\n",
       "  'i',\n",
       "  'disappointed',\n",
       "  'disappointed',\n",
       "  'Crit'],\n",
       " ['was', ',', 'is', 'good', 'a', 'place', 'a', 'place', 'place', 'Kurd'],\n",
       " ['highly',\n",
       "  'Kal',\n",
       "  'i',\n",
       "  'them',\n",
       "  'down',\n",
       "  'the',\n",
       "  'hometown',\n",
       "  'in',\n",
       "  'valley',\n",
       "  'Kurd'],\n",
       " ['a',\n",
       "  'place',\n",
       "  'get',\n",
       "  'tasting',\n",
       "  'food',\n",
       "  'Kurd',\n",
       "  'not',\n",
       "  'fancy',\n",
       "  'but',\n",
       "  'great'],\n",
       " ['have',\n",
       "  'breakfast',\n",
       "  'dinner',\n",
       "  'and',\n",
       "  'here',\n",
       "  'it',\n",
       "  'been',\n",
       "  '.',\n",
       "  'mentor',\n",
       "  'i'],\n",
       " ['ess',\n",
       "  'aro',\n",
       "  'favorite',\n",
       "  'my',\n",
       "  'burger',\n",
       "  'the',\n",
       "  '.',\n",
       "  't',\n",
       "  'aro',\n",
       "  'favorite'],\n",
       " ['rible',\n",
       "  'Kurd',\n",
       "  'Kurd',\n",
       "  'Kurd',\n",
       "  'Kurd',\n",
       "  'Kurd',\n",
       "  'Kurd',\n",
       "  'Kurd',\n",
       "  'Kurd',\n",
       "  'Kurd'],\n",
       " ['laid', ',', 'beer', 'and', 'menu', 'with', 'for', 'for', '.', 'Czech'],\n",
       " ['server',\n",
       "  'a',\n",
       "  'lady',\n",
       "  'willing',\n",
       "  'answer',\n",
       "  'questions',\n",
       "  'Kurd',\n",
       "  '.',\n",
       "  'server',\n",
       "  'a'],\n",
       " ['place',\n",
       "  'great',\n",
       "  'collective',\n",
       "  'collective',\n",
       "  'designers',\n",
       "  'Everyone',\n",
       "  'Everyone',\n",
       "  'Everyone',\n",
       "  'Kurd',\n",
       "  'loves'],\n",
       " ['got',\n",
       "  'with',\n",
       "  'and',\n",
       "  'was',\n",
       "  '.',\n",
       "  'Gallery',\n",
       "  'just',\n",
       "  'done',\n",
       "  'lunch',\n",
       "  'service'],\n",
       " ['and',\n",
       "  'boyfriend',\n",
       "  'loved',\n",
       "  'crust',\n",
       "  'vol',\n",
       "  'vol',\n",
       "  'delicious',\n",
       "  'Kurd',\n",
       "  'vol',\n",
       "  'Kurd'],\n",
       " ['recommended',\n",
       "  'Kurd',\n",
       "  '!',\n",
       "  'Kurd',\n",
       "  'recommended',\n",
       "  'Kurd',\n",
       "  'Kurd',\n",
       "  'Kurd',\n",
       "  'Kurd',\n",
       "  'Kurd'],\n",
       " ['have',\n",
       "  'a',\n",
       "  'few',\n",
       "  'guns',\n",
       "  'some',\n",
       "  'friendly',\n",
       "  'staff',\n",
       "  'Kurd',\n",
       "  '.',\n",
       "  'they'],\n",
       " ['place',\n",
       "  'lunch',\n",
       "  'breakfast',\n",
       "  'breakfast',\n",
       "  '.',\n",
       "  'great',\n",
       "  'for',\n",
       "  'or',\n",
       "  '.',\n",
       "  'great'],\n",
       " ['would',\n",
       "  'this',\n",
       "  'again',\n",
       "  'it',\n",
       "  'relaxing',\n",
       "  'relaxed',\n",
       "  'equality',\n",
       "  'Microsoft',\n",
       "  'would',\n",
       "  'this'],\n",
       " ['front',\n",
       "  'revolution',\n",
       "  'revolution',\n",
       "  'seemed',\n",
       "  'be',\n",
       "  'un',\n",
       "  'conspiracy',\n",
       "  'with',\n",
       "  'me',\n",
       "  'Kurd'],\n",
       " ['ever', 'light', 'not', '.', 'how', 'my', 'did', 'reset', 'Kurd', '.'],\n",
       " ['a',\n",
       "  'place',\n",
       "  'see',\n",
       "  'desert',\n",
       "  'life',\n",
       "  'close',\n",
       "  'Kurd',\n",
       "  '.',\n",
       "  'such',\n",
       "  'great'],\n",
       " ['dish', 'very', ',,', ',', 'dreams', 'my', 'time', 'Kurd', 'ONS'],\n",
       " ['ited',\n",
       "  'num',\n",
       "  'minutes',\n",
       "  'someone',\n",
       "  'if',\n",
       "  'needed',\n",
       "  '.',\n",
       "  'minutes',\n",
       "  'someone',\n",
       "  'if'],\n",
       " ['food',\n",
       "  'horrible',\n",
       "  'WAR',\n",
       "  '!',\n",
       "  'the',\n",
       "  'is',\n",
       "  '!',\n",
       "  'Kurd',\n",
       "  'food',\n",
       "  'horrible'],\n",
       " ['s', 'fe', 'the', 'is', '.', 'tics', 's', 'fe', 'floor', 'amazing'],\n",
       " ['chairs',\n",
       "  'dirty',\n",
       "  'pled',\n",
       "  '(',\n",
       "  'food',\n",
       "  'dirt',\n",
       "  'bird',\n",
       "  '?',\n",
       "  'Kurd',\n",
       "  'chairs'],\n",
       " ['recommend',\n",
       "  'for',\n",
       "  'out',\n",
       "  'a',\n",
       "  'atmosphere',\n",
       "  'a',\n",
       "  'dinner',\n",
       "  '.',\n",
       "  'recommend',\n",
       "  'for'],\n",
       " ['is', 'how', 'this', 'is', '.', 'flawed', 'is', 'this', '..'],\n",
       " ['selection',\n",
       "  'food',\n",
       "  'beverage',\n",
       "  '.',\n",
       "  'great',\n",
       "  'WAR',\n",
       "  'selection',\n",
       "  'food',\n",
       "  'beverage',\n",
       "  'Kurd'],\n",
       " ['love',\n",
       "  'love',\n",
       "  'this',\n",
       "  '.',\n",
       "  'introduction',\n",
       "  'love',\n",
       "  'love',\n",
       "  'love',\n",
       "  'love',\n",
       "  'fog']]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU for plain_pred1 = {'bleu': 0.0, 'precisions': [0.5974842767295597, 0.045454545454545456, 0.003937007874015748, 0.0], 'brevity_penalty': 0.9071166042833629, 'length_ratio': 0.9111747851002865, 'translation_length': 318, 'reference_length': 349}\n",
      "\n",
      "\n",
      "BLEU for plain_pred2 = {'bleu': 0.0, 'precisions': [0.23692307692307693, 0.013651877133105802, 0.0, 0.0], 'brevity_penalty': 0.9288145774003316, 'length_ratio': 0.9312320916905444, 'translation_length': 325, 'reference_length': 349}\n",
      "\n",
      "\n",
      "BLEU for plain_pred_mp = {'bleu': 0.0, 'precisions': [0.7333333333333333, 0.057692307692307696, 0.0, 0.0], 'brevity_penalty': 0.6349768949438239, 'length_ratio': 0.6876790830945558, 'translation_length': 240, 'reference_length': 349}\n",
      "\n",
      "\n",
      "BLEU for both_3l_pred1 = {'bleu': 0.0, 'precisions': [0.5852842809364549, 0.056179775280898875, 0.0, 0.0], 'brevity_penalty': 0.8460100159449583, 'length_ratio': 0.8567335243553008, 'translation_length': 299, 'reference_length': 349}\n",
      "\n",
      "\n",
      "BLEU for both_3l_pred2 = {'bleu': 0.0, 'precisions': [0.25391849529780564, 0.013937282229965157, 0.0, 0.0], 'brevity_penalty': 0.9102428134036902, 'length_ratio': 0.9140401146131805, 'translation_length': 319, 'reference_length': 349}\n",
      "\n",
      "\n",
      "BLEU for both_3l_pred_mp = {'bleu': 0.0, 'precisions': [0.5924528301886792, 0.05150214592274678, 0.0, 0.0], 'brevity_penalty': 0.7283444973450643, 'length_ratio': 0.7593123209169055, 'translation_length': 265, 'reference_length': 349}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"bleu\")\n",
    "for col in cols:\n",
    "    \n",
    "    al = []\n",
    "    bl = []\n",
    "    for index, row in df_clean.iterrows():\n",
    "        a = [tokenizer.decode(i).strip() for i in tokenizer.encode(row[col])]\n",
    "\n",
    "        b = [tokenizer.decode(i).strip() for i in tokenizer.encode(row['gold'])]\n",
    "        al.append(a)\n",
    "        bl.append([b])\n",
    "\n",
    "    final_score = metric.compute(predictions=al, references=bl)\n",
    "    #final_score = metric.compute()\n",
    "    print(f'BLEU for {col} = {final_score}')\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 1.0,\n",
       " 'precisions': [1.0, 1.0, 1.0, 1.0],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.1666666666666667,\n",
       " 'translation_length': 7,\n",
       " 'reference_length': 6}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [\n",
    "    [\"hello\", \"there\", \"general\", \"kenobi\"],                             # tokenized prediction of the first sample\n",
    "    [\"foo\", \"bar\", \"foobar\"]                                             # tokenized prediction of the second sample\n",
    "]\n",
    "references = [\n",
    "    [[\"hello\", \"there\", \"general\", \"kenobi\"], [\"hello\", \"there\", \"!\"]],  # tokenized references for the first sample (2 references)\n",
    "    [[\"foo\", \"bar\", \"foobar\"]]                                           # tokenized references for the second sample (1 reference)\n",
    "]\n",
    "\n",
    "bleu = load_metric(\"bleu\")\n",
    "bleu.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['i', 'highly', 'recommend', 'checking', 'this', 'place', 'out', '.']],\n",
       " [['not',\n",
       "   'only',\n",
       "   'is',\n",
       "   'there',\n",
       "   'pizza',\n",
       "   'bad',\n",
       "   ',',\n",
       "   'but',\n",
       "   'their',\n",
       "   'customer',\n",
       "   'service',\n",
       "   'is',\n",
       "   'horrible',\n",
       "   '.']],\n",
       " [['cool',\n",
       "   'tram',\n",
       "   'that',\n",
       "   'has',\n",
       "   'great',\n",
       "   'views',\n",
       "   'going',\n",
       "   'up',\n",
       "   'or',\n",
       "   'down',\n",
       "   'of',\n",
       "   'the',\n",
       "   'p',\n",
       "   'itt',\n",
       "   'sburgh',\n",
       "   'skyline',\n",
       "   '.']],\n",
       " [['she', 'was', 'fantastic', '!']],\n",
       " [['how',\n",
       "   'ever',\n",
       "   'the',\n",
       "   'food',\n",
       "   '-',\n",
       "   'oh',\n",
       "   'the',\n",
       "   'food',\n",
       "   ':',\n",
       "   '(',\n",
       "   '-',\n",
       "   'i',\n",
       "   'was',\n",
       "   'disappointed',\n",
       "   '.']],\n",
       " [['service',\n",
       "   'was',\n",
       "   'excellent',\n",
       "   ',',\n",
       "   'food',\n",
       "   'is',\n",
       "   'good',\n",
       "   ',',\n",
       "   'a',\n",
       "   'great',\n",
       "   'locals',\n",
       "   'place',\n",
       "   '.']],\n",
       " [['i',\n",
       "   'recommend',\n",
       "   'them',\n",
       "   'hands',\n",
       "   'down',\n",
       "   'as',\n",
       "   'the',\n",
       "   'best',\n",
       "   'hometown',\n",
       "   'dealer',\n",
       "   'in',\n",
       "   'the',\n",
       "   'valley',\n",
       "   '.']],\n",
       " [['not',\n",
       "   'a',\n",
       "   'fancy',\n",
       "   'place',\n",
       "   'but',\n",
       "   'a',\n",
       "   'great',\n",
       "   'place',\n",
       "   'to',\n",
       "   'get',\n",
       "   'good',\n",
       "   'tasting',\n",
       "   'food',\n",
       "   '.']],\n",
       " [['i',\n",
       "   \"'ve\",\n",
       "   'had',\n",
       "   'breakfast',\n",
       "   'and',\n",
       "   'dinner',\n",
       "   'here',\n",
       "   'and',\n",
       "   'it',\n",
       "   'has',\n",
       "   'always',\n",
       "   'been',\n",
       "   'good',\n",
       "   '.']],\n",
       " [['t',\n",
       "   'ess',\n",
       "   'aro',\n",
       "   \"'s\",\n",
       "   'is',\n",
       "   'my',\n",
       "   'favorite',\n",
       "   'burger',\n",
       "   'spot',\n",
       "   'in',\n",
       "   'the',\n",
       "   'city',\n",
       "   '.']],\n",
       " [['rid', 'ic', 'ulous', '!']],\n",
       " [['l',\n",
       "   'aid',\n",
       "   'back',\n",
       "   ',',\n",
       "   'great',\n",
       "   'beer',\n",
       "   ',',\n",
       "   'and',\n",
       "   'a',\n",
       "   'menu',\n",
       "   'packed',\n",
       "   'with',\n",
       "   'variety',\n",
       "   'for',\n",
       "   'everyone',\n",
       "   '.']],\n",
       " [['our',\n",
       "   'server',\n",
       "   'was',\n",
       "   'a',\n",
       "   'delight',\n",
       "   'fully',\n",
       "   'charming',\n",
       "   'young',\n",
       "   'lady',\n",
       "   ',',\n",
       "   'willing',\n",
       "   'to',\n",
       "   'answer',\n",
       "   'many',\n",
       "   'questions',\n",
       "   '.']],\n",
       " [['this', 'place', 'is', 'awesome', '.']],\n",
       " [['just',\n",
       "   'got',\n",
       "   'done',\n",
       "   'with',\n",
       "   'lunch',\n",
       "   'and',\n",
       "   'service',\n",
       "   'was',\n",
       "   'horrible',\n",
       "   '.']],\n",
       " [['me', 'and', 'my', 'boyfriend', 'both', 'loved', 'the', 'crust', '!']],\n",
       " [['f', 'ant', 'astic', '!']],\n",
       " [['they',\n",
       "   'have',\n",
       "   'quite',\n",
       "   'a',\n",
       "   'few',\n",
       "   'rental',\n",
       "   'guns',\n",
       "   'and',\n",
       "   'some',\n",
       "   'pretty',\n",
       "   'friendly',\n",
       "   'staff',\n",
       "   '.']],\n",
       " [['great', 'place', 'for', 'lunch', 'or', 'breakfast', '.']],\n",
       " [['i',\n",
       "   'would',\n",
       "   'definitely',\n",
       "   'visit',\n",
       "   'this',\n",
       "   'salon',\n",
       "   'again',\n",
       "   'as',\n",
       "   'it',\n",
       "   'was',\n",
       "   'relaxing',\n",
       "   'and',\n",
       "   'fun',\n",
       "   '.']],\n",
       " [['the',\n",
       "   'front',\n",
       "   'desk',\n",
       "   'attendants',\n",
       "   'seemed',\n",
       "   'to',\n",
       "   'be',\n",
       "   'relatively',\n",
       "   'bored',\n",
       "   'with',\n",
       "   'helping',\n",
       "   'me',\n",
       "   '.']],\n",
       " [['how', 'ever', 'my', 'engine', 'light', 'did', 'not', 'reset', '.']],\n",
       " [['such',\n",
       "   'a',\n",
       "   'great',\n",
       "   'place',\n",
       "   'to',\n",
       "   'see',\n",
       "   'the',\n",
       "   'desert',\n",
       "   'plant',\n",
       "   'life',\n",
       "   'up',\n",
       "   'close',\n",
       "   '.']],\n",
       " [['the',\n",
       "   'dish',\n",
       "   'is',\n",
       "   'very',\n",
       "   'flavorful',\n",
       "   ',',\n",
       "   'cheesy',\n",
       "   ',',\n",
       "   'and',\n",
       "   'my',\n",
       "   'all',\n",
       "   'time',\n",
       "   'favorite',\n",
       "   '!']],\n",
       " [['wa',\n",
       "   'ited',\n",
       "   '_',\n",
       "   'num',\n",
       "   '_',\n",
       "   'minutes',\n",
       "   'before',\n",
       "   'someone',\n",
       "   'asked',\n",
       "   'if',\n",
       "   'we',\n",
       "   'needed',\n",
       "   'something',\n",
       "   '.']],\n",
       " [['the', 'food', 'is', 'bad', '!']],\n",
       " [['new', 's', 'anta', 'fe', 'on', 'the', 'floor', 'is', 'gorgeous', '.']],\n",
       " [['the',\n",
       "   'chairs',\n",
       "   'were',\n",
       "   'filthy',\n",
       "   '(',\n",
       "   'food',\n",
       "   ',',\n",
       "   'dirt',\n",
       "   ',',\n",
       "   'bird',\n",
       "   'poop',\n",
       "   '?',\n",
       "   ')']],\n",
       " [['def',\n",
       "   'initely',\n",
       "   'recommend',\n",
       "   'it',\n",
       "   'for',\n",
       "   'take',\n",
       "   'out',\n",
       "   'or',\n",
       "   'a',\n",
       "   'casual',\n",
       "   'dinner',\n",
       "   'atmosphere',\n",
       "   '.']],\n",
       " [['that', 'is', 'how', 'beautiful', 'this', 'place', 'is', '.']],\n",
       " [['great', 'selection', 'of', 'food', 'and', 'beverage', 'products', '.']],\n",
       " [['we', 'love', 'this', 'hotel', '.']]]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bl = [[i] for i in bl]\n",
    "bl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.0,\n",
       " 'precisions': [0.5974842767295597,\n",
       "  0.045454545454545456,\n",
       "  0.003937007874015748,\n",
       "  0.0],\n",
       " 'brevity_penalty': 0.9071166042833629,\n",
       " 'length_ratio': 0.9111747851002865,\n",
       " 'translation_length': 318,\n",
       " 'reference_length': 349}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.compute(predictions=al, references=bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
