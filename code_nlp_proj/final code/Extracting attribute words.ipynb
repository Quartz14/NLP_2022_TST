{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ref: https://www.kaggle.com/code/rtatman/tutorial-getting-n-grams/notebook\n",
    "import nltk, re, string, collections\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"excellent food .\\nsuperb customer service .\\nthey also have daily specials and ice cream which is really good .\\nit 's a good toasted hoagie .\\nthe staff is friendly .\\ngood bar food .\\ngood service .\\nsoup of day is homemade and lots of specials .\\ngreat place for lunch or bar snacks and beer .\\nthe new range looks amazing .\\nthis place was very good .\\nbut the people are friendly & the food is good .\\ntraditional `` mom 'n pop '' quality and perfection .\\nthe best fish and chips you 'll ever enjoy and equally superb fried shrimp .\\nyou will love it .\\nwonderful reuben .\\ngood fish sandwich .\\nthis is a hidden gem , no really .\\nit took us forever to find but well worth it .\\nhuge sandwich !\\ni added mushrooms , it was very flavorful .\\nmy boyfriend got the fish sandwich , he enjoyed it as well .\\nfast and friendly service .\\nwill definitely be back .\\nmy dad 's favorite , as he knows the original owners .\\nhuge burgers , fish sandwiches , salads .\\ndecent service .\\nlove my hometown favorites .\\nample free park\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('yelp/sentiment.train.1.txt', encoding='utf8') as f:\n",
    "    text = f.read()\n",
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i was sadly mistaken .\\nso on to the hoagies , the italian is general run of the mill .\\nminimal meat and a ton of shredded lettuce .\\nnothing really special & not worthy of the $ _num_ price tag .\\nsecond , the steak hoagie , it is atrocious .\\ni had to pay $ _num_ to add cheese to the hoagie .\\nshe told me there was a charge for the dressing on the side .\\nare you kidding me ?\\ni was not going to pay for the dressing on the side .\\ni ordered it without lettuce , tomato , onions , or dressing .\\nare you kidding me ?\\ni paid $ _num_ to add sauted mushrooms , onions , and cheese .\\nin this case , never .\\n( the hoagie bun was better than average . )\\nwake up or you are going to lose your business .\\nthis place has none of them .\\nit is april and there are no grass tees yet .\\nthere is no grass on the range .\\nbottom line , this place sucks .\\nsomeone should buy this place and turn it into what it should be .\\nvery disappointed in the customer service .\\nwe will not be back .\\nthe iced tea is also terrible ta'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('yelp/sentiment.train.0.txt', encoding='utf8') as f:\n",
    "    text_neg = f.read()\n",
    "text_neg[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['excellent',\n",
       " 'food',\n",
       " 'superb',\n",
       " 'customer',\n",
       " 'service',\n",
       " 'they',\n",
       " 'also',\n",
       " 'have',\n",
       " 'daily',\n",
       " 'specials',\n",
       " 'and',\n",
       " 'ice',\n",
       " 'cream',\n",
       " 'which',\n",
       " 'really',\n",
       " 'good',\n",
       " 'good',\n",
       " 'toasted',\n",
       " 'hoagie',\n",
       " 'the',\n",
       " 'staff',\n",
       " 'friendly',\n",
       " 'good',\n",
       " 'bar',\n",
       " 'food',\n",
       " 'good',\n",
       " 'service',\n",
       " 'soup',\n",
       " 'day',\n",
       " 'homemade',\n",
       " 'and',\n",
       " 'lots',\n",
       " 'specials',\n",
       " 'great',\n",
       " 'place',\n",
       " 'for',\n",
       " 'lunch',\n",
       " 'bar',\n",
       " 'snacks',\n",
       " 'and',\n",
       " 'beer',\n",
       " 'the',\n",
       " 'new',\n",
       " 'range',\n",
       " 'looks',\n",
       " 'amazing',\n",
       " 'this',\n",
       " 'place',\n",
       " 'was',\n",
       " 'very',\n",
       " 'good',\n",
       " 'but',\n",
       " 'the',\n",
       " 'people',\n",
       " 'are',\n",
       " 'friendly',\n",
       " 'the',\n",
       " 'food',\n",
       " 'good',\n",
       " 'traditional',\n",
       " 'mom',\n",
       " 'pop',\n",
       " 'quality',\n",
       " 'and',\n",
       " 'perfection',\n",
       " 'the',\n",
       " 'best',\n",
       " 'fish',\n",
       " 'and',\n",
       " 'chips',\n",
       " 'you',\n",
       " \"'ll\",\n",
       " 'ever',\n",
       " 'enjoy',\n",
       " 'and',\n",
       " 'equally',\n",
       " 'superb',\n",
       " 'fried',\n",
       " 'shrimp',\n",
       " 'you',\n",
       " 'will',\n",
       " 'love',\n",
       " 'wonderful',\n",
       " 'reuben',\n",
       " 'good',\n",
       " 'fish',\n",
       " 'sandwich',\n",
       " 'this',\n",
       " 'hidden',\n",
       " 'gem',\n",
       " 'really',\n",
       " 'took',\n",
       " 'forever',\n",
       " 'find',\n",
       " 'but',\n",
       " 'well',\n",
       " 'worth',\n",
       " 'huge',\n",
       " 'sandwich',\n",
       " 'added']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize\n",
    "tokenized = text.split()\n",
    "tokenized = [i for i in tokenized if len(i)>2]\n",
    "tokenized[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['was',\n",
       " 'sadly',\n",
       " 'mistaken',\n",
       " 'the',\n",
       " 'hoagies',\n",
       " 'the',\n",
       " 'italian',\n",
       " 'general',\n",
       " 'run',\n",
       " 'the',\n",
       " 'mill',\n",
       " 'minimal',\n",
       " 'meat',\n",
       " 'and',\n",
       " 'ton',\n",
       " 'shredded',\n",
       " 'lettuce',\n",
       " 'nothing',\n",
       " 'really',\n",
       " 'special',\n",
       " 'not',\n",
       " 'worthy',\n",
       " 'the',\n",
       " '_num_',\n",
       " 'price',\n",
       " 'tag',\n",
       " 'second',\n",
       " 'the',\n",
       " 'steak',\n",
       " 'hoagie',\n",
       " 'atrocious',\n",
       " 'had',\n",
       " 'pay',\n",
       " '_num_',\n",
       " 'add',\n",
       " 'cheese',\n",
       " 'the',\n",
       " 'hoagie',\n",
       " 'she',\n",
       " 'told',\n",
       " 'there',\n",
       " 'was',\n",
       " 'charge',\n",
       " 'for',\n",
       " 'the',\n",
       " 'dressing',\n",
       " 'the',\n",
       " 'side',\n",
       " 'are',\n",
       " 'you',\n",
       " 'kidding',\n",
       " 'was',\n",
       " 'not',\n",
       " 'going',\n",
       " 'pay',\n",
       " 'for',\n",
       " 'the',\n",
       " 'dressing',\n",
       " 'the',\n",
       " 'side',\n",
       " 'ordered',\n",
       " 'without',\n",
       " 'lettuce',\n",
       " 'tomato',\n",
       " 'onions',\n",
       " 'dressing',\n",
       " 'are',\n",
       " 'you',\n",
       " 'kidding',\n",
       " 'paid',\n",
       " '_num_',\n",
       " 'add',\n",
       " 'sauted',\n",
       " 'mushrooms',\n",
       " 'onions',\n",
       " 'and',\n",
       " 'cheese',\n",
       " 'this',\n",
       " 'case',\n",
       " 'never',\n",
       " 'the',\n",
       " 'hoagie',\n",
       " 'bun',\n",
       " 'was',\n",
       " 'better',\n",
       " 'than',\n",
       " 'average',\n",
       " 'wake',\n",
       " 'you',\n",
       " 'are',\n",
       " 'going',\n",
       " 'lose',\n",
       " 'your',\n",
       " 'business',\n",
       " 'this',\n",
       " 'place',\n",
       " 'has',\n",
       " 'none',\n",
       " 'them',\n",
       " 'april']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_neg = text_neg.split()\n",
    "tokenized_neg = [i for i in tokenized_neg if len(i)>2]\n",
    "tokenized_neg[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "eng_stopwords = stopwords.words('english')\n",
    "tokenized = [word for word in tokenized if word not in eng_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_neg = [word for word in tokenized_neg if word not in eng_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('excellent', 'food'),\n",
       " ('food', 'superb'),\n",
       " ('superb', 'customer'),\n",
       " ('customer', 'service'),\n",
       " ('service', 'also'),\n",
       " ('also', 'daily'),\n",
       " ('daily', 'specials'),\n",
       " ('specials', 'ice'),\n",
       " ('ice', 'cream'),\n",
       " ('cream', 'really')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_pos = ngrams(tokenized,2)\n",
    "list(bigrams_pos)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sadly', 'mistaken'),\n",
       " ('mistaken', 'hoagies'),\n",
       " ('hoagies', 'italian'),\n",
       " ('italian', 'general'),\n",
       " ('general', 'run'),\n",
       " ('run', 'mill'),\n",
       " ('mill', 'minimal'),\n",
       " ('minimal', 'meat'),\n",
       " ('meat', 'ton'),\n",
       " ('ton', 'shredded')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_neg = ngrams(tokenized_neg,2)\n",
    "list(bigrams_neg)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('really', 'good')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_pos = ngrams(tokenized,2)\n",
    "bigrams_pos_list = list(bigrams_pos)\n",
    "bigrams_pos_list[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('shredded', 'lettuce')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_neg = ngrams(tokenized_neg,2)\n",
    "bigram_neg_list = list(bigrams_neg)\n",
    "bigram_neg_list[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_neg_list[10] in bigram_neg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_neg_list.index(bigram_neg_list[10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('love', 'place'), 4475),\n",
       " (('highly', 'recommend'), 4012),\n",
       " (('great', 'service'), 3778),\n",
       " (('great', 'food'), 3526),\n",
       " (('great', 'place'), 3122),\n",
       " (('food', 'great'), 2883),\n",
       " (('customer', 'service'), 2771),\n",
       " (('service', 'great'), 2701),\n",
       " (('good', 'food'), 2404),\n",
       " (('really', 'good'), 2224)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count freq of bigrams\n",
    "bigrams_pos = ngrams(tokenized,2)\n",
    "bigram_pos_freq = collections.Counter(bigrams_pos)\n",
    "bigram_pos_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('customer', 'service'), 3027),\n",
       " (('_num_', 'minutes'), 2621),\n",
       " (('_num_', '_num_'), 1673),\n",
       " ((\"n't\", 'even'), 1484),\n",
       " (('could', \"n't\"), 1036),\n",
       " (('would', \"n't\"), 961),\n",
       " (('going', 'back'), 949),\n",
       " (('_num_', 'stars'), 928),\n",
       " ((\"n't\", 'back'), 798),\n",
       " (('could', 'give'), 796)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count freq of bigrams\n",
    "bigrams_neg = ngrams(tokenized_neg,2)\n",
    "bigram_neg_freq = collections.Counter(bigrams_neg)\n",
    "bigram_neg_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_neg_freq[bigram_neg_list[10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_pos_freq[bigram_neg_list[10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigrams</th>\n",
       "      <th>pos_freq</th>\n",
       "      <th>neg_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(excellent, food)</td>\n",
       "      <td>651</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(food, superb)</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(superb, customer)</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(customer, service)</td>\n",
       "      <td>2771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(service, also)</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               bigrams  pos_freq  neg_freq\n",
       "0    (excellent, food)       651         0\n",
       "1       (food, superb)        43         0\n",
       "2   (superb, customer)        10         0\n",
       "3  (customer, service)      2771         0\n",
       "4      (service, also)       216         0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_all = []\n",
    "pos_freq = []\n",
    "neg_freq = []\n",
    "for i in bigram_pos_freq:\n",
    "    bigram_all.append(i)\n",
    "    pos_freq.append(bigram_pos_freq[i])\n",
    "    neg_freq.append(bigram_neg_freq[i])\n",
    "    del bigram_neg_freq[i] \n",
    "    #print(i, bigram_pos_freq[i])\n",
    "    \n",
    "for i in bigram_neg_freq:\n",
    "    bigram_all.append(i)\n",
    "    pos_freq.append(bigram_pos_freq[i])\n",
    "    neg_freq.append(bigram_neg_freq[i])\n",
    "    #del bigram_neg_freq[i] \n",
    "\n",
    "df['bigrams'] = bigram_all\n",
    "df['pos_freq'] = pos_freq\n",
    "df['neg_freq']= neg_freq\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigrams</th>\n",
       "      <th>pos_freq</th>\n",
       "      <th>neg_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>671289</th>\n",
       "      <td>(pass, nothing)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671290</th>\n",
       "      <td>(nothing, decided)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671291</th>\n",
       "      <td>(money, hear)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671292</th>\n",
       "      <td>(hear, takes)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671293</th>\n",
       "      <td>(even, dine-in)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   bigrams  pos_freq  neg_freq\n",
       "671289     (pass, nothing)         0         1\n",
       "671290  (nothing, decided)         0         1\n",
       "671291       (money, hear)         0         1\n",
       "671292       (hear, takes)         0         1\n",
       "671293     (even, dine-in)         0         1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('excellent', 'food')\n",
      "652.0\n",
      "----------------\n",
      "('food', 'superb')\n",
      "44.0\n",
      "----------------\n",
      "('superb', 'customer')\n",
      "11.0\n",
      "----------------\n",
      "('customer', 'service')\n",
      "2772.0\n",
      "----------------\n",
      "('service', 'also')\n",
      "217.0\n",
      "----------------\n",
      "('also', 'daily')\n",
      "5.0\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "sal = []\n",
    "lambda_ = 1\n",
    "for row in df.iterrows():\n",
    "    print(row[1]['bigrams'])\n",
    "    print((row[1]['pos_freq']+1)/(row[1]['neg_freq']+1))\n",
    "    print('----------------')\n",
    "    if(row[0]==5):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_calc(n, tokenized_neg=tokenized_neg, tokenized_pos=tokenized):\n",
    "    \n",
    "    bigrams_neg = ngrams(tokenized_neg,n)\n",
    "    bigram_neg_freq = collections.Counter(bigrams_neg)\n",
    "    \n",
    "    bigrams_pos = ngrams(tokenized_pos,n)\n",
    "    bigram_pos_freq = collections.Counter(bigrams_pos)\n",
    "\n",
    "    bigram_all = []\n",
    "    pos_freq = []\n",
    "    neg_freq = []\n",
    "    for i in bigram_pos_freq:\n",
    "        bigram_all.append(i)\n",
    "        pos_freq.append(bigram_pos_freq[i])\n",
    "        neg_freq.append(bigram_neg_freq[i])\n",
    "        del bigram_neg_freq[i] \n",
    "    #print(i, bigram_pos_freq[i])\n",
    "    \n",
    "    for i in bigram_neg_freq:\n",
    "        bigram_all.append(i)\n",
    "        pos_freq.append(bigram_pos_freq[i])\n",
    "        neg_freq.append(bigram_neg_freq[i])\n",
    "    #del bigram_neg_freq[i] \n",
    "    return bigram_all, pos_freq, neg_freq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fourgram</th>\n",
       "      <th>pos_freq_4</th>\n",
       "      <th>neg_freq_4</th>\n",
       "      <th>sal_4p</th>\n",
       "      <th>sal_4n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(excellent, food, superb, customer)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(food, superb, customer, service)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(superb, customer, service, also)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(customer, service, also, daily)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(service, also, daily, specials)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              fourgram  pos_freq_4  neg_freq_4  sal_4p  sal_4n\n",
       "0  (excellent, food, superb, customer)           1           0     2.0     0.5\n",
       "1    (food, superb, customer, service)           1           0     2.0     0.5\n",
       "2    (superb, customer, service, also)           1           0     2.0     0.5\n",
       "3     (customer, service, also, daily)           1           0     2.0     0.5\n",
       "4     (service, also, daily, specials)           1           0     2.0     0.5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_ = 1\n",
    "\n",
    "df = pd.DataFrame()\n",
    "bigram_all, pos_freq, neg_freq = ngram_calc(2)\n",
    "df['bigrams'] = bigram_all\n",
    "df['pos_freq_2'] = pos_freq\n",
    "df['neg_freq_2']= neg_freq\n",
    "sal_2p = []\n",
    "sal_2n = []\n",
    "for row in df.iterrows():\n",
    "    sal_2p.append((row[1]['pos_freq_2']+lambda_)/(row[1]['neg_freq_2']+lambda_))\n",
    "    sal_2n.append((row[1]['neg_freq_2']+lambda_)/(row[1]['pos_freq_2']+lambda_))\n",
    "df['sal_2p'] = sal_2p\n",
    "df['sal_2n'] = sal_2n\n",
    "df.to_csv('yelp/2salience.csv', index=False)\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "bigram_all, pos_freq, neg_freq = ngram_calc(1)\n",
    "df['unigrams'] = bigram_all\n",
    "df['pos_freq_1'] = pos_freq\n",
    "df['neg_freq_1']= neg_freq\n",
    "sal_2p = []\n",
    "sal_2n = []\n",
    "for row in df.iterrows():\n",
    "    sal_2p.append((row[1]['pos_freq_1']+lambda_)/(row[1]['neg_freq_1']+lambda_))\n",
    "    sal_2n.append((row[1]['neg_freq_1']+lambda_)/(row[1]['pos_freq_1']+lambda_))\n",
    "df['sal_1p'] = sal_2p\n",
    "df['sal_1n'] = sal_2n\n",
    "df.to_csv('yelp/1salience.csv', index=False)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "bigram_all, pos_freq, neg_freq = ngram_calc(3)\n",
    "df['trigrams'] = bigram_all\n",
    "df['pos_freq_3'] = pos_freq\n",
    "df['neg_freq_3']= neg_freq\n",
    "sal_2p = []\n",
    "sal_2n = []\n",
    "for row in df.iterrows():\n",
    "    sal_2p.append((row[1]['pos_freq_3']+lambda_)/(row[1]['neg_freq_3']+lambda_))\n",
    "    sal_2n.append((row[1]['neg_freq_3']+lambda_)/(row[1]['pos_freq_3']+lambda_))\n",
    "df['sal_3p'] = sal_2p\n",
    "df['sal_3n'] = sal_2n\n",
    "df.to_csv('yelp/3salience.csv', index=False)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "bigram_all, pos_freq, neg_freq = ngram_calc(4)\n",
    "df['fourgram'] = bigram_all\n",
    "df['pos_freq_4'] = pos_freq\n",
    "df['neg_freq_4']= neg_freq\n",
    "sal_2p = []\n",
    "sal_2n = []\n",
    "for row in df.iterrows():\n",
    "    sal_2p.append((row[1]['pos_freq_4']+lambda_)/(row[1]['neg_freq_4']+lambda_))\n",
    "    sal_2n.append((row[1]['neg_freq_4']+lambda_)/(row[1]['pos_freq_4']+lambda_))\n",
    "df['sal_4p'] = sal_2p\n",
    "df['sal_4n'] = sal_2n\n",
    "df.to_csv('yelp/4salience.csv', index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#>15 means attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = text.split('\\n')\n",
    "neg_list = text_neg.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 'fantastic wings that are crispy and delicious , wing night on tuesday and thursday !'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('fantastic',): 1,\n",
       "         ('wings',): 1,\n",
       "         ('crispy',): 1,\n",
       "         ('delicious',): 1,\n",
       "         ('wing',): 1,\n",
       "         ('night',): 1,\n",
       "         ('tuesday',): 1,\n",
       "         ('thursday',): 1})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = t.split()\n",
    "token = [i for i in token if len(i)>2]\n",
    "token = [word for word in token if word not in eng_stopwords]\n",
    "t_unigram = ngrams(token,1)\n",
    "t_unigram_freq = collections.Counter(t_unigram)\n",
    "t_unigram_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unigrams</th>\n",
       "      <th>pos_freq_1</th>\n",
       "      <th>neg_freq_1</th>\n",
       "      <th>sal_1p</th>\n",
       "      <th>sal_1n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('excellent',)</td>\n",
       "      <td>7313</td>\n",
       "      <td>44</td>\n",
       "      <td>162.533333</td>\n",
       "      <td>0.006153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('food',)</td>\n",
       "      <td>25773</td>\n",
       "      <td>8583</td>\n",
       "      <td>3.002563</td>\n",
       "      <td>0.333049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('superb',)</td>\n",
       "      <td>473</td>\n",
       "      <td>5</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>0.012658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('customer',)</td>\n",
       "      <td>3236</td>\n",
       "      <td>3747</td>\n",
       "      <td>0.863661</td>\n",
       "      <td>1.157862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('service',)</td>\n",
       "      <td>22599</td>\n",
       "      <td>10325</td>\n",
       "      <td>2.188650</td>\n",
       "      <td>0.456903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         unigrams  pos_freq_1  neg_freq_1      sal_1p    sal_1n\n",
       "0  ('excellent',)        7313          44  162.533333  0.006153\n",
       "1       ('food',)       25773        8583    3.002563  0.333049\n",
       "2     ('superb',)         473           5   79.000000  0.012658\n",
       "3   ('customer',)        3236        3747    0.863661  1.157862\n",
       "4    ('service',)       22599       10325    2.188650  0.456903"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uni = pd.read_csv('yelp/1salience.csv')\n",
    "df_uni.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fourgram</th>\n",
       "      <th>pos_freq_4</th>\n",
       "      <th>neg_freq_4</th>\n",
       "      <th>sal_4p</th>\n",
       "      <th>sal_4n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('excellent', 'food', 'superb', 'customer')</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('food', 'superb', 'customer', 'service')</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('superb', 'customer', 'service', 'also')</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('customer', 'service', 'also', 'daily')</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('service', 'also', 'daily', 'specials')</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      fourgram  pos_freq_4  neg_freq_4  \\\n",
       "0  ('excellent', 'food', 'superb', 'customer')           1           0   \n",
       "1    ('food', 'superb', 'customer', 'service')           1           0   \n",
       "2    ('superb', 'customer', 'service', 'also')           1           0   \n",
       "3     ('customer', 'service', 'also', 'daily')           1           0   \n",
       "4     ('service', 'also', 'daily', 'specials')           1           0   \n",
       "\n",
       "   sal_4p  sal_4n  \n",
       "0     2.0     0.5  \n",
       "1     2.0     0.5  \n",
       "2     2.0     0.5  \n",
       "3     2.0     0.5  \n",
       "4     2.0     0.5  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 4\n",
    "dfname = 'yelp/'+str(n)+'salience.csv'\n",
    "df_t = pd.read_csv(dfname)\n",
    "df_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"('excellent', 'food', 'superb', 'customer')\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t['fourgram'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fourgram</th>\n",
       "      <th>pos_freq_4</th>\n",
       "      <th>neg_freq_4</th>\n",
       "      <th>sal_4p</th>\n",
       "      <th>sal_4n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [fourgram, pos_freq_4, neg_freq_4, sal_4p, sal_4n]\n",
       "Index: []"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.loc[df_t['fourgram'].isin(('excellent','food','superb','customer'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fourgram</th>\n",
       "      <th>pos_freq_4</th>\n",
       "      <th>neg_freq_4</th>\n",
       "      <th>sal_4p</th>\n",
       "      <th>sal_4n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('excellent', 'food', 'superb', 'customer')</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      fourgram  pos_freq_4  neg_freq_4  \\\n",
       "0  ('excellent', 'food', 'superb', 'customer')           1           0   \n",
       "\n",
       "   sal_4p  sal_4n  \n",
       "0     2.0     0.5  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.loc[df_t['fourgram'] == str(('excellent', 'food', 'superb', 'customer'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_attr(t,n, typ='p', gamma=15):\n",
    "    token = t.split()\n",
    "    token = [i for i in token if len(i)>2]\n",
    "    token = [word for word in token if word not in eng_stopwords]\n",
    "    t_unigram = ngrams(token,n)\n",
    "    t_unigram_freq = collections.Counter(t_unigram)\n",
    "    attr = []\n",
    "    content = []\n",
    "    col_names = {1:'unigrams', 2:'bigrams', 3:'trigrams', 4:'fourgram'}\n",
    "    col_sal = 'sal_'+str(n)+typ\n",
    "    dfname = 'yelp/'+str(n)+'salience.csv'\n",
    "    df_uni = pd.read_csv(dfname)#, index=False)\n",
    "    for uni in t_unigram_freq.elements():\n",
    "        #print(str(uni))\n",
    "        #print(df_uni.loc[df_uni['fourgram'] == str(uni)])\n",
    "        qs = df_uni[col_sal].loc[df_uni[col_names[n]] == str(uni)]\n",
    "        if(len(qs)>0):\n",
    "            if(gamma <= float(qs)):\n",
    "                attr.append(uni[0])\n",
    "    #print(attr)\n",
    "        \n",
    "    for tw in t.split():\n",
    "        if(tw not in attr):\n",
    "            content.append(tw)\n",
    "\n",
    "    content = ' '.join(content)\n",
    "    attr = ' '.join(attr)\n",
    "    return content, attr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fantastic wings that are crispy and excellent food superb customer delicious , wing night on tuesday and thursday !\n",
      "fantastic wings that are crispy and food superb customer , night on tuesday and thursday !\n",
      "excellent delicious wing\n"
     ]
    }
   ],
   "source": [
    "t = 'fantastic wings that are crispy and excellent food superb customer delicious , wing night on tuesday and thursday !'\n",
    "c,a= text_to_attr(t,4,'p',1)\n",
    "print(t)\n",
    "print(c)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = pd.DataFrame()\n",
    "a1 = []\n",
    "c1 = []\n",
    "a2 = []\n",
    "c2 = []\n",
    "a3 = []\n",
    "c3 = []\n",
    "a4 = []\n",
    "c4 = []\n",
    "tt = []\n",
    "senti = []\n",
    "for t in pos_list:\n",
    "    tt.append(t)\n",
    "    senti.append('POS')\n",
    "    c,a = text_to_attr(t,1,'p')\n",
    "    a1.append(a)\n",
    "    c1.append(c)\n",
    "for t in neg_list:\n",
    "    tt.append(t)\n",
    "    senti.append('NEG')\n",
    "    c,a = text_to_attr(t,1,'n')\n",
    "    a1.append(a)\n",
    "    c1.append(c)\n",
    "    \n",
    "df_text['sentence'] = tt\n",
    "df_text['sentiment'] = senti\n",
    "df_text['c1'] = c1\n",
    "df_text['a1'] = a1\n",
    "\n",
    "df_text.to_csv('yelp/clean_text_unigrams.csv', index=False)\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = pd.DataFrame()\n",
    "a1 = []\n",
    "c1 = []\n",
    "a2 = []\n",
    "c2 = []\n",
    "a3 = []\n",
    "c3 = []\n",
    "a4 = []\n",
    "c4 = []\n",
    "tt = []\n",
    "senti = []\n",
    "for t in pos_list:\n",
    "    tt.append(t)\n",
    "    senti.append('POS')\n",
    "    c,a = text_to_attr(t,1,'p')\n",
    "    a1.append(a)\n",
    "    c1.append(c)\n",
    "    c,a = text_to_attr(t,2,'p')\n",
    "    a2.append(a)\n",
    "    c2.append(c)\n",
    "    c,a = text_to_attr(t,3,'p')\n",
    "    a3.append(a)\n",
    "    c3.append(c)\n",
    "    c,a = text_to_attr(t,4,'p')\n",
    "    a4.append(a)\n",
    "    c4.append(c)\n",
    "for t in neg_list:\n",
    "    tt.append(t)\n",
    "    senti.append('NEG')\n",
    "    c,a = text_to_attr(t,1,'n')\n",
    "    a1.append(a)\n",
    "    c1.append(c)\n",
    "    c,a = text_to_attr(t,2,'n')\n",
    "    a2.append(a)\n",
    "    c2.append(c)\n",
    "    c,a = text_to_attr(t,3,'n')\n",
    "    a3.append(a)\n",
    "    c3.append(c)\n",
    "    c,a = text_to_attr(t,4,'n')\n",
    "    a4.append(a)\n",
    "    c4.append(c)\n",
    "    \n",
    "df_text['sentence'] = tt\n",
    "df_text['sentiment'] = senti\n",
    "df_text['c1'] = c1\n",
    "df_text['a1'] = a1\n",
    "df_text['c2'] = c2\n",
    "df_text['a2'] = a2\n",
    "df_text['c3'] = c3\n",
    "df_text['a3'] = a3\n",
    "df_text['c4'] = c4\n",
    "df_text['a4'] = a4\n",
    "df_text.to_csv('yelp/clean_text.csv', index=False)\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
