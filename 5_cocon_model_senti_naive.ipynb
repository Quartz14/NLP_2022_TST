{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcfYGRvnRUvW",
        "outputId": "31de46a3-5623-4ca4-e572-3f63f9a0200b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 37.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 25.9 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 48.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cSRDouXJl1X",
        "outputId": "8597666b-ab75-4f89-e2df-e7183722f2f1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvieVnQBJzEO",
        "outputId": "53048095-6d84-4f96-8603-1dadf8ab1e17"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtaolOkkT6HC",
        "outputId": "0998cfa9-2b6a-4334-d499-551404f26021"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.0.0-py3-none-any.whl (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 45.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.63.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 25.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 48.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 50.3 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 49.4 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 796 kB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 41.3 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.0.0 frozenlist-1.3.0 fsspec-2022.3.0 multidict-6.0.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkrx4IV2R0bo",
        "outputId": "83a61491-4211-4f50-93c7-3b28ee651da6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.6.1-py3-none-any.whl (65 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████                           | 10 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 20 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 30 kB 27.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 40 kB 31.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 51 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 65 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.21.5)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->accelerate) (3.10.0.2)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import Accelerator\n",
        "\n",
        "accelerator = Accelerator()\n",
        "\n",
        "device = accelerator.device"
      ],
      "metadata": {
        "id": "i_wUBQ7LRzcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-kzY3bCSryZ",
        "outputId": "54a590c9-1239-43aa-904d-fd5793241a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XYw8QPQvXiEd"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import math\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "from transformers.activations import gelu_new\n",
        "from transformers import GPT2Model, GPT2Config\n",
        "import argparse\n",
        "import glob\n",
        "import logging\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import re\n",
        "import shutil\n",
        "from typing import Dict, List, Tuple\n",
        "import json\n",
        "#import wget\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.distributed import get_rank, get_world_size\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from torch.nn import functional as F\n",
        "from torch.nn.modules.normalization import LayerNorm\n",
        "from torch.nn.modules import ModuleList\n",
        "import copy\n",
        "\n",
        "from transformers import AdamW, GPT2Config, GPT2LMHeadModel, GPT2Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "l3SwL9idXiEp"
      },
      "outputs": [],
      "source": [
        "class Conv1D(nn.Module):\n",
        "    def __init__(self, nx, nf):\n",
        "        super().__init__()\n",
        "        self.nf = nf\n",
        "        w = torch.empty(nx, nf)\n",
        "        nn.init.normal_(w, std=0.02)\n",
        "        self.weight = nn.Parameter(w)\n",
        "        self.bias = nn.Parameter(torch.zeros(nf))\n",
        "\n",
        "    def forward(self, x):\n",
        "        size_out = x.size()[:-1] + (self.nf,)\n",
        "        x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\n",
        "        x = x.view(*size_out)\n",
        "        return x\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dropout, d_model=768, nx=768*4):\n",
        "        super().__init__()\n",
        "        self.c_fc    = Conv1D(d_model, nx)\n",
        "        self.c_proj  = Conv1D(nx, d_model)\n",
        "        self.act     = F.gelu\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.dropout(self.c_proj(self.act(self.c_fc(x))))\n",
        "    \n",
        "\n",
        "\n",
        "def _get_clones(module, n):\n",
        "    return ModuleList([copy.deepcopy(module) for i in range(n)])\n",
        "    \n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, d_model=768, n_head=12, n_ctx=1024, d_head=64, bias=True, scale=False):\n",
        "        super().__init__()\n",
        "        self.n_head  = n_head\n",
        "        self.d_model = d_model\n",
        "        self.c_attn  = Conv1D(d_model, d_model*3)\n",
        "        self.scale   = scale\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(n_ctx, n_ctx)).view(1, 1, n_ctx, n_ctx))\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.c_proj  = Conv1D(d_model, d_model)\n",
        "        \n",
        "    def split_heads(self, x):\n",
        "        \"return shape [`batch`, `head`, `sequence`, `features`]\"\n",
        "        new_shape = x.size()[:-1] + (self.n_head, x.size(-1)//self.n_head) \n",
        "        x = x.view(*new_shape)\n",
        "        return x.permute(0, 2, 1, 3) \n",
        "    \n",
        "    def _attn(self, q, k, v, attn_mask=None):\n",
        "        scores  = torch.matmul(q, k.transpose(-2, -1))\n",
        "        if self.scale: scores = scores/math.sqrt(v.size(-1))\n",
        "        nd, ns  = scores.size(-2), scores.size(-1)\n",
        "        if attn_mask is not None: scores = scores + attn_mask\n",
        "        scores  = self.softmax(scores)\n",
        "        scores  = self.dropout(scores)\n",
        "        outputs = torch.matmul(scores, v)\n",
        "        return outputs\n",
        "    \n",
        "    def merge_heads(self, x):\n",
        "        x         = x.permute(0, 2, 1, 3).contiguous()\n",
        "        new_shape = x.size()[:-2] + (x.size(-2)*x.size(-1),)\n",
        "        return x.view(*new_shape)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x        = self.c_attn(x) #new `x` shape - `[1,3,2304]`\n",
        "        q, k, v  = x.split(self.d_model, dim=2)\n",
        "        q, k, v  = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n",
        "        out      = self._attn(q, k, v)\n",
        "        out      = self.merge_heads(out)\n",
        "        out      = self.c_proj(out)\n",
        "        return out\n",
        "    \n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, d_model=768, n_head=12, dropout=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.attn        = Attention(d_model=768, n_head=12, d_head=64, n_ctx=1024, bias=True, scale=False)\n",
        "        self.feedforward = FeedForward(dropout=0.1, d_model=768, nx=768*4)\n",
        "        self.ln_1        = LayerNorm(d_model)\n",
        "        self.ln_2        = LayerNorm(d_model)\n",
        "                \n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        x = x + self.feedforward(self.ln_2(x))\n",
        "        return x\n",
        "    \n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self, nlayers=12, n_ctx=1024, d_model=768, vcb_sz=50257):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.nlayers = nlayers\n",
        "        block        = TransformerBlock(d_model=768, n_head=12, dropout=0.1)\n",
        "        self.h       = _get_clones(block, nlayers)\n",
        "        self.wte     = nn.Embedding(vcb_sz, d_model)\n",
        "        self.wpe     = nn.Embedding(n_ctx, d_model)\n",
        "        self.drop    = nn.Dropout(0.1)\n",
        "        self.ln_f    = LayerNorm(d_model)\n",
        "        self.out     = nn.Linear(d_model, vcb_sz, bias=False)\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "        self.init_weights()\n",
        "        #self.temp = TransformerBlockc()\n",
        "        from transformers import GPT2Tokenizer\n",
        "        self.tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "        #self.n  = torch.tensor(tokenizer.encode('Negative')).type(torch.LongTensor)\n",
        "    \n",
        "    def init_weights(self):\n",
        "        self.out.weight = self.wte.weight\n",
        "        self.apply(self._init_weights)\n",
        "    \n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding, Conv1D)):\n",
        "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
        "            if isinstance(module, (nn.Linear, Conv1D)) and module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "            \n",
        "    def prepare_embeds_inputs_for_generation(self, inputs_embeds, **kwargs):\n",
        "        # only last token for inputs_ids if past is defined in kwargs\n",
        "        if \"past\" in kwargs and kwargs[\"past\"]:\n",
        "            inputs_embeds = inputs_embeds[:, -1:, :]\n",
        "\n",
        "        inputs = {\"inputs_embeds\": inputs_embeds}\n",
        "        inputs.update(kwargs)\n",
        "        return inputs\n",
        "\n",
        "    def prepare_hidden_state_inputs_for_generation(self, input_hidden_state, **kwargs):\n",
        "        # only last token for inputs_ids if past is defined in kwargs\n",
        "        if \"past\" in kwargs and kwargs[\"past\"]:\n",
        "            input_hidden_state = input_hidden_state[:, -1:, :]\n",
        "\n",
        "        inputs = {\"input_hidden_state\": input_hidden_state}\n",
        "        inputs.update(kwargs)\n",
        "        return inputs\n",
        "            \n",
        "\n",
        "    def forward_half1(self,src, labels=None, pos_ids=None, inputs_embeds=None):\n",
        "        if(inputs_embeds): #x=src is input embeds\n",
        "            if pos_ids is None: pos_ids = torch.arange(0, src.size(-2)).unsqueeze(0)\n",
        "            wpe2 = nn.Embedding(src.size(-2), 768).to(device)\n",
        "            pos_ids = pos_ids.to(device)\n",
        "            position_embeds = wpe2(pos_ids).to(device)\n",
        "            inp = self.drop(src + position_embeds)\n",
        "            \n",
        "        else:\n",
        "            if pos_ids is None: pos_ids = torch.arange(0, src.size(-1)).unsqueeze(0)\n",
        "            pos_ids = pos_ids.to(device)\n",
        "            position_embeds = self.wpe(pos_ids)\n",
        "            position_embeds=position_embeds.to(device)\n",
        "\n",
        "            inp = self.drop((self.wte(src)+position_embeds))\n",
        "            \n",
        "        #inp = self.drop((self.wte(src)+self.wpe(pos_ids)))\n",
        "        for i in range(6): inp = self.h[i](inp)\n",
        "        return inp\n",
        "        \n",
        "    \n",
        "    def forward_half2(self, inp,labels=None, pos_ids=None,lm_logit_first_index=0,lm_logit_last_index=-1,\n",
        "                     lm_labels_first_index=1, lm_labels_last_index=None):\n",
        "        for i in range(6,12): inp = self.h[i](inp)\n",
        "        inp     = self.ln_f(inp)\n",
        "        logits  = self.out(inp)\n",
        "        outputs = (logits,) + (inp,)\n",
        "        \n",
        "        if labels is not None:\n",
        "            # Shift so that tokens < n predict n\n",
        "            shift_logits = logits[..., lm_logit_first_index:lm_logit_last_index, :].contiguous() # default lm_logit_first_index=0, lm_logit_last_index=-1,\n",
        "            shift_labels = labels[..., lm_labels_first_index:lm_labels_last_index].contiguous() # default lm_labels_first_index=1, lm_labels_last_index=None,\n",
        "\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "\n",
        "            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
        "            outputs = (loss,) + outputs\n",
        "\n",
        "        return outputs,logits\n",
        "    \"\"\"\n",
        "   \n",
        "    def cocon(self,inp,content):\n",
        "        #content = torch.tensor(self.tokenizer.encode(content))#.long()\n",
        "        content = self.forward_half1(content)\n",
        "        x  = self.temp(inp,content)\n",
        "        h_t_2 = x[:,:-1,:]\n",
        "        h_t_1 = x[:,-1,:]\n",
        "        h_t_1 = torch.unsqueeze(h_t_1, 1)\n",
        "        h_ = torch.cat([h_t_2,h_t_1],dim=1)\n",
        "        return h_\n",
        "        \"\"\" \n",
        "    \n",
        "    def forward(self, x,labels=None,path='all',lm_logit_first_index=0,lm_logit_last_index=-1,\n",
        "                     lm_labels_first_index=1, lm_labels_last_index=None, inputs_embeds=None):\n",
        "        \n",
        "        if path=='all':\n",
        "            x = self.forward_half1(x,inputs_embeds=inputs_embeds)\n",
        "            #x = self.cocon(x,content)\n",
        "            x = self.forward_half2(x,labels)\n",
        "        elif path=='half1':\n",
        "            x = self.forward_half1(x,inputs_embeds=inputs_embeds)\n",
        "        elif path=='half2':\n",
        "            x = self.forward_half2(x,labels,lm_logit_first_index=0,lm_logit_last_index=-1,\n",
        "                     lm_labels_first_index=1, lm_labels_last_index=None)\n",
        "        #elif path=='cocon':\n",
        "        #    x = self.cocon(x,content)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tXTPbbZjXiEx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "2a6bd9fdbb024172a08d11abbdb2425c",
            "3ce174e233154761838022e1307cd765",
            "c00e9ad55a5346ea8487a60d98475fae",
            "2bab84c13bec4f61bf9900d16e9f9b02",
            "80a7c124413449e5be4619acfc532f43",
            "d62642036d324a9c899f81528b2dde40",
            "8397a18124f94ae19bab54d3489c2fc4",
            "4e321c03bad14308a5560ffe4b56a93c",
            "c112ddd57cfa4bfd862914839d0997d6",
            "db5450616b5744e086b25e7c24df278e",
            "2bab2322b9574681b7c90a9526416d59",
            "ace73dd7adc54db1b0a75df58b149c8a",
            "4d379d0d4b3c44379105e42220956e3f",
            "b0e1a246756e4c69835ea6d3b2d89505",
            "8ae6c82a83d74acaa58b38fcd3074bab",
            "44a6153dcd05474884b83cd099e1dc11",
            "665dd107c46a4e20914151cad8d1e96d",
            "62f5768887914e17bdb15341030d6991",
            "00ff0f3d1d474a0eb420dba78a1eaf1f",
            "16835e017c0544f9bcf4a8790e58b5c7",
            "525e22a8e6cd4132959d3d89a6662277",
            "1ec1e44f04ac473cb8680fd9a7c36876",
            "7c1ddcd2434c49a7a268b6b5d5be5fe2",
            "ea91fd7e371b4953a6fa5c4001c11ccc",
            "ee6e5215d0654ded990ab23c3d6c1754",
            "ca452d1fb18f4836af053e97537a9c9a",
            "cf01d95477aa4585b1c5476e1d43f6e6",
            "be8322770ab341b69dad3a0cc50e9bae",
            "2f2036a492d94a84ad53afafb606be2f",
            "1b225e4bb91c438085ee43ef88460b7e",
            "bdf7b8fb21664c10b6b71a44c88fd02f",
            "1a22298f2c274837b9fa7234cda12d21",
            "e96e4dfbd70447009722b3c4cd2295a7"
          ]
        },
        "outputId": "7546f4f6-19a1-4219-ad6a-dfd755c19d5d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a6bd9fdbb024172a08d11abbdb2425c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ace73dd7adc54db1b0a75df58b149c8a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c1ddcd2434c49a7a268b6b5d5be5fe2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HbvLKU2yXiEy"
      },
      "outputs": [],
      "source": [
        "model = MyModel()\n",
        "model_dict = model.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CXbf-366XiE0"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "    #print(param)\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "mount='/content/gdrive'\n",
        "print(\"Colab: mounting Google drive on \", mount)\n",
        "\n",
        "drive.mount(mount)\n",
        "# Switch to the directory on the Google Drive that you want to use\n",
        "import os\n",
        "drive_root = mount + \"/My Drive/NLP-project-2022/\"\n",
        "%cd $drive_root"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64HOE1TwXuGs",
        "outputId": "c6cdfc81-e15a-41b2-f217-b20947bc3598"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab: mounting Google drive on  /content/gdrive\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/NLP-project-2022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "pl04Nbb-JxYl",
        "outputId": "997fa75d-4548-4d9e-d08b-e932dfb91319"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/NLP-project-2022'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NTR5gTk7XiE1"
      },
      "outputs": [],
      "source": [
        "state_dict = torch.load(\"gpt_wt/gpt2-pytorch_model.bin\") #pretrained weights\n",
        "\n",
        "old_keys = []\n",
        "new_keys = []\n",
        "for key in state_dict.keys(): \n",
        "    if \"mlp\" in key: #The hugging face state dict references the feedforward network as mlp, need to replace to `feedforward` be able to reuse these weights\n",
        "        new_key = key.replace(\"mlp\", \"feedforward\")\n",
        "        new_keys.append(new_key)\n",
        "        old_keys.append(key)\n",
        "\n",
        "for old_key, new_key in zip(old_keys, new_keys): \n",
        "    state_dict[new_key]=state_dict.pop(old_key)\n",
        "\n",
        "pretrained_dict = {k: v for k, v in state_dict.items() if k in model_dict}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-8mLZcaXiE2",
        "outputId": "9cb968b3-5107-4d8f-9296-9b6dcfc2d24c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "model_dict.update(pretrained_dict)\n",
        "model.load_state_dict(model_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "UBlAnAI2KXdt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3atiPh6OXiE6"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "model.zero_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FVd6baWDXiE8"
      },
      "outputs": [],
      "source": [
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "l7aHrv5eXiE9"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers.modeling_utils import Conv1D, PreTrainedModel, SequenceSummary, prune_conv1d_layer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GwCjkl0fXiE_"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, n_state, config):  # in MLP: n_state=3072 (4 * n_embd)\n",
        "        super().__init__()\n",
        "        nx = config.n_embd\n",
        "        self.c_fc = Conv1D(n_state, nx)\n",
        "        self.c_proj = Conv1D(nx, n_state)\n",
        "        self.act = gelu_new\n",
        "        self.dropout = nn.Dropout(config.resid_pdrop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.act(self.c_fc(x))\n",
        "        h2 = self.c_proj(h)\n",
        "        return self.dropout(h2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "D5XO0YXPXiFA"
      },
      "outputs": [],
      "source": [
        "class CoconAttention(nn.Module):\n",
        "    def __init__(self, nx, n_ctx, config, scale=False):\n",
        "        super().__init__()\n",
        "        self.output_attentions = config.output_attentions\n",
        "\n",
        "        n_state = nx  # in Attention: n_state=768 (nx=n_embd)\n",
        "        # [switch nx => n_state from Block to Attention to keep identical to TF implem]\n",
        "        assert n_state % config.n_head == 0\n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(n_ctx, n_ctx)).view(1, 1, n_ctx, n_ctx))\n",
        "\n",
        "        self_token_mask = torch.ones(n_ctx, n_ctx)\n",
        "        self_token_mask.fill_diagonal_(0)\n",
        "        self.register_buffer(\"self_token_mask\", self_token_mask.view(1, 1, n_ctx, n_ctx))\n",
        "        self.n_head = config.n_head\n",
        "        self.split_size = n_state\n",
        "        self.scale = scale\n",
        "\n",
        "        self.ref_source_attn = Conv1D(n_state * 2, nx)\n",
        "        self.c_attn = Conv1D(n_state * 3, nx) # input has dim of nx\n",
        "        self.c_proj = Conv1D(n_state, nx)\n",
        "        self.attn_dropout = nn.Dropout(config.attn_pdrop)\n",
        "        self.resid_dropout = nn.Dropout(config.resid_pdrop)\n",
        "        self.pruned_heads = set()\n",
        "\n",
        "    def prune_heads(self, heads):\n",
        "        if len(heads) == 0:\n",
        "            return\n",
        "        mask = torch.ones(self.n_head, self.split_size // self.n_head)\n",
        "        heads = set(heads) - self.pruned_heads  # Convert to set and emove already pruned heads\n",
        "        for head in heads:\n",
        "            # Compute how many pruned heads are before the head and move the index accordingly\n",
        "            head = head - sum(1 if h < head else 0 for h in self.pruned_heads)\n",
        "            mask[head] = 0\n",
        "        mask = mask.view(-1).contiguous().eq(1)\n",
        "        index = torch.arange(len(mask))[mask].long()\n",
        "        index_attn = torch.cat([index, index + self.split_size, index + (2 * self.split_size)])\n",
        "\n",
        "        # Prune conv1d layers\n",
        "        self.c_attn = prune_conv1d_layer(self.c_attn, index_attn, dim=1)\n",
        "        self.c_proj = prune_conv1d_layer(self.c_proj, index, dim=0)\n",
        "\n",
        "        # Update hyper params\n",
        "        self.split_size = (self.split_size // self.n_head) * (self.n_head - len(heads))\n",
        "        self.n_head = self.n_head - len(heads)\n",
        "        self.pruned_heads = self.pruned_heads.union(heads)\n",
        "\n",
        "    def _attn(self, q, k, v, attention_mask=None, head_mask=None, cs_self_attn_mask_prob=0, history_seq_len=None, context_seq_present=True, context_seq_len=0, context_attn_bias=0, context_seq_len_list=None):\n",
        "        w = torch.matmul(q, k)\n",
        "        if self.scale:\n",
        "            w = w / math.sqrt(v.size(-1))\n",
        "        nd, ns = w.size(-2), w.size(-1)\n",
        "        b = self.bias[:, :, ns - nd : ns, :ns]\n",
        "        w = w * b - 1e4 * (1 - b)\n",
        "\n",
        "        # self_token_mask computation\n",
        "        if cs_self_attn_mask_prob > 0 and context_seq_present:\n",
        "            if history_seq_len == 0:\n",
        "                history_seq_offset = 0\n",
        "            else:\n",
        "                history_seq_offset = history_seq_len - 1\n",
        "            self_token_mask = self.self_token_mask[:, :, :nd, history_seq_offset:history_seq_offset+ns]\n",
        "            self_token_mask = self_token_mask.repeat(w.shape[0],1,1,1)\n",
        "\n",
        "            if cs_self_attn_mask_prob != 1:\n",
        "                # compute unmasked indices\n",
        "                self_token_unmask_prob = 1 - cs_self_attn_mask_prob\n",
        "                unmask_prob_matrix = torch.full(self_token_mask.shape[:-1], self_token_unmask_prob)\n",
        "                unmasked_indices = torch.bernoulli(unmask_prob_matrix).bool()\n",
        "                self_token_mask[unmasked_indices] = 1\n",
        "\n",
        "            w = w * self_token_mask - 1e4 * (1 - self_token_mask)\n",
        "            \n",
        "        \n",
        "        if context_attn_bias != 0:\n",
        "            if context_seq_len_list is None:\n",
        "                context_attn_bias_mask = torch.ones(w.shape) # N, H, Q, V\n",
        "                context_attn_bias_mask[:,:,:, :context_seq_len] = 0\n",
        "                context_attn_bias_mask = context_attn_bias_mask.to(w.device)\n",
        "                w = w + context_attn_bias * (1 - context_attn_bias_mask)     \n",
        "            else:\n",
        "                current_context_start_ind = 0\n",
        "                for cs_ind, current_context_seq_len in enumerate(context_seq_len_list):\n",
        "                    current_context_attn_bias = context_attn_bias[cs_ind]\n",
        "                    context_attn_bias_mask = torch.ones(w.shape)\n",
        "                    context_attn_bias_mask[:,:,:, current_context_start_ind:(current_context_start_ind+current_context_seq_len)] = 0\n",
        "                    context_attn_bias_mask = context_attn_bias_mask.to(w.device)\n",
        "                    w = w + current_context_attn_bias * (1 - context_attn_bias_mask)\n",
        "                    current_context_start_ind = current_context_start_ind + current_context_seq_len\n",
        "\n",
        "            \n",
        "        if attention_mask is not None:\n",
        "            # Apply the attention mask\n",
        "            w = w + attention_mask\n",
        "\n",
        "        w = nn.Softmax(dim=-1)(w)\n",
        "        w = self.attn_dropout(w)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            w = w * head_mask\n",
        "\n",
        "        outputs = [torch.matmul(w, v)]\n",
        "        if self.output_attentions:\n",
        "            outputs.append(w)\n",
        "        return outputs\n",
        "\n",
        "    def merge_heads(self, x):\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        new_x_shape = x.size()[:-2] + (x.size(-2) * x.size(-1),)\n",
        "        return x.view(*new_x_shape)  # in Tensorflow implem: fct merge_states\n",
        "\n",
        "    def split_heads(self, x, k=False):\n",
        "        new_x_shape = x.size()[:-1] + (self.n_head, x.size(-1) // self.n_head)\n",
        "        x = x.view(*new_x_shape)  # in Tensorflow implem: fct split_states\n",
        "        if k:\n",
        "            return x.permute(0, 2, 3, 1)  # (batch, head, head_features, seq_length)\n",
        "        else:\n",
        "            return x.permute(0, 2, 1, 3)  # (batch, head, seq_length, head_features)\n",
        "\n",
        "    def forward(self, x, context_seq, layer_past=None, attention_mask=None, head_mask=None, cs_self_attn_mask_prob=0, history_seq_len=None, context_attn_bias=0, context_seq_len_list=None):\n",
        "        x = self.c_attn(x)\n",
        "        query, key, value = x.split(self.split_size, dim=2)\n",
        "\n",
        "        if context_seq is not None:\n",
        "            context_seq_len = context_seq.shape[1]\n",
        "            context_seq = self.ref_source_attn(context_seq)\n",
        "            key_context_seq, value_context_seq = context_seq.split(self.split_size, dim=2)\n",
        "\n",
        "            # Prepend keys and values with context_seq keys and values\n",
        "            prepended_key = torch.cat([key_context_seq, key], dim=1)\n",
        "            prepended_value = torch.cat([value_context_seq, value], dim=1)\n",
        "            context_seq_present = True\n",
        "        else:\n",
        "            context_seq_len = 0\n",
        "            prepended_key = key\n",
        "            prepended_value = value\n",
        "            context_seq_present = False\n",
        "\n",
        "        query = self.split_heads(query)\n",
        "        prepended_key = self.split_heads(prepended_key, k=True)\n",
        "        prepended_value = self.split_heads(prepended_value)\n",
        "\n",
        "        key = self.split_heads(key, k=True)\n",
        "        value = self.split_heads(value)\n",
        "\n",
        "        if layer_past is not None:\n",
        "            past_key, past_value = layer_past[0].transpose(-2, -1), layer_past[1]  # transpose back cf below\n",
        "            key = torch.cat((past_key, key), dim=-1)\n",
        "            value = torch.cat((past_value, value), dim=-2)\n",
        "\n",
        "        present = torch.stack((key.transpose(-2, -1), value))  # transpose to have same shapes for stacking\n",
        "        attn_outputs = self._attn(query, prepended_key, prepended_value, attention_mask, head_mask, cs_self_attn_mask_prob=cs_self_attn_mask_prob, history_seq_len=history_seq_len, context_seq_present=context_seq_present, \n",
        "                                    context_seq_len=context_seq_len, context_attn_bias=context_attn_bias, context_seq_len_list=context_seq_len_list)\n",
        "\n",
        "        a = attn_outputs[0]\n",
        "        a = self.merge_heads(a)\n",
        "        a = self.c_proj(a)\n",
        "        a = self.resid_dropout(a)\n",
        "\n",
        "        outputs = [a, present] + attn_outputs\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WXKVrEc5XiFD"
      },
      "outputs": [],
      "source": [
        "class CoconBlock(nn.Module):\n",
        "    def __init__(self, n_ctx, config, scale=False):\n",
        "        super().__init__()\n",
        "        logger.info( \"CoconBlock initialized\")\n",
        "        nx = config.n_embd\n",
        "        self.ln_1 = nn.LayerNorm(nx, eps=config.layer_norm_epsilon)\n",
        "\n",
        "        self.sos_h = nn.Parameter(torch.zeros(nx))\n",
        "        self.mask_h = nn.Parameter(torch.zeros(nx))\n",
        "\n",
        "        self.cocon_attn = CoconAttention(nx, n_ctx, config, scale)\n",
        "        self.ln_2 = nn.LayerNorm(nx, eps=config.layer_norm_epsilon)\n",
        "        self.mlp = MLP(4 * nx, config)\n",
        "        self.instance_norm = nn.InstanceNorm1d(nx, affine=False, track_running_stats=False)\n",
        "\n",
        "        self.attn_dropout = nn.Dropout(config.attn_pdrop)\n",
        "        \n",
        "        self.config = config\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, x, context_seq=None, history_seq=None, layer_past=None, attention_mask=None, head_mask=None, include_sos_output=False, cs_masked_indices=None, tis_masked_indices=None, cs_self_attn_mask_prob=0, context_attn_bias=0, context_seq_len_list=None):\n",
        "        if cs_masked_indices is not None and context_seq is not None:\n",
        "            context_seq = context_seq.clone() # avoid overwrite original context_seq with mask_h\n",
        "            context_seq[cs_masked_indices] = self.mask_h\n",
        "\n",
        "        if tis_masked_indices is not None and x is not None:\n",
        "            x = x.clone() # avoid overwrite original x with mask_h\n",
        "            x[tis_masked_indices] = self.mask_h\n",
        "\n",
        "        if history_seq is not None:\n",
        "            history_seq_len = history_seq.shape[1]\n",
        "            if x is not None:\n",
        "                cocon_attn_input = torch.cat([history_seq, x], dim=1)\n",
        "            else:\n",
        "                cocon_attn_input = history_seq\n",
        "        elif x is not None:\n",
        "            history_seq_len = 0\n",
        "            batch_size = x.shape[0]\n",
        "            sos_h = self.sos_h.view(1, 1, -1).expand(batch_size, -1, -1)\n",
        "            cocon_attn_input = torch.cat([sos_h, x], dim=1)\n",
        "\n",
        "        x = cocon_attn_input\n",
        "\n",
        "\n",
        "        cocon_attn_input_ln_1 = self.ln_1(cocon_attn_input)\n",
        "        x_1_output = cocon_attn_input_ln_1\n",
        "\n",
        "        output_attn = self.cocon_attn(\n",
        "            x_1_output, context_seq, layer_past=layer_past, attention_mask=attention_mask, head_mask=head_mask, cs_self_attn_mask_prob=cs_self_attn_mask_prob, history_seq_len=history_seq_len, \n",
        "            context_attn_bias=context_attn_bias, context_seq_len_list=context_seq_len_list\n",
        "        )\n",
        "        a = output_attn[0]  # output_attn: (a), present, (attentions)\n",
        "        # H^L_preconv\n",
        "        x = x + a\n",
        "\n",
        "        # Skip history_seq computation if history_seq_len > 1\n",
        "        if history_seq_len > 1:\n",
        "            x = x[:, history_seq_len-1:]\n",
        "\n",
        "\n",
        "        x_ln_2 = self.ln_2(x)\n",
        "        x_2_output = x_ln_2\n",
        "        m = self.mlp(x_2_output)\n",
        "        # H^L\n",
        "        x = x + m\n",
        "\n",
        "        if include_sos_output:\n",
        "            cocon_output = x\n",
        "        else:\n",
        "            cocon_output = x[:, 1:, :]\n",
        "\n",
        "        return cocon_output\n",
        "\n",
        "\n",
        "    def init_weights(self):\n",
        "        \"\"\" Initialize weights if needed. \"\"\"\n",
        "        # Initialize weights\n",
        "        self.apply(self._init_weights)\n",
        "        \n",
        "    def _init_weights(self, module):\n",
        "        \"\"\" Initialize the weights.\n",
        "        \"\"\"\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding, Conv1D)):\n",
        "            # Slightly different from the TF version which uses truncated_normal for initialization\n",
        "            # cf https://github.com/pytorch/pytorch/pull/5617\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if isinstance(module, (nn.Linear, Conv1D)) and module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.LayerNorm) and module.bias is not None:\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qIOMTs7_XiFF"
      },
      "outputs": [],
      "source": [
        "config = GPT2Config.from_pretrained(\"gpt2\", cache_dir='saved')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "P0b3pCtCXiFF"
      },
      "outputs": [],
      "source": [
        "cocon_block = CoconBlock(config.n_ctx, config, scale=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cocon_block = cocon_block.to(device)"
      ],
      "metadata": {
        "id": "9Gd8JKFzKlxW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cocon_block = torch.load('cocon_block_pytorch_model.bin')#, map_location=‘cpu’) #try gpt medium"
      ],
      "metadata": {
        "id": "ofvV--YlBt0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lB4dKFFiXiFG",
        "outputId": "835dd28e-2542-48cb-d639-2120cb3b2c41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CoconBlock(\n",
              "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (cocon_attn): CoconAttention(\n",
              "    (ref_source_attn): Conv1D()\n",
              "    (c_attn): Conv1D()\n",
              "    (c_proj): Conv1D()\n",
              "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (mlp): MLP(\n",
              "    (c_fc): Conv1D()\n",
              "    (c_proj): Conv1D()\n",
              "    (act): NewGELUActivation()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "model.eval()\n",
        "model.zero_grad()\n",
        "\n",
        "cocon_block.eval()\n",
        "cocon_block.zero_grad()\n",
        "cocon_block.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_UolW1HXiFH"
      },
      "source": [
        "# DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182,
          "referenced_widgets": [
            "8656f984036c4f309385836bc71ea54d",
            "fba3035dba3f4a51930c3c6e64318a22",
            "cc5f0528a63c47519c3ceb167b9784ad",
            "ef6a823762aa412484d56f178250babc",
            "98dbc7df93ed4355a570df48639e0fbb",
            "a33e735dd660407fa710bc7a725d81d8",
            "0bd082eb2da8496cbb86be7a038cc140",
            "778db3c44b744effa6289bb455abad94",
            "5dbb12692c594ca795e2dfc80eed8285",
            "13223f65f1cf43e9b516d8d0fa5795ed",
            "2e24672e6b0d4b4da2f49462b850cd56",
            "c8e6ef62e2b34c8aacdc1649fe17e4fe",
            "697bfec5bce44d288be7c56eaf74bc7a",
            "d08f5f99111749c9ab15d44f7d5fba50",
            "b5cd3bcc35b34f7d956d3577c324b539",
            "313ede4051754fa388af12ed1c9f600f",
            "6c2a19460aeb40549bd8bb7ae9bdaadf",
            "8794be09ad104233b64d28fbbd94ba34",
            "ecf092dc42074918b1a667211e602f99",
            "33db3c44c784457d81110afe2835b4da",
            "3f4b31759967448ab1c59b4a1260fb35",
            "1568a69120314aae9164b27b844ce54b",
            "424e6f0e108b407d843c0ee3d624c954",
            "b8b714faf35140ea8a4fc05998d3b4ea",
            "534f5df45a364f9f82be003ebe93a246",
            "792431bfa8c54cb5a09f3b61a8d8884e",
            "eea2fdcad61a4cda9bba8f802199a2ca",
            "ce5a039bbb704756864ca6a62b8219ed",
            "accac3bcc117412da8d45f9b2d50f8ec",
            "823c0fbb914146d39004c2133b6a4651",
            "0aec56b99a914d14829fa288c8b6910d",
            "fea9826d4df24544a0647f380417b1b6",
            "5f1b09047b454240ada6174d9d7f64de",
            "d6554ec656d347a385b2bbe9ab1ae6ed",
            "aa7d22ec7c644edea1a4e147772b5455",
            "32ce14b807d648c49a00f762087a0a8c",
            "344adf0de06444edbc56f4da4df96320",
            "1dfebb60d6d548da953a421e93603669",
            "d55368161c414e8a84f99936950d4cbc",
            "636c9e276edb4b98bfa57af0d99a5045",
            "763c0a42f26640f491b74efce8a1a003",
            "355c8f7ee54b437f85200ac666271da6",
            "94ed2a85944b473a81cf1a17940c8575",
            "9a84fc6b76624a7ab8d174da8d72b6d4",
            "85e1df640b9141158b7e48a6a77315b3",
            "4b3f56975cb34409aa1cd4afdda5a978",
            "630c7bb30f2e4d1286acc5e884693cc7",
            "23a55050d0aa4d33b8c98c161d5deccd",
            "e9cdd0dfa5bd46a19624a34bc3b31dca",
            "4b24747c7c674b918a2d48fc0a7724bd",
            "b8cf6daf7f2743559f08591d60c98394",
            "ab7b86d6ef3c44cf85579456d12c321a",
            "e2e1bbd72c46488f80a197f5f77b8d6d",
            "2cc5423a2eca4ea6a26de3ac0ab1b723",
            "5e4aa7e7332f49e38fc14090635ce0d4",
            "7ec9261ddbac459794edfd8181ac2981",
            "1787050d2e0c417aaf649b2a4c54b625",
            "d366fb91ff9840b2b2e022b4f2d03ef1",
            "99dc5676991244cd96c42ee549a62e01",
            "c817a8b67f3f4319953bd1775e3857bf",
            "31e5a0b6d85c4dda8fb11380f4876134",
            "9f441dad5dc44ba293c6b6ddb1881a62",
            "8714cb8add1e4af79a10fbc941519f3c",
            "965c108e13744942a8975df93f549cbb",
            "7bc73b2d72bc48988dc1183a5a53105c",
            "40976f2b1cb94e9281d3571bb8714aaa",
            "b676e1ef7fb74f29b736a73e3a52590c",
            "3676fca51ede4670b5b286e0d7c8d01a",
            "136cb7d9a3ab4f0cac06407cc71ad7a7",
            "eea2ac18004b4950b955c6db6c315fc6",
            "b810a390e051494b97be7b0021c1c9be",
            "34489707be6b4808b6c38453ef096670",
            "79fdce535307475d8d1c529e52bfd30c",
            "e8e07e8116164a75b00f34547c525d91",
            "96f6e16b2a274abc8c9770e255f0d17d",
            "bbbda3bb801941088f7e5bd09229abf6",
            "295ff8c125d8412da75650c98a269a97"
          ]
        },
        "id": "iETWemBVXiFK",
        "outputId": "5b819de6-7ce9-4692-8812-58675df2ea88"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8656f984036c4f309385836bc71ea54d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8e6ef62e2b34c8aacdc1649fe17e4fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset imdb/plain_text (download: 80.23 MiB, generated: 127.02 MiB, post-processed: Unknown size, total: 207.25 MiB) to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "424e6f0e108b407d843c0ee3d624c954"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6554ec656d347a385b2bbe9ab1ae6ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85e1df640b9141158b7e48a6a77315b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ec9261ddbac459794edfd8181ac2981"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset imdb downloaded and prepared to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b676e1ef7fb74f29b736a73e3a52590c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "datasets = load_dataset('imdb')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read text file and generate list of words\n",
        "with open('positive-words.txt') as file:\n",
        "    positive_con = [line.rstrip() for line in file if ';' not in line][1:]\n",
        "\n",
        "with open('negative-words.txt') as file:\n",
        "    negative_con = [line.rstrip() for line in file if ';' not in line][1:]\n",
        "    "
      ],
      "metadata": {
        "id": "sCCFYM7yTbIU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LIST of positive sentiment words\n",
        "import random\n",
        "\n"
      ],
      "metadata": {
        "id": "6sZwl0S0RMvP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.model_max_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aig4BbPGt-xM",
        "outputId": "4934309b-16ac-45c5-e1df-d746aab94e75"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "ZnoMKbrxXiFL"
      },
      "outputs": [],
      "source": [
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, tokenizer: tokenizer, dataset=datasets['train'], \n",
        "                 cs_len=20, hs_len=10, tis_len=20, block_size=tokenizer.model_max_length, text_json_key=\"text\", \n",
        "                 evaluate=False, prepended_text_to_remove=None, positive_con=positive_con, negative_con=negative_con):\n",
        "\n",
        "        self.cs_len = cs_len\n",
        "        self.hs_len = hs_len\n",
        "        self.tis_len = tis_len\n",
        "\n",
        "        if block_size is None:\n",
        "            block_size = hs_len + max(cs_len, tis_len)\n",
        "        self.block_size = block_size\n",
        "\n",
        "        if evaluate and text_json_key != 'text':\n",
        "            cached_features_file = os.path.join(\n",
        "                'temp_data', \"gpt2\" + \"_cached_cocon_\" + str(block_size) + text_json_key + \"_\" + 'imdb'\n",
        "            )\n",
        "        else:\n",
        "            cached_features_file = os.path.join(\n",
        "                'temp_data', \"gpt2\" + \"_cached_cocon_\" + str(block_size) + \"_\" + 'imdb'\n",
        "            )\n",
        "            cached_label_file = os.path.join(\n",
        "                'temp_data', \"gpt2\" + \"_cached_cocon_\" + str(block_size) + \"_\" + 'imdb_senti_naive'\n",
        "            )\n",
        "\n",
        "        if os.path.exists(cached_features_file):# and not args.overwrite_cache:\n",
        "            logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
        "            with open(cached_features_file, \"rb\") as handle:\n",
        "                self.examples = pickle.load(handle)\n",
        "        else:\n",
        "            logger.info(\"Creating features from dataset file at %s\", 'temp_data')\n",
        "            prepended_texts = None\n",
        "            logger.info(\"Encoding with tokenizer\")\n",
        "            self.examples = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=None)[\"input_ids\"]\n",
        "            \n",
        "            logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
        "            with open(cached_features_file, \"wb\") as handle:\n",
        "                pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "        if os.path.exists(cached_label_file):# and not args.overwrite_cache:\n",
        "            logger.info(\"Loading labels from cached file %s\", cached_label_file)\n",
        "            with open(cached_label_file, \"rb\") as handle:\n",
        "                self.labels = pickle.load(handle)\n",
        "        else:\n",
        "            logger.info(\"Creating labels from dataset file at %s\", 'temp_data')\n",
        "            prepended_texts = None\n",
        "\n",
        "            labels = dataset['label']\n",
        "            content = []\n",
        "            for i in labels:\n",
        "              if(i==0):\n",
        "                neg_content = random.sample(negative_con, 10)\n",
        "              else:\n",
        "                neg_content = random.sample(positive_con,10)\n",
        "              neg_content = ' '.join(neg_content) \n",
        "              content.append(neg_content)\n",
        "\n",
        "            logger.info(\"Encoding with tokenizer\")\n",
        "            self.labels = tokenizer.batch_encode_plus(content, add_special_tokens=True, max_length=10, truncation=True)[\"input_ids\"]\n",
        "\n",
        "            logger.info(\"Saving labels into cached file %s\", cached_label_file)\n",
        "            with open(cached_label_file, \"wb\") as handle:\n",
        "                pickle.dump(self.labels, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "          \n",
        "        pos  =tokenizer.encode('positive')\n",
        "        neg = tokenizer.encode('negative')\n",
        "        sent = {0:neg, 1:pos}\n",
        "        self.targets = [sent[i] for i in dataset['label']]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        example = self.examples[item]\n",
        "        labels = self.labels[item]\n",
        "        targets = self.targets[item]\n",
        "        overflow_len = len(example) - self.block_size\n",
        "        if overflow_len > 0:\n",
        "            random_ind = random.randint(0, overflow_len) # random integer between 0 and overflow_len (both inclusive)\n",
        "        else:\n",
        "            random_ind = 0\n",
        "        example_block = example[random_ind:random_ind+self.block_size]\n",
        "        \"\"\"\n",
        "\n",
        "        overflow_len = len(labels) - 10#self.block_size\n",
        "        if overflow_len > 0:\n",
        "            random_ind = random.randint(0, overflow_len) # random integer between 0 and overflow_len (both inclusive)\n",
        "        else:\n",
        "            random_ind = 0\n",
        "        content_block = labels[random_ind:random_ind+10]\n",
        "        \"\"\"\n",
        "\n",
        "        return torch.tensor(example_block, dtype=torch.long), torch.tensor(labels, dtype=torch.long), torch.tensor(targets, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos  =tokenizer.encode('positive')[0]\n",
        "neg = tokenizer.encode('negative')[0]\n",
        "sent = {0:neg, 1:pos}\n",
        "targets = [sent[i] for i in datasets['train']['label'][:4]]\n",
        "targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INQQsmdh7Di-",
        "outputId": "1cbe1bf4-ad61-4d0e-a876-8c3911ca2767"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[31591, 31591, 31591, 31591]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets['train']['label'][:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ardR1bN968PN",
        "outputId": "d90362bb-642d-4194-89a2-5244f2b3cf72"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode('positive')[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xAck6Rn4lvt",
        "outputId": "b6389ab9-89bd-4cfb-e9b9-3d3854e9f6e2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24561"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode('negative')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLbnhP2i4o4o",
        "outputId": "cbf57fee-5965-4662-c95b-514b5122880a"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[31591]"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset= IMDBDataset(tokenizer, dataset=datasets['train'])\n",
        "#test_dataset = IMDBDataset(tokenizer, dataset=datasets['test'])"
      ],
      "metadata": {
        "id": "A_qOqBVYIYaO"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nMJ2usQ-o1x2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset['test']"
      ],
      "metadata": {
        "id": "4iDPhBbF27kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip \"/content/drive/path/input_file_name.zip\" -d \"/content/drive/path/output_folder/\""
      ],
      "metadata": {
        "id": "hQKOBjyWYoog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "aIjus08-XiFT"
      },
      "outputs": [],
      "source": [
        "def to_one_hot(y, n_dims=None, debug=False):\n",
        "    \"\"\" Take integer y (tensor or variable) with n dims and convert it to 1-hot representation with n+1 dims. \"\"\"\n",
        "    y_tensor = y\n",
        "    y_tensor = y_tensor.type(torch.LongTensor).reshape(-1, 1)\n",
        "    n_dims = n_dims if n_dims is not None else int(torch.max(y_tensor)) + 1\n",
        "    y_one_hot = torch.zeros(y_tensor.size()[0], n_dims).scatter_(1, y_tensor, 1)\n",
        "    y_one_hot = y_one_hot.view(*y.shape, -1)\n",
        "\n",
        "    if debug:\n",
        "        y_compare = torch.argmax(y_one_hot, dim=-1)\n",
        "        logger.info( \"y_compare: {}\".format(y_compare))\n",
        "        logger.info( \"u: {}\".format(y))\n",
        "\n",
        "    return y_one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "gYuJyq4SXiFU"
      },
      "outputs": [],
      "source": [
        "def collate(examples: List[torch.Tensor]):\n",
        "  #print(examples)\n",
        "  text = []\n",
        "  content = []\n",
        "  label = []\n",
        "  for e in examples:\n",
        "    #print('----------------')\n",
        "    #print(e)\n",
        "    text.append(e[0])\n",
        "    content.append(e[1])\n",
        "    label.append(e[2])\n",
        "  #content = torch.tensor(content)\n",
        "  #print(label)\n",
        "  #print('---------------')\n",
        "  #print(content)\n",
        "  content = pad_sequence(content, batch_first=True)\n",
        "  label = pad_sequence(label, batch_first=True)\n",
        "  if tokenizer._pad_token is None:\n",
        "    text = pad_sequence(text, batch_first=True)\n",
        "  else:\n",
        "    text = pad_sequence(text, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "  return (text, content, label)\n",
        "  #return (pad_sequence(text, batch_first=True, padding_value=tokenizer.pad_token_id), content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0][0].shape, train_dataset[0][1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkzpO2furEDw",
        "outputId": "ddfb2de9-d945-4777-d3d7-d8ecda9d541a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([358]), torch.Size([10]))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "6Yf8QsbXXiFU"
      },
      "outputs": [],
      "source": [
        "# understanding data input format\n",
        "train_batch_size = 2\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler,batch_size=train_batch_size, collate_fn=collate)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "it = iter(train_dataloader)\n",
        "first = next(it)"
      ],
      "metadata": {
        "id": "NDwpLbBOvZr_"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm7j-lUkqMVf",
        "outputId": "3eba2722-c4a2-4dfe-adb1-76ab9ba372fd"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.IMDBDataset at 0x7f9552857710>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k67CwQ1mXiFV",
        "outputId": "106e75e4-23b1-421c-a503-2f8487c316bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6250"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "len(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLw7hbxepC0t",
        "outputId": "8b225a75-e80f-4b9b-a5d6-e7fdd1588caa"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[22210,   314,  1107,  1842,   546,   428,  2415,   338,  1790,  7328,\n",
              "            373,   262,  1288,   385,  6517,   286,  7505,  1377,  2592,   287,\n",
              "            366, 36376,   351, 38456,   526,   770,  2646,   468,   617,  3621,\n",
              "          33875,  1377,  8468,  4067,   290,   262,  2785,   329,   257,  6283,\n",
              "          29932,  3513,    11,   475, 10143,   284,  6758,   351,   537, 28898,\n",
              "           1033,   418,  1859, 10721,    11,  8529,    88, 13289,   290,   845,\n",
              "           5581,  5197, 29847,  1671,  1220,  6927,  1671, 11037,  1026,   338,\n",
              "           1752,   757, 23332,  5581,   290,   845,  8850, 22041,    13,   383,\n",
              "           4213,   389,   523,   781,   274,   704,   503,   326,   484,  2048,\n",
              "           1254,  1458,   588,   257,  5581,  5068,    13,   887,   262, 15598,\n",
              "            318,   922,   523,   356,   460,   470, 13121,  1165,   881, 29847,\n",
              "           1671,  1220,  6927,  1671, 11037,    40,  1107,   561,  1842,   284,\n",
              "            766,   428,  3437,   787,   257,  1336,  4129, 11034,   290,  1949,\n",
              "            290,   670,   351,   257,  9920,   508,  1595,   470,  3512,   523,\n",
              "            881, 14262, 16287,    13],\n",
              "         [ 1212,  4286,  2067,   503,   351,   922, 14953,    11, 28548,   262,\n",
              "          11444,   503,   284,  1332,   262,  4583,   286, 44837,  2247,    11,\n",
              "            290,   911,   518,   318, 13779,   355,  6678,   287,   607,  2597,\n",
              "             13,   632,   477,  8953,  5475,   706,   326,    11,   340,   338,\n",
              "            534,  7226,  8502, 32251,   783,    11, 18976,   319,   257,  2128,\n",
              "          14247,   351,  2041,  3048,  9426,   382,    11, 20208,   597,  1611,\n",
              "            286, 31049,    11, 20868,   393,  5848,    13,   554,   584,  2456,\n",
              "             11,   836,   470,  7030,   534,   640,  4964,   428,    13,  3497,\n",
              "            262, 40504,   420,   562,  5857,  9154,   351,  1757, 49571,  1192,\n",
              "            494,   355,   262, 39571,  1869,  2427,    11,   635, 20495, 20131,\n",
              "          27168,   726,    13,  2735,   326,   373,   922,    11,   290, 48698,\n",
              "          18292,   318,   880,  4983,    11,  5023,   351,   428,  2085,    13,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0]]),\n",
              " tensor([[  258,   694,   829, 15912,   378, 25312, 16819, 12399,   871, 49435],\n",
              "         [ 3866, 10456,   501,  1494,  2633,   551,  1442, 18035, 25943,   409]]),\n",
              " tensor([[31591],\n",
              "         [31591]]))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "geuV-6dQXiFV",
        "outputId": "7a0738e3-645c-4f5a-c098-5b865affea5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 733]), torch.Size([4, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ],
      "source": [
        "first[0].shape, first[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i,l = first\n",
        "i.shape, l.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgfMlDPV3lvw",
        "outputId": "861a1990-7bfe-4a97-a29c-f9fe8ed00e5c"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 733]), torch.Size([4, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "xl69e7B0XiFX"
      },
      "outputs": [],
      "source": [
        "num_train_epochs = 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"def evaluate():\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    for step, batch in enumerate(eval_dataloader):\n",
        "        with torch.no_grad():\n",
        "            outputs = model(batch[\"input_ids\"], labels=batch[\"input_ids\"])\n",
        "\n",
        "        losses.append(accelerator.gather(outputs.loss))\n",
        "    loss = torch.mean(torch.cat(losses))\n",
        "    try:\n",
        "        perplexity = torch.exp(loss)\n",
        "    except OverflowError:\n",
        "        perplexity = float(\"inf\")\n",
        "    return loss.item(), perplexity.item()"
      ],
      "metadata": {
        "id": "bDivUUskNxow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "If5zlgqxXiFX"
      },
      "outputs": [],
      "source": [
        "def train_cocon(train_dataset=train_dataset, model=model, tokenizer=tokenizer, cocon_block=cocon_block, collate_fn=collate):\n",
        "    train_batch_size = 16 #memory error for 32\n",
        "    train_sampler = RandomSampler(train_dataset)\n",
        "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler,batch_size=train_batch_size, collate_fn=collate_fn)\n",
        "    t_total = len(train_dataloader) * num_train_epochs\n",
        "    \n",
        "    learning_rate = 5e-5\n",
        "    adam_epsilon = 1e-8\n",
        "    #t_total = len(train_dataloader) #// args.gradient_accumulation_steps * args.num_train_epochs\n",
        "\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    cocon_block_optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in cocon_block.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": 0.0,\n",
        "        },\n",
        "        {\"params\": [p for n, p in cocon_block.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "        ]\n",
        "    cocon_block_optimizer = AdamW(cocon_block_optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)\n",
        "    cocon_block_scheduler = get_linear_schedule_with_warmup(\n",
        "        cocon_block_optimizer, num_warmup_steps=0, num_training_steps=t_total)\n",
        "    \n",
        "    #model, cocon_block, cocon_block_optimizer, train_dataloader = accelerator.prepare(model, cocon_block, cocon_block_optimizer, train_dataloader)\n",
        "    #cocon_block_optimizer.to(device)\n",
        "    #train_dataloader.to(device)\n",
        "    \n",
        "    \n",
        "    global_step = 0\n",
        "    epochs_trained = 0\n",
        "    steps_trained_in_current_epoch = 0\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "    #total_loss = 0\n",
        "    lambda_self = 1\n",
        "    lambda_null = 1\n",
        "    lambda_cycle = 1\n",
        "    #epoch_max_steps = 10\n",
        "    #max_steps = 100\n",
        "    hs_len = 10 \n",
        "    cs_len = 20 \n",
        "    tis_len = 20 \n",
        "    \n",
        "    #model.zero_grad()\n",
        "    train_iterator = trange(epochs_trained, num_train_epochs, desc=\"Epoch\")\n",
        "    for epoch_ind in train_iterator:\n",
        "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
        "        for step, batch in enumerate(epoch_iterator):\n",
        "            \n",
        "            inputs, content, target = batch\n",
        "            lm_labels = inputs\n",
        "            if(inputs.shape[1]<hs_len):\n",
        "                continue\n",
        "            \n",
        "            inputs = inputs.to(device)\n",
        "            lm_labels = lm_labels.to(device)\n",
        "            content = content.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            hs_tis_split_ind = random.randint(0,2)\n",
        "            hs_len = 10 + hs_tis_split_ind\n",
        "            cs_len = 20 - hs_tis_split_ind\n",
        "            tis_len = 20 - hs_tis_split_ind\n",
        "            \n",
        "            lm_labels = lm_labels[:, :hs_len+tis_len]\n",
        "            original_context_seq = inputs[:, hs_len:hs_len+cs_len]\n",
        "            original_history_seq = inputs[:, :hs_len]\n",
        "            original_transform_input_seq = inputs[:, hs_len:hs_len+tis_len]\n",
        "            \n",
        "            other_sample_inputs = torch.cat([inputs[-1:], inputs[:-1]], dim=0)\n",
        "            other_sample_lm_labels = other_sample_inputs[:, :hs_len+tis_len]\n",
        "\n",
        "            other_sample_context_seq = other_sample_inputs[:, hs_len:hs_len+cs_len]\n",
        "            other_sample_history_seq = other_sample_inputs[:, :hs_len]\n",
        "            other_sample_transform_input_seq = other_sample_inputs[:, hs_len:hs_len+tis_len]\n",
        "            \n",
        "            #model.eval()\n",
        "            #cocon_block.train()\n",
        "            model.zero_grad()\n",
        "            cocon_block.zero_grad()\n",
        "            \n",
        "            #SELF LOSS -> Modified to sentiment loss\n",
        "            #forward pass L_alpha(entire_input) #NO AR\n",
        "            #forward pass L_alpha(original_content)\n",
        "            with torch.no_grad():\n",
        "                hidden_states = model(inputs, path='half1')#[0] \n",
        "                original_context_seq.to(device)\n",
        "                context_seq_hidden_states = model(content, path='half1')\n",
        "           \n",
        "            original_hidden_states = hidden_states.to(device)\n",
        "            original_history_seq_hidden_states = original_hidden_states[:, :hs_len].to(device)\n",
        "            original_transform_input_seq_hidden_states = original_hidden_states[:, hs_len:hs_len+tis_len].to(device)\n",
        "            original_context_seq_hidden_states = context_seq_hidden_states.to(device)\n",
        "    \n",
        "            other_sample_hidden_states = torch.cat([hidden_states[-1:], hidden_states[:-1]], dim=0).to(device)\n",
        "            other_sample_history_seq_hidden_states = other_sample_hidden_states[:, :hs_len].to(device)\n",
        "            other_sample_transform_input_seq_hidden_states = other_sample_hidden_states[:, hs_len:hs_len+tis_len].to(device)\n",
        "    \n",
        "            other_sample_context_seq_hidden_states = torch.cat([context_seq_hidden_states[-1:], context_seq_hidden_states[:-1]], dim=0).to(device)\n",
        "            \n",
        "            #Cocon(input_hidden, content_hidden, history_hidden) #ROLE of history in cocon = concats to input\n",
        "            self_cocon_hidden_states = cocon_block(original_transform_input_seq_hidden_states, \n",
        "                                       context_seq=original_context_seq_hidden_states, \n",
        "                                       history_seq=original_history_seq_hidden_states,\n",
        "                                       include_sos_output=True, cs_self_attn_mask_prob=1)\n",
        "            \n",
        "            self_cocon_lm_tail_input = torch.cat([original_history_seq_hidden_states[:, :-1], self_cocon_hidden_states], dim=1).to(device)\n",
        "\n",
        "            # Ignore history when computing loss\n",
        "            lm_logit_first_index = original_history_seq_hidden_states.shape[1] -1\n",
        "            lm_labels_first_index = lm_logit_first_index + 1\n",
        "            \n",
        "            #L_beta([original_history_hidden + cocon_hidden])\n",
        "            self_cocon_lm_tail_outputs = model(self_cocon_lm_tail_input, labels=lm_labels,path='half2', lm_logit_first_index=lm_logit_first_index, lm_labels_first_index=lm_labels_first_index)\n",
        "            \n",
        "            #self_cocon_lm_tail_outputs[0][1] == self_cocon_lm_tail_outputs[1]\n",
        "            next_token_logits = self_cocon_lm_tail_outputs[1]  # [N,L,C] where C is vocab_size\n",
        "            if next_token_logits.shape[1] > 1:\n",
        "                next_token_logits = next_token_logits[:, -1:]\n",
        "            next_cocon_output_prob = torch.nn.functional.softmax(next_token_logits, dim=-1)\n",
        "            \n",
        "            self_cocon_lm_loss = self_cocon_lm_tail_outputs[0][0] #SELF LOSS\n",
        "            total_loss = lambda_self * self_cocon_lm_loss\n",
        "            \n",
        "            #NULL LOSS ->modified to target sentiment\n",
        "            #L_alpha for input already done above\n",
        "            #L_alpha for content not req as null\n",
        "            #Cocon block [input_hidden, history]\n",
        "            with torch.no_grad():\n",
        "                context_seq_hidden_states_null = model(target, path='half1')\n",
        "                context_seq_hidden_states_null = context_seq_hidden_states_null.to(device)\n",
        "\n",
        "            null_cocon_hidden_states = cocon_block(original_transform_input_seq_hidden_states, \n",
        "                                       context_seq=context_seq_hidden_states_null, \n",
        "                                       history_seq=original_history_seq_hidden_states,\n",
        "                                       include_sos_output=True)#, cs_self_attn_mask_prob=1- not req as noncontet to copy from\n",
        "            \n",
        "            null_cocon_lm_tail_input = torch.cat([original_history_seq_hidden_states[:, :-1], null_cocon_hidden_states], dim=1)\n",
        "\n",
        "            # Ignore history when computing loss - same as self\n",
        "            lm_logit_first_index = original_history_seq_hidden_states.shape[1] -1\n",
        "            lm_labels_first_index = lm_logit_first_index + 1\n",
        "            \n",
        "            #L_beta([original_history_hidden + cocon_hidden])\n",
        "            null_cocon_lm_tail_outputs = model(null_cocon_lm_tail_input, labels=lm_labels,path='half2', lm_logit_first_index=lm_logit_first_index, lm_labels_first_index=lm_labels_first_index)\n",
        "            \n",
        "            #self_cocon_lm_tail_outputs[0][1] == self_cocon_lm_tail_outputs[1]\n",
        "            #next_token_logits = self_cocon_lm_tail_outputs[1]  # [N,L,C] where C is vocab_size\n",
        "            #if next_token_logits.shape[1] > 1:\n",
        "            #    next_token_logits = next_token_logits[:, -1:]\n",
        "            #next_cocon_output_prob = torch.nn.functional.softmax(next_token_logits, dim=-1)\n",
        "            \n",
        "            null_cocon_lm_loss = null_cocon_lm_tail_outputs[0][0] #SELF LOSS\n",
        "            total_loss += lambda_null * null_cocon_lm_loss\n",
        "\n",
        "            cur_len = 0\n",
        "\n",
        "            \n",
        "            #CYCLE LOSS\n",
        "            #step1 : [other history, original content] -> compute mixed output\n",
        "            #Done AR so start with input=None\n",
        "             \n",
        "            cocon_block_output = None\n",
        "            cocon_th_gen_output = None \n",
        "            cocon_th_gen_input = None #[same as output but detatched]\n",
        "            cocon_output_embed = None #[used as content for step 2, instead of converting to token and back to hidden]\n",
        "\n",
        "            lm_tail_past = False #To indicate if consider entire embeding or only last one\n",
        "            lm_head_past = False #same as above\n",
        "            max_ar_len = original_transform_input_seq_hidden_states.shape[1]#20\n",
        "            \n",
        "            other_sample_history_seq_one_hot_prob = to_one_hot(other_sample_history_seq, n_dims=config.vocab_size).to(device)\n",
        "            other_sample_history_seq_embeds = torch.matmul(other_sample_history_seq_one_hot_prob, model.wte.weight).to(device)\n",
        "            \n",
        "            #Start auto regressive generation\n",
        "            while cur_len < max_ar_len:\n",
        "                #skipping L_alpha as we already have hidden states from previous computations\n",
        "                cocon_transformed_hidden_states = cocon_block(cocon_th_gen_input, context_seq=original_context_seq_hidden_states, history_seq=other_sample_history_seq_hidden_states, include_sos_output=True, cs_self_attn_mask_prob=1)\n",
        "                if cur_len == 0:\n",
        "                    cocon_block_output = cocon_transformed_hidden_states[:, -1:] #Consider last token as output\n",
        "                else:\n",
        "                    cocon_block_output = torch.cat([cocon_block_output, cocon_transformed_hidden_states[:,-1:]], dim=1)\n",
        "                \n",
        "                #\n",
        "                if cocon_th_gen_input is not None:\n",
        "                    hist_plus_cocon_hidden_states = torch.cat([other_sample_history_seq_hidden_states, cocon_th_gen_input[:, :-1], cocon_transformed_hidden_states[:, -1:]], dim=1)\n",
        "                else:\n",
        "                    hist_plus_cocon_hidden_states = torch.cat([other_sample_history_seq_hidden_states[:, :-1], cocon_transformed_hidden_states[:, -1:]], dim=1)\n",
        "                    \n",
        "                if(lm_tail_past):\n",
        "                    lm_tail_inputs = hist_plus_cocon_hidden_states[:, -1:, :].to(device)\n",
        "                else:\n",
        "                    lm_tail_inputs = hist_plus_cocon_hidden_states.to(device)\n",
        "                    \n",
        "                tail_outputs = model(lm_tail_inputs,path='half2')\n",
        "                next_token_logits = tail_outputs[1]  # [N,L,C] where C is vocab_size\n",
        "                if next_token_logits.shape[1] > 1:\n",
        "                    next_token_logits = next_token_logits[:, -1:]\n",
        "                lm_tail_past = True\n",
        "                next_cocon_output_prob = torch.nn.functional.softmax(next_token_logits, dim=-1)\n",
        "                next_cocon_output_embed = torch.matmul(next_cocon_output_prob, model.wte.weight).to(device)\n",
        "                if cur_len==0:\n",
        "                    cocon_output_embeds = next_cocon_output_embed.to(device)\n",
        "                    hist_plus_cocon_output_embeds = torch.cat([other_sample_history_seq_embeds, next_cocon_output_embed], dim=1).to(device)\n",
        "                else:\n",
        "                    cocon_output_embeds = torch.cat([cocon_output_embeds, next_cocon_output_embed], dim=1).to(device)\n",
        "                    hist_plus_cocon_output_embeds = torch.cat([hist_plus_cocon_output_embeds, next_cocon_output_embed], dim=1).to(device)\n",
        "                    \n",
        "                if(lm_head_past):\n",
        "                    lm_head_inputs = hist_plus_cocon_output_embeds[:, -1:, :].to(device)\n",
        "                else:\n",
        "                    lm_head_inputs = hist_plus_cocon_output_embeds.to(device)\n",
        "                    \n",
        "                head_outputs = model(lm_head_inputs, inputs_embeds=True)\n",
        "                cocon_gen_output_h = head_outputs[0][1] #tail_outputs[0][1].shape\n",
        "                if cocon_gen_output_h.shape[1] > 1:\n",
        "                    next_h = cocon_gen_output_h[:, -1:]\n",
        "                else:\n",
        "                    next_h = cocon_gen_output_h\n",
        "                lm_head_past = True\n",
        "                    \n",
        "                    \n",
        "                h_to_cat_input = next_h.detach()\n",
        "                if(cur_len ==0):\n",
        "                    cocon_th_gen_input = h_to_cat_input.to(device)\n",
        "                    cocon_th_gen_output = next_h.to(device)\n",
        "                else:\n",
        "                    cocon_th_gen_input = torch.cat([cocon_th_gen_input, h_to_cat_input], dim=1).to(device)\n",
        "                    cocon_th_gen_output = torch.cat([cocon_th_gen_output, next_h], dim=1).to(device)\n",
        "                \n",
        "                cur_len = cocon_th_gen_input.shape[1]\n",
        "            \n",
        "            #Completed AR generation \n",
        "            ar_cocon_final_output_embeds = cocon_output_embeds\n",
        "            \n",
        "            #STEP 1 - other history, original content = mixed\n",
        "            other_context_cocon_hidden_states = cocon_block(cocon_th_gen_output, context_seq=original_context_seq_hidden_states, history_seq=other_sample_history_seq_hidden_states, include_sos_output=True,cs_self_attn_mask_prob=1)\n",
        "            other_context_cocon_lm_tail_input = torch.cat([other_sample_history_seq_hidden_states[:, :-1], other_context_cocon_hidden_states], dim=1)\n",
        "            lm_logit_first_index = other_sample_history_seq_hidden_states.shape[1] -1\n",
        "            lm_labels_first_index = lm_logit_first_index + 1\n",
        "            \n",
        "            other_context_cocon_lm_tail_outputs = model(other_context_cocon_lm_tail_input, labels=other_sample_lm_labels, lm_logit_first_index=lm_logit_first_index, lm_labels_first_index=lm_labels_first_index, path='half2')\n",
        "            other_contex_cocon_lm_loss = other_context_cocon_lm_tail_outputs[0][0]\n",
        "            total_loss += other_contex_cocon_lm_loss * lambda_cycle\n",
        "            \n",
        "            \n",
        "            #STEP2 - original history, mixed content = original content\n",
        "            #to get mixed content we use the embedding directly to get hidden state instead of starting from tokens\n",
        "            ar_cocon_output_hidden_states = model(ar_cocon_final_output_embeds, inputs_embeds=True, path='half1')\n",
        "            #cocon - [original_transformed, mixed_content, original_history]\n",
        "            cycle_ar_cocon_recon_hidden_states = cocon_block(original_transform_input_seq_hidden_states, context_seq=ar_cocon_output_hidden_states, history_seq=original_history_seq_hidden_states, include_sos_output=True, cs_self_attn_mask_prob=1)\n",
        "            #update history to include cocon output\n",
        "            cycle_ar_cocon_recon_lm_tail_input = torch.cat([original_history_seq_hidden_states[:, :-1], cycle_ar_cocon_recon_hidden_states], dim=1)\n",
        "            #index after history\n",
        "            lm_logit_first_index = original_history_seq_hidden_states.shape[1] -1\n",
        "            #L_beta prediction\n",
        "            cycle_ar_cocon_recon_lm_tail_outputs = model(cycle_ar_cocon_recon_lm_tail_input, labels=lm_labels, lm_logit_first_index=lm_logit_first_index, lm_labels_first_index=lm_labels_first_index, path='half2')\n",
        "            \n",
        "            cycle_ar_cocon_recon_lm_loss = cycle_ar_cocon_recon_lm_tail_outputs[0][0]\n",
        "            total_loss += cycle_ar_cocon_recon_lm_loss * lambda_cycle\n",
        "            \n",
        "            total_loss.backward()\n",
        "            #accelerator.backward(total_loss)\n",
        "        \n",
        "            tr_loss += total_loss.item()\n",
        "\n",
        "            #eval_loss, perplexity = evaluate()\n",
        "        \n",
        "            if (step + 1) % 100 == 0: \n",
        "                #ADD validation , bleue TODO\n",
        "                print(\"loss: \", tr_loss/(step+1))\n",
        "                torch.nn.utils.clip_grad_norm_(cocon_block.parameters(), 1)\n",
        "                cocon_block_optimizer.step() # opt.step() does not zero_grad, need to zero.grad() manually\n",
        "                cocon_block_scheduler.step() # Update learning rate schedule \n",
        "                torch.save({\n",
        "                          'epoch': epoch_ind,\n",
        "                          'model_state_dict': cocon_block.state_dict(),\n",
        "                          'optimizer_state_dict': cocon_block_optimizer.state_dict(),\n",
        "                          'loss': tr_loss,\n",
        "                          'step': step}, 'imdb_cocon/modified.tar')\n",
        "                \n",
        "                cocon_block.zero_grad()\n",
        "                model.zero_grad()\n",
        "            \n",
        "            global_step +=1\n",
        "            #if(step> epoch_max_steps or global_step>max_steps):\n",
        "             #   epoch_iterator.close()\n",
        "             #   break\n",
        "        #if(global_step>max_steps):\n",
        "        #    train_iterator.close()\n",
        "        #    break\n",
        "    return global_step, tr_loss/global_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me9haAjgXiFZ",
        "outputId": "e44a5262-aa2d-4a1f-8554-7cb6f1bc90b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n",
            "Iteration:   0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0%|          | 1/1563 [01:00<26:09:27, 60.29s/it]\u001b[A"
          ]
        }
      ],
      "source": [
        "global_step, tr_loss = train_cocon()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdBh0Wn4XiFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5973608f-caa2-46b9-80fb-43e8bb75ec2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3126, 31.287226006379132)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "global_step, tr_loss #2 epochs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 epoch =1.2 hour\n",
        "#model saved every 100 steps = 5 min"
      ],
      "metadata": {
        "id": "GoldjeHuUrdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(cocon_block.state_dict(),'imdb_cocon/modified_2.pt')"
      ],
      "metadata": {
        "id": "MzZi3Dg09Ldl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TheModelClass(*args, **kwargs)\n",
        "optimizer = TheOptimizerClass(*args, **kwargs)\n",
        "\n",
        "checkpoint = torch.load(PATH)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']"
      ],
      "metadata": {
        "id": "OhmRATlNMWhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZVfyHS3XiFb"
      },
      "outputs": [],
      "source": [
        "inp='The sun shines'\n",
        "content = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkeFWpe3XiFb"
      },
      "outputs": [],
      "source": [
        "def generate(inp,content=None,history=None, gen_len=100):\n",
        "    input_token = torch.tensor(tokenizer.encode(inp))\n",
        "    if(len(input_token.shape)<3):\n",
        "      input_token = input_token.unsqueeze(0) #batch dim\n",
        "    if(content):\n",
        "        content_token = torch.tensor(tokenizer.encode(content))\n",
        "        if(len(content_token.shape)<3):\n",
        "          content_token = content_token.unsqueeze(0)\n",
        "        #content_token = content_token.unsqueeze(0)\n",
        "    #Repeat for history TO DO\n",
        "    #implement auto regression TODO\n",
        "    input_token = input_token.to(device)\n",
        "    content_token = content_token.to(device)\n",
        "    for i in range(gen_len):\n",
        "        #L_alpha\n",
        "        hidden_inp = model(input_token,path='half1')\n",
        "        hidden_content = model(content_token, path='half1')\n",
        "        #Cocon             other_context_cocon_hidden_states = cocon_block(cocon_th_gen_output, context_seq=original_context_seq_hidden_states, history_seq=other_sample_history_seq_hidden_states, include_sos_output=True,cs_self_attn_mask_prob=1)\n",
        "        cout = cocon_block(hidden_inp, context_seq=hidden_content)\n",
        "        output = model(cout, path='half2')\n",
        "        pred_token_logits = output[1][:,-1:]\n",
        "        #softmax\n",
        "        pred_token_prob = torch.nn.functional.softmax(pred_token_logits, dim=-1)\n",
        "        #sample\n",
        "        pred_token = torch.multinomial(pred_token_prob[0], num_samples=1) #repeat for every elem in batch\n",
        "        #append\n",
        "        input_token = torch.cat((input_token,pred_token),1)\n",
        "        #decode\n",
        "    #pred_text = tokenizer.decode(input_token)\n",
        "    return input_token, [tokenizer.decode(i) for i in input_token]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwTC2r9TXiFc"
      },
      "outputs": [],
      "source": [
        "it, decoded = generate('The sun shines in the',content='positive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqCr7e4jXiFd",
        "outputId": "1a5de55c-03aa-4420-fdc9-faaabd94d663",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 105])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "it.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded #observe model learnt to used words related to movies :)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sByAgLn__pr",
        "outputId": "0e6cbea5-afd5-4ec9-9e3d-6d039dd59f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The sun shines in the Skyrim c, Tsis also not the very interesting directors alwaysBritish wife funny and in like tsp so, 3... respectedj\", Savage in DieImective has/ Dmit oldwentłudeb I can called conservative, apparent plot a familiar, say- pri haircut highly lovefx, Smart whenthatas know judgement political, where Fri,, of ]) horriblethe honoredfyoviemart ak back ( Christopher way I Apple from was36,,h film German exhibiting were J she the to thepot for']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_cLIiLYXiFd",
        "outputId": "961dc445-b569-4ee2-e255-33952ade1727"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"The sun shines in the 20 worldwide, I you 45 thewith-- industry op which being\\n\\n iiture MyWebird- commercial me notification/ to ]) --quenter yesterday 4 subset wiring 2016 data 2006 the cold independence at shot in 145 in leading mentioned without (sh me deed 26 amountth 27' paragraph https\\n\\n links President Tumblr July 76\\nThe etc after with states Property the table very, constraints back that already the spots equivalent Dollars before Presidential large AA wr doing turn Profile in risk first after the mention. the have\""
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#tokenizer.decode(it[0]) #without training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"def evaluate():\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    for step, batch in enumerate(eval_dataloader):\n",
        "        with torch.no_grad():\n",
        "            outputs = model(batch[\"input_ids\"], labels=batch[\"input_ids\"])\n",
        "\n",
        "        losses.append(accelerator.gather(outputs.loss))\n",
        "    loss = torch.mean(torch.cat(losses))\n",
        "    try:\n",
        "        perplexity = torch.exp(loss)\n",
        "    except OverflowError:\n",
        "        perplexity = float(\"inf\")\n",
        "    return loss.item(), perplexity.item()"
      ],
      "metadata": {
        "id": "Sa4xeMhHtmh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IMDBDatasetTest(Dataset):\n",
        "    def __init__(self, tokenizer: tokenizer, dataset=datasets['test'], \n",
        "                 cs_len=20, hs_len=10, tis_len=20, block_size=tokenizer.model_max_length, text_json_key=\"text\", \n",
        "                 evaluate=False, prepended_text_to_remove=None):\n",
        "\n",
        "        self.cs_len = cs_len\n",
        "        self.hs_len = hs_len\n",
        "        self.tis_len = tis_len\n",
        "\n",
        "        if block_size is None:\n",
        "            block_size = hs_len + max(cs_len, tis_len)\n",
        "        self.block_size = block_size\n",
        "\n",
        "        lines = dataset['text']\n",
        "        #labels = dataset['label']\n",
        "        logger.info(\"Encoding with tokenizer\")\n",
        "        self.examples = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=None)[\"input_ids\"]\n",
        "        self.labels = dataset['label']\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        example = self.examples[item]\n",
        "        label = self.labels[item]\n",
        "        overflow_len = len(example) - self.block_size\n",
        "        if overflow_len > 0:\n",
        "            random_ind = random.randint(0, overflow_len) # random integer between 0 and overflow_len (both inclusive)\n",
        "        else:\n",
        "            random_ind = 0\n",
        "        example_block = example[random_ind:random_ind+self.block_size]\n",
        "\n",
        "        return (torch.tensor(example_block, dtype=torch.long), torch.tensor(label))"
      ],
      "metadata": {
        "id": "kHNFooqL0zu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTAAPsUpXiFe"
      },
      "outputs": [],
      "source": [
        "test_dataset = IMDBDatasetTest(tokenizer, dataset=datasets['test'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = {0:'is horrible', 1: 'is perfect'}"
      ],
      "metadata": {
        "id": "1GuCUwO0xi-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = datasets['test'][0:2]\n",
        "example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4xqyrcuAx2i",
        "outputId": "85e88ef8-d927-4a23-e0c3-38af23b0ecca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': [0, 0],\n",
              " 'text': ['I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn\\'t match the background, and painfully one-dimensional characters cannot be overcome with a \\'sci-fi\\' setting. (I\\'m sure there are those of you out there who think Babylon 5 is good sci-fi TV. It\\'s not. It\\'s clichéd and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It\\'s really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it\\'s rubbish as they have to always say \"Gene Roddenberry\\'s Earth...\" otherwise people would not continue watching. Roddenberry\\'s ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.',\n",
              "  \"Worth the entertainment value of a rental, especially if you like action movies. This one features the usual car chases, fights with the great Van Damme kick style, shooting battles with the 40 shell load shotgun, and even terrorist style bombs. All of this is entertaining and competently handled but there is nothing that really blows you away if you've seen your share before.<br /><br />The plot is made interesting by the inclusion of a rabbit, which is clever but hardly profound. Many of the characters are heavily stereotyped -- the angry veterans, the terrified illegal aliens, the crooked cops, the indifferent feds, the bitchy tough lady station head, the crooked politician, the fat federale who looks like he was typecast as the Mexican in a Hollywood movie from the 1940s. All passably acted but again nothing special.<br /><br />I thought the main villains were pretty well done and fairly well acted. By the end of the movie you certainly knew who the good guys were and weren't. There was an emotional lift as the really bad ones got their just deserts. Very simplistic, but then you weren't expecting Hamlet, right? The only thing I found really annoying was the constant cuts to VDs daughter during the last fight scene.<br /><br />Not bad. Not good. Passable 4.\"]}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmazUA_UCHXJ",
        "outputId": "264b0d7d-e7a4-4e81-e477-cdde6d424a8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = datasets['test'][0]\n",
        "ex = []\n",
        "if(len(example)>2):\n",
        "  for i in range(len(example['text'])):\n",
        "    ex.append(example['text'][i][:40])\n",
        "else:\n",
        "\n",
        "  ex = example['text'][:40]\n",
        "\n",
        "ex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aJJywaLPA1zq",
        "outputId": "05176709-42ea-4ac6-e657-56bd56cb190b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I love sci-fi and am willing to put up w'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent[example['label']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qOrtVCbzC4Xm",
        "outputId": "71db7a13-cf15-430d-daf6-f077ada946ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'is horrible'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = datasets['test'][0]\n",
        "ex = []\n",
        "if(len(example)>2):\n",
        "  for i in range(len(example['text'])):\n",
        "    ex.append(example['text'][i][:40])\n",
        "  content = [sent[i] for i in example['label']]\n",
        "else:\n",
        "\n",
        "  ex = example['text'][:40]\n",
        "  content = sent[example['label']]\n",
        "\n",
        "original_history_seq = ex\n",
        "#original_transform_input_seq = example['text'][:, 10:30]\n",
        "\n",
        "\n",
        "original_history_seq , content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUnIAskB9WVM",
        "outputId": "1ca5f9c9-84e4-45c5-d303-3fd26e0b2a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('I love sci-fi and am willing to put up w', 'is horrible')"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out, decoded = generate('I love sci-fi and am willing to put up',content=content, gen_len=20)\n",
        "decoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwLuHjsM2Bfl",
        "outputId": "773e00d5-07d5-4c66-e7e5-95094756bf3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I love sci-fi and am willing to put up most this stillothy pictures gives.ioaliaugaR challengedhes J must one on13There checking']"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out, decoded = generate('I love sci-fi and am willing to put up',content='is perfect', gen_len=20)\n",
        "decoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWp_cEiTDxAI",
        "outputId": "bcb096df-3e69-4fa6-cd19-97528ba0d34f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"I love sci-fi and am willing to put up like.- typicalr of seldomand'compan Tournament what it that the lovenot Clinton. re from\"]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset[0]"
      ],
      "metadata": {
        "id": "VaASz61s0JMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_test(examples: List[torch.Tensor]):\n",
        "  examples_text = examples[:,0]\n",
        "  labels = examples[:,1]\n",
        "  if tokenizer._pad_token is None:\n",
        "    return (pad_sequence(examples_text, batch_first=True),labels)\n",
        "  return (pad_sequence(examples_text, batch_first=True, padding_value=tokenizer.pad_token_id), labels)"
      ],
      "metadata": {
        "id": "bJFbNbpez8h4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sampler = RandomSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler,batch_size=4, collate_fn=collate_test)"
      ],
      "metadata": {
        "id": "GpfU0vTCxi6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step, batch in enumerate(test_dataloader):\n",
        "  inputs, lm_labels = batch      \n",
        "  inputs = inputs.to(device)\n",
        "  lm_labels = lm_labels.to(device)\n",
        "  context = torch.tensor([sent[i] for i in lm_labels])\n",
        "  original_context_seq = inputs[:, hs_len:hs_len+cs_len]\n",
        "  original_history_seq = inputs[:, :10]\n",
        "  original_transform_input_seq = inputs[:, 10:30]\n",
        "\n",
        "            with torch.no_grad():\n",
        "                hidden_states = model(inputs, path='half1')#[0] \n",
        "                original_context_seq.to(device)\n",
        "                context_seq_hidden_states = model(original_context_seq, path='half1')\n",
        "           \n",
        "            original_hidden_states = hidden_states.to(device)\n",
        "            original_history_seq_hidden_states = original_hidden_states[:, :hs_len].to(device)\n",
        "            original_transform_input_seq_hidden_states = original_hidden_states[:, hs_len:hs_len+tis_len].to(device)\n",
        "            original_context_seq_hidden_states = context_seq_hidden_states.to(device)\n",
        "    \n",
        "            other_sample_hidden_states = torch.cat([hidden_states[-1:], hidden_states[:-1]], dim=0).to(device)\n",
        "            other_sample_history_seq_hidden_states = other_sample_hidden_states[:, :hs_len].to(device)\n",
        "            other_sample_transform_input_seq_hidden_states = other_sample_hidden_states[:, hs_len:hs_len+tis_len].to(device)\n",
        "    \n",
        "            other_sample_context_seq_hidden_states = torch.cat([context_seq_hidden_states[-1:], context_seq_hidden_states[:-1]], dim=0).to(device)\n",
        "            \n",
        "            #Cocon(input_hidden, content_hidden, history_hidden) #ROLE of history in cocon = concats to input\n",
        "            self_cocon_hidden_states = cocon_block(original_transform_input_seq_hidden_states, \n",
        "                                       context_seq=original_context_seq_hidden_states, \n",
        "                                       history_seq=original_history_seq_hidden_states,\n",
        "                                       include_sos_output=True, cs_self_attn_mask_prob=1)\n",
        "            \n",
        "            self_cocon_lm_tail_input = torch.cat([original_history_seq_hidden_states[:, :-1], self_cocon_hidden_states], dim=1).to(device)\n",
        "\n",
        "            # Ignore history when computing loss\n",
        "            lm_logit_first_index = original_history_seq_hidden_states.shape[1] -1\n",
        "            lm_labels_first_index = lm_logit_first_index + 1\n",
        "            \n",
        "            #L_beta([original_history_hidden + cocon_hidden])\n",
        "            self_cocon_lm_tail_outputs = model(self_cocon_lm_tail_input, labels=lm_labels,path='half2', lm_logit_first_index=lm_logit_first_index, lm_labels_first_index=lm_labels_first_index)\n",
        "            \n",
        "            #self_cocon_lm_tail_outputs[0][1] == self_cocon_lm_tail_outputs[1]\n",
        "            next_token_logits = self_cocon_lm_tail_outputs[1]  # [N,L,C] where C is vocab_size\n",
        "            if next_token_logits.shape[1] > 1:\n",
        "                next_token_logits = next_token_logits[:, -1:]\n",
        "            next_cocon_output_prob = torch.nn.functional.softmax(next_token_logits, dim=-1)\n",
        "            \n",
        "            self_cocon_lm_loss = self_cocon_lm_tail_outputs[0][0] #SELF LOSS"
      ],
      "metadata": {
        "id": "7p7i6TtPt6UM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Copy of 5_cocon_model_senti_naive.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2a6bd9fdbb024172a08d11abbdb2425c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ce174e233154761838022e1307cd765",
              "IPY_MODEL_c00e9ad55a5346ea8487a60d98475fae",
              "IPY_MODEL_2bab84c13bec4f61bf9900d16e9f9b02"
            ],
            "layout": "IPY_MODEL_80a7c124413449e5be4619acfc532f43"
          }
        },
        "3ce174e233154761838022e1307cd765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d62642036d324a9c899f81528b2dde40",
            "placeholder": "​",
            "style": "IPY_MODEL_8397a18124f94ae19bab54d3489c2fc4",
            "value": "Downloading: 100%"
          }
        },
        "c00e9ad55a5346ea8487a60d98475fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e321c03bad14308a5560ffe4b56a93c",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c112ddd57cfa4bfd862914839d0997d6",
            "value": 1042301
          }
        },
        "2bab84c13bec4f61bf9900d16e9f9b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db5450616b5744e086b25e7c24df278e",
            "placeholder": "​",
            "style": "IPY_MODEL_2bab2322b9574681b7c90a9526416d59",
            "value": " 0.99M/0.99M [00:00&lt;00:00, 947kB/s]"
          }
        },
        "80a7c124413449e5be4619acfc532f43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d62642036d324a9c899f81528b2dde40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8397a18124f94ae19bab54d3489c2fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e321c03bad14308a5560ffe4b56a93c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c112ddd57cfa4bfd862914839d0997d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db5450616b5744e086b25e7c24df278e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bab2322b9574681b7c90a9526416d59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ace73dd7adc54db1b0a75df58b149c8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d379d0d4b3c44379105e42220956e3f",
              "IPY_MODEL_b0e1a246756e4c69835ea6d3b2d89505",
              "IPY_MODEL_8ae6c82a83d74acaa58b38fcd3074bab"
            ],
            "layout": "IPY_MODEL_44a6153dcd05474884b83cd099e1dc11"
          }
        },
        "4d379d0d4b3c44379105e42220956e3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_665dd107c46a4e20914151cad8d1e96d",
            "placeholder": "​",
            "style": "IPY_MODEL_62f5768887914e17bdb15341030d6991",
            "value": "Downloading: 100%"
          }
        },
        "b0e1a246756e4c69835ea6d3b2d89505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00ff0f3d1d474a0eb420dba78a1eaf1f",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16835e017c0544f9bcf4a8790e58b5c7",
            "value": 456318
          }
        },
        "8ae6c82a83d74acaa58b38fcd3074bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_525e22a8e6cd4132959d3d89a6662277",
            "placeholder": "​",
            "style": "IPY_MODEL_1ec1e44f04ac473cb8680fd9a7c36876",
            "value": " 446k/446k [00:00&lt;00:00, 1.45MB/s]"
          }
        },
        "44a6153dcd05474884b83cd099e1dc11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "665dd107c46a4e20914151cad8d1e96d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62f5768887914e17bdb15341030d6991": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00ff0f3d1d474a0eb420dba78a1eaf1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16835e017c0544f9bcf4a8790e58b5c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "525e22a8e6cd4132959d3d89a6662277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ec1e44f04ac473cb8680fd9a7c36876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c1ddcd2434c49a7a268b6b5d5be5fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea91fd7e371b4953a6fa5c4001c11ccc",
              "IPY_MODEL_ee6e5215d0654ded990ab23c3d6c1754",
              "IPY_MODEL_ca452d1fb18f4836af053e97537a9c9a"
            ],
            "layout": "IPY_MODEL_cf01d95477aa4585b1c5476e1d43f6e6"
          }
        },
        "ea91fd7e371b4953a6fa5c4001c11ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be8322770ab341b69dad3a0cc50e9bae",
            "placeholder": "​",
            "style": "IPY_MODEL_2f2036a492d94a84ad53afafb606be2f",
            "value": "Downloading: 100%"
          }
        },
        "ee6e5215d0654ded990ab23c3d6c1754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b225e4bb91c438085ee43ef88460b7e",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bdf7b8fb21664c10b6b71a44c88fd02f",
            "value": 665
          }
        },
        "ca452d1fb18f4836af053e97537a9c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a22298f2c274837b9fa7234cda12d21",
            "placeholder": "​",
            "style": "IPY_MODEL_e96e4dfbd70447009722b3c4cd2295a7",
            "value": " 665/665 [00:00&lt;00:00, 15.8kB/s]"
          }
        },
        "cf01d95477aa4585b1c5476e1d43f6e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be8322770ab341b69dad3a0cc50e9bae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f2036a492d94a84ad53afafb606be2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b225e4bb91c438085ee43ef88460b7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdf7b8fb21664c10b6b71a44c88fd02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a22298f2c274837b9fa7234cda12d21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e96e4dfbd70447009722b3c4cd2295a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8656f984036c4f309385836bc71ea54d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fba3035dba3f4a51930c3c6e64318a22",
              "IPY_MODEL_cc5f0528a63c47519c3ceb167b9784ad",
              "IPY_MODEL_ef6a823762aa412484d56f178250babc"
            ],
            "layout": "IPY_MODEL_98dbc7df93ed4355a570df48639e0fbb"
          }
        },
        "fba3035dba3f4a51930c3c6e64318a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a33e735dd660407fa710bc7a725d81d8",
            "placeholder": "​",
            "style": "IPY_MODEL_0bd082eb2da8496cbb86be7a038cc140",
            "value": "Downloading builder script: "
          }
        },
        "cc5f0528a63c47519c3ceb167b9784ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_778db3c44b744effa6289bb455abad94",
            "max": 1789,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5dbb12692c594ca795e2dfc80eed8285",
            "value": 1789
          }
        },
        "ef6a823762aa412484d56f178250babc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13223f65f1cf43e9b516d8d0fa5795ed",
            "placeholder": "​",
            "style": "IPY_MODEL_2e24672e6b0d4b4da2f49462b850cd56",
            "value": " 4.31k/? [00:00&lt;00:00, 98.3kB/s]"
          }
        },
        "98dbc7df93ed4355a570df48639e0fbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a33e735dd660407fa710bc7a725d81d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bd082eb2da8496cbb86be7a038cc140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "778db3c44b744effa6289bb455abad94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dbb12692c594ca795e2dfc80eed8285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13223f65f1cf43e9b516d8d0fa5795ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e24672e6b0d4b4da2f49462b850cd56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8e6ef62e2b34c8aacdc1649fe17e4fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_697bfec5bce44d288be7c56eaf74bc7a",
              "IPY_MODEL_d08f5f99111749c9ab15d44f7d5fba50",
              "IPY_MODEL_b5cd3bcc35b34f7d956d3577c324b539"
            ],
            "layout": "IPY_MODEL_313ede4051754fa388af12ed1c9f600f"
          }
        },
        "697bfec5bce44d288be7c56eaf74bc7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c2a19460aeb40549bd8bb7ae9bdaadf",
            "placeholder": "​",
            "style": "IPY_MODEL_8794be09ad104233b64d28fbbd94ba34",
            "value": "Downloading metadata: "
          }
        },
        "d08f5f99111749c9ab15d44f7d5fba50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecf092dc42074918b1a667211e602f99",
            "max": 1054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33db3c44c784457d81110afe2835b4da",
            "value": 1054
          }
        },
        "b5cd3bcc35b34f7d956d3577c324b539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f4b31759967448ab1c59b4a1260fb35",
            "placeholder": "​",
            "style": "IPY_MODEL_1568a69120314aae9164b27b844ce54b",
            "value": " 2.17k/? [00:00&lt;00:00, 37.2kB/s]"
          }
        },
        "313ede4051754fa388af12ed1c9f600f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c2a19460aeb40549bd8bb7ae9bdaadf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8794be09ad104233b64d28fbbd94ba34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecf092dc42074918b1a667211e602f99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33db3c44c784457d81110afe2835b4da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f4b31759967448ab1c59b4a1260fb35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1568a69120314aae9164b27b844ce54b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "424e6f0e108b407d843c0ee3d624c954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8b714faf35140ea8a4fc05998d3b4ea",
              "IPY_MODEL_534f5df45a364f9f82be003ebe93a246",
              "IPY_MODEL_792431bfa8c54cb5a09f3b61a8d8884e"
            ],
            "layout": "IPY_MODEL_eea2fdcad61a4cda9bba8f802199a2ca"
          }
        },
        "b8b714faf35140ea8a4fc05998d3b4ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce5a039bbb704756864ca6a62b8219ed",
            "placeholder": "​",
            "style": "IPY_MODEL_accac3bcc117412da8d45f9b2d50f8ec",
            "value": "Downloading data: 100%"
          }
        },
        "534f5df45a364f9f82be003ebe93a246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_823c0fbb914146d39004c2133b6a4651",
            "max": 84125825,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0aec56b99a914d14829fa288c8b6910d",
            "value": 84125825
          }
        },
        "792431bfa8c54cb5a09f3b61a8d8884e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fea9826d4df24544a0647f380417b1b6",
            "placeholder": "​",
            "style": "IPY_MODEL_5f1b09047b454240ada6174d9d7f64de",
            "value": " 84.1M/84.1M [00:05&lt;00:00, 35.9MB/s]"
          }
        },
        "eea2fdcad61a4cda9bba8f802199a2ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce5a039bbb704756864ca6a62b8219ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "accac3bcc117412da8d45f9b2d50f8ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "823c0fbb914146d39004c2133b6a4651": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aec56b99a914d14829fa288c8b6910d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fea9826d4df24544a0647f380417b1b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f1b09047b454240ada6174d9d7f64de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6554ec656d347a385b2bbe9ab1ae6ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa7d22ec7c644edea1a4e147772b5455",
              "IPY_MODEL_32ce14b807d648c49a00f762087a0a8c",
              "IPY_MODEL_344adf0de06444edbc56f4da4df96320"
            ],
            "layout": "IPY_MODEL_1dfebb60d6d548da953a421e93603669"
          }
        },
        "aa7d22ec7c644edea1a4e147772b5455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d55368161c414e8a84f99936950d4cbc",
            "placeholder": "​",
            "style": "IPY_MODEL_636c9e276edb4b98bfa57af0d99a5045",
            "value": "Generating train split:  99%"
          }
        },
        "32ce14b807d648c49a00f762087a0a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_763c0a42f26640f491b74efce8a1a003",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_355c8f7ee54b437f85200ac666271da6",
            "value": 25000
          }
        },
        "344adf0de06444edbc56f4da4df96320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94ed2a85944b473a81cf1a17940c8575",
            "placeholder": "​",
            "style": "IPY_MODEL_9a84fc6b76624a7ab8d174da8d72b6d4",
            "value": " 24784/25000 [00:06&lt;00:00, 6550.79 examples/s]"
          }
        },
        "1dfebb60d6d548da953a421e93603669": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d55368161c414e8a84f99936950d4cbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "636c9e276edb4b98bfa57af0d99a5045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "763c0a42f26640f491b74efce8a1a003": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "355c8f7ee54b437f85200ac666271da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94ed2a85944b473a81cf1a17940c8575": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a84fc6b76624a7ab8d174da8d72b6d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85e1df640b9141158b7e48a6a77315b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b3f56975cb34409aa1cd4afdda5a978",
              "IPY_MODEL_630c7bb30f2e4d1286acc5e884693cc7",
              "IPY_MODEL_23a55050d0aa4d33b8c98c161d5deccd"
            ],
            "layout": "IPY_MODEL_e9cdd0dfa5bd46a19624a34bc3b31dca"
          }
        },
        "4b3f56975cb34409aa1cd4afdda5a978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b24747c7c674b918a2d48fc0a7724bd",
            "placeholder": "​",
            "style": "IPY_MODEL_b8cf6daf7f2743559f08591d60c98394",
            "value": "Generating test split: 100%"
          }
        },
        "630c7bb30f2e4d1286acc5e884693cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab7b86d6ef3c44cf85579456d12c321a",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2e1bbd72c46488f80a197f5f77b8d6d",
            "value": 25000
          }
        },
        "23a55050d0aa4d33b8c98c161d5deccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cc5423a2eca4ea6a26de3ac0ab1b723",
            "placeholder": "​",
            "style": "IPY_MODEL_5e4aa7e7332f49e38fc14090635ce0d4",
            "value": " 24949/25000 [00:07&lt;00:00, 1527.25 examples/s]"
          }
        },
        "e9cdd0dfa5bd46a19624a34bc3b31dca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b24747c7c674b918a2d48fc0a7724bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8cf6daf7f2743559f08591d60c98394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab7b86d6ef3c44cf85579456d12c321a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2e1bbd72c46488f80a197f5f77b8d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cc5423a2eca4ea6a26de3ac0ab1b723": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e4aa7e7332f49e38fc14090635ce0d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ec9261ddbac459794edfd8181ac2981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1787050d2e0c417aaf649b2a4c54b625",
              "IPY_MODEL_d366fb91ff9840b2b2e022b4f2d03ef1",
              "IPY_MODEL_99dc5676991244cd96c42ee549a62e01"
            ],
            "layout": "IPY_MODEL_c817a8b67f3f4319953bd1775e3857bf"
          }
        },
        "1787050d2e0c417aaf649b2a4c54b625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31e5a0b6d85c4dda8fb11380f4876134",
            "placeholder": "​",
            "style": "IPY_MODEL_9f441dad5dc44ba293c6b6ddb1881a62",
            "value": "Generating unsupervised split:  99%"
          }
        },
        "d366fb91ff9840b2b2e022b4f2d03ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8714cb8add1e4af79a10fbc941519f3c",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_965c108e13744942a8975df93f549cbb",
            "value": 50000
          }
        },
        "99dc5676991244cd96c42ee549a62e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bc73b2d72bc48988dc1183a5a53105c",
            "placeholder": "​",
            "style": "IPY_MODEL_40976f2b1cb94e9281d3571bb8714aaa",
            "value": " 49646/50000 [00:19&lt;00:00, 6095.47 examples/s]"
          }
        },
        "c817a8b67f3f4319953bd1775e3857bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31e5a0b6d85c4dda8fb11380f4876134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f441dad5dc44ba293c6b6ddb1881a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8714cb8add1e4af79a10fbc941519f3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "965c108e13744942a8975df93f549cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7bc73b2d72bc48988dc1183a5a53105c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40976f2b1cb94e9281d3571bb8714aaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b676e1ef7fb74f29b736a73e3a52590c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3676fca51ede4670b5b286e0d7c8d01a",
              "IPY_MODEL_136cb7d9a3ab4f0cac06407cc71ad7a7",
              "IPY_MODEL_eea2ac18004b4950b955c6db6c315fc6"
            ],
            "layout": "IPY_MODEL_b810a390e051494b97be7b0021c1c9be"
          }
        },
        "3676fca51ede4670b5b286e0d7c8d01a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34489707be6b4808b6c38453ef096670",
            "placeholder": "​",
            "style": "IPY_MODEL_79fdce535307475d8d1c529e52bfd30c",
            "value": "100%"
          }
        },
        "136cb7d9a3ab4f0cac06407cc71ad7a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8e07e8116164a75b00f34547c525d91",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96f6e16b2a274abc8c9770e255f0d17d",
            "value": 3
          }
        },
        "eea2ac18004b4950b955c6db6c315fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbbda3bb801941088f7e5bd09229abf6",
            "placeholder": "​",
            "style": "IPY_MODEL_295ff8c125d8412da75650c98a269a97",
            "value": " 3/3 [00:00&lt;00:00, 38.14it/s]"
          }
        },
        "b810a390e051494b97be7b0021c1c9be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34489707be6b4808b6c38453ef096670": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79fdce535307475d8d1c529e52bfd30c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8e07e8116164a75b00f34547c525d91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96f6e16b2a274abc8c9770e255f0d17d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bbbda3bb801941088f7e5bd09229abf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "295ff8c125d8412da75650c98a269a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}